{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Form the NB Regression Random Intercept Model: Simulated set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling GLMCopula [c47b6ae2-b804-4668-9957-eb588c99ffbc]\n",
      "└ @ Base loading.jl:1278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000-element Array{Array{Float64,1},1}:\n",
       " [2.0, 1.0, 7.0, 0.0, 7.0]\n",
       " [1.0, 6.0, 7.0, 2.0, 12.0]\n",
       " [3.0, 3.0, 0.0, 1.0, 0.0]\n",
       " [7.0, 4.0, 0.0, 0.0, 4.0]\n",
       " [2.0, 7.0, 4.0, 1.0, 2.0]\n",
       " [3.0, 0.0, 3.0, 1.0, 1.0]\n",
       " [10.0, 3.0, 0.0, 5.0, 2.0]\n",
       " [0.0, 2.0, 0.0, 7.0, 1.0]\n",
       " [0.0, 2.0, 8.0, 0.0, 1.0]\n",
       " [2.0, 3.0, 5.0, 1.0, 6.0]\n",
       " [1.0, 4.0, 4.0, 0.0, 0.0]\n",
       " [0.0, 1.0, 1.0, 2.0, 0.0]\n",
       " [2.0, 7.0, 1.0, 4.0, 0.0]\n",
       " ⋮\n",
       " [4.0, 2.0, 3.0, 2.0, 9.0]\n",
       " [1.0, 0.0, 1.0, 1.0, 0.0]\n",
       " [0.0, 1.0, 2.0, 5.0, 0.0]\n",
       " [4.0, 3.0, 2.0, 3.0, 2.0]\n",
       " [2.0, 3.0, 4.0, 1.0, 12.0]\n",
       " [0.0, 0.0, 5.0, 4.0, 7.0]\n",
       " [1.0, 7.0, 3.0, 3.0, 2.0]\n",
       " [4.0, 1.0, 4.0, 2.0, 2.0]\n",
       " [1.0, 6.0, 1.0, 1.0, 0.0]\n",
       " [0.0, 0.0, 2.0, 3.0, 1.0]\n",
       " [4.0, 2.0, 2.0, 0.0, 0.0]\n",
       " [0.0, 3.0, 0.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames, Random, GLM, GLMCopula, Revise\n",
    "using ForwardDiff, Test, LinearAlgebra\n",
    "using LinearAlgebra: BlasReal, copytri!\n",
    "\n",
    "Random.seed!(1235)\n",
    "\n",
    "# sample size\n",
    "N = 10000\n",
    "# observations per subject\n",
    "n = 5\n",
    "\n",
    "variance_component_1 = 0.1\n",
    "variance_component_2 = 0.9\n",
    "\n",
    "r = 2\n",
    "p = 0.5\n",
    "μ = r * p * inv(1-p)\n",
    "# true beta\n",
    "β_true = log(μ)\n",
    "\n",
    "dist = NegativeBinomial\n",
    "\n",
    "Γ = variance_component_1 * ones(n, n) + variance_component_2 * Matrix(I, n, n)\n",
    "vecd = [dist(r, p) for i in 1:n]\n",
    "nonmixed_multivariate_dist = NonMixedMultivariateDistribution(vecd, Γ)\n",
    "\n",
    "Y_Nsample = simulate_nobs_independent_vectors(nonmixed_multivariate_dist, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = NegativeBinomial()\n",
    "D = typeof(d)\n",
    "gcs = Vector{GLMCopulaVCObs{Float64, D}}(undef, N)\n",
    "for i in 1:N\n",
    "    y = Float64.(Y_Nsample[i])\n",
    "    X = ones(n, 1)\n",
    "    V = [ones(n, n), Matrix(I, n, n)]\n",
    "    gcs[i] = GLMCopulaVCObs(y, X, V, d)\n",
    "end\n",
    "gcm = GLMCopulaVCModel(gcs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Float64,1}:\n",
       " 0.6931471805599453"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill!(gcm.β, β_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize β and σ2, here I just copy the solution for β and σ2 from MixedModels.jl over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcm.Σ = [10613.43343608239, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 10613.43343608239\n",
       "     0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill!(gcm.Σ, 1.0)\n",
    "update_Σ!(gcm)\n",
    "@show gcm.Σ\n",
    "# GLMCopula.loglikelihood!(gcm, true, true) this line doesnt work ArgumentError: NegativeBinomial: the condition zero(p) < p <= one(p) is not satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closer Look at Observation 1\n",
    "i =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "β = [0.6931471805599453]\n",
      "Σ = [10613.43343608239, 0.0]\n",
      "τ = [0.05314691797819666]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc = gcm.data[1]\n",
    "β  = gcm.β\n",
    "Σ  = gcm.Σ\n",
    "τ  = gcm.τ\n",
    "\n",
    "@show β\n",
    "@show Σ\n",
    "@show τ\n",
    "\n",
    "n_i  = length(gc.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loglikelihood for observation i = 1, j in [1, n_1]\n",
    "$$\\mathcal{L}(\\mathbf{\\beta})_1 =  - \\ln \\Big[1\\! +\\! \\frac{1}{2}tr(\\mathbf{\\Gamma_{1}})\\Big] +\n",
    "\\ln \\Big\\{1\\!+\\!\\frac{1}{2}\\mathbf{r_1}(\\mathbf{\\beta})^t \\mathbf{\\Gamma_1} \\mathbf{r_1}(\\mathbf{\\beta})\\Big\\} +  \\sum_{j=1}^{n_1}y_{1j}log(\\mu_{1j}(\\mathbf{\\beta})) - \\mu_{1j}(\\mathbf{\\beta})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First I want to check if the mean and residuals are updated and standardized at this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gc.res = [2.82842712474619, 2.1213203435596424, 6.363961030678928, 1.414213562373095, 6.363961030678928]\n",
      "gc.res = [0.0, -1.0, 5.0, -2.0, 5.0]\n",
      "gc.res = [0.0, -0.4082482904638631, 2.041241452319315, -0.8164965809277261, 2.041241452319315]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show gc.res\n",
    "update_res!(gcm)\n",
    "@show gc.res\n",
    "standardize_res!(gcm)\n",
    "@show gc.res\n",
    "\n",
    "@test gc.η == gc.X*β                         # systematic linear component\n",
    "@test gc.μ == exp.(gc.η)                     # mu = ginverse of XB = mean component for GLM\n",
    "@test gc.varμ == gc.μ .* (1 .+ gc.μ ./gc.d.r)                # variance of the GLM response as a function of mean mu\n",
    "@test gc.res == (gc.y .- gc.μ) ./ sqrt.(gc.varμ) # standardized residual for GLM outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next I want to check if the hard coded terms in the loglikelihood are correct\n",
    "\n",
    "$$\\text{Term 1 }= - \\ln \\Big[1\\! +\\! \\frac{1}{2}tr(\\mathbf{\\Gamma_{1}})\\Big]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term1 = -10.186204202288135\n"
     ]
    }
   ],
   "source": [
    "Γ_est = Σ[1] * gc.V[1] + Σ[2] * gc.V[2]\n",
    "trace_gamma = tr(Γ_est)\n",
    "\n",
    "term1 = -log(1 + 0.5 * trace_gamma)\n",
    "@show term1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-(log(1 + tsum)) = -10.186204202288135\n"
     ]
    }
   ],
   "source": [
    "tsum = dot(Σ, gc.t)\n",
    "@show -log(1 + tsum);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gc.res = [0.0, -0.4082482904638631, 2.041241452319315, -0.8164965809277261, 2.041241452319315]\n",
      "log(1 + qsum) = 10.676812505432654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.676812505432654"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show gc.res\n",
    "m = length(gc.V)\n",
    "for k in 1:m\n",
    "    mul!(gc.storage_n, gc.V[k], gc.res) \n",
    "    gc.q[k] = dot(gc.res, gc.storage_n) / 2 \n",
    "end\n",
    "qsum  = dot(Σ, gc.q) \n",
    "inv1pq = inv(1 + qsum)\n",
    "\n",
    "@show  log(1 + qsum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Term 2} = \\ln \\Big\\{1\\!+\\!\\frac{1}{2}\\mathbf{r_1}(\\mathbf{\\beta})^t \\mathbf{\\Gamma_1} \\mathbf{r_1}(\\mathbf{\\beta})\\Big\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quad_form_standardized_res = 86676.37306133953\n",
      "term2 = 10.676812505432654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.676812505432654"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# term 2:\n",
    "quad_form_standardized_res = transpose(gc.res) * Γ_est * gc.res\n",
    "@show quad_form_standardized_res\n",
    "\n",
    "term2 = log(1 + 0.5 * quad_form_standardized_res) \n",
    "@show term2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the loglikelihood function I have:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Term1 + Term2} =  - \\ln \\Big[1\\! +\\! \\frac{1}{2}tr(\\mathbf{\\Gamma_{1}})\\Big] +\n",
    "\\ln \\Big\\{1\\!+\\!\\frac{1}{2}\\mathbf{r_1}(\\mathbf{\\beta})^t \\mathbf{\\Gamma_1} \\mathbf{r_1}(\\mathbf{\\beta})\\Big\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gc.res = [0.0, -0.4082482904638631, 2.041241452319315, -0.8164965809277261, 2.041241452319315]\n",
      "logl_hard_coded_obs1 = 0.4906083031445192\n",
      "copula_logl_function = 0.4906083031445192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logl_hard_coded_obs1 = term1 + term2\n",
    "copula_logl_function = GLMCopula.copula_loglikelihood_addendum(gc, Σ)\n",
    "@show gc.res\n",
    "@show logl_hard_coded_obs1\n",
    "@show copula_logl_function\n",
    "@test copula_logl_function ≈ logl_hard_coded_obs1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of Loglikelihood that comes from the Density using GLM.jl\n",
    "\n",
    "$$\\text{Term 3} = \\sum_{j=1}^{n_1} NB(y_{ij})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-12.38596828117934"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term3 = 0.0\n",
    "for j in 1:n_i\n",
    "   term3 += GLM.logpdf(NegativeBinomial(gc.d.r, gc.d.r/(gc.μ[j]+gc.d.r)), gc.y[j]) \n",
    "end\n",
    "term3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-12.38596828117934"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logl_component_nb = 0.0\n",
    "logl_component_nb += component_loglikelihood(gc, τ[1], logl_component_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathcal{L}(\\mathbf{\\beta})_1 =  - \\ln \\Big[1\\! +\\! \\frac{1}{2}tr(\\mathbf{\\Gamma_{1}})\\Big] +\n",
    "\\ln \\Big\\{1\\!+\\!\\frac{1}{2}\\mathbf{r_1}(\\mathbf{\\beta})^t \\mathbf{\\Gamma_1} \\mathbf{r_1}(\\mathbf{\\beta})\\Big\\} +  \\sum_{j=1}^{n_1} NB(y_{1j})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-11.89535997803482"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logl_hard = term1 + term2 + term3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-11.89535997803482"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logl_my_function = copula_loglikelihood(gc, β, τ[1], Σ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test logl_hard ≈ logl_my_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Closer Look at the Gradient for observation i=1\n",
    "\n",
    "$$\\begin{eqnarray*}\n",
    "\\nabla_\\beta &=& \\sum_{i=1}^n \\sum_j \\nabla \\ln f_{ij}(y_{ij} \\mid \\mathbf{\\beta}) + \\sum_{i=1}^n\n",
    "\\frac{\\nabla \\mathbf{r_i(\\mathbf{\\beta})}\\mathbf{\\Gamma_i}\\mathbf{r_i(\\mathbf{\\beta})}}{1+\\frac{1}{2}\\mathbf{r_i}(\\mathbf{\\beta})^t \\mathbf{\\Gamma_i} \\mathbf{r_i(\\mathbf{\\beta})}}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "The gradient is made of two terms. The first is from the GLM component loglikelihood that corresponds to the Logistic Regression density. The second part is specific to our copula model. We start with Term 1 for observation 1:\n",
    "\n",
    "$$\\begin{eqnarray*}\n",
    "    \\text{Term 1} &=& \\sum_{j=1}^{n_1} \\frac{(y_{1j}-\\mu_{1j}) \\mu_{1j}'(\\eta_{1j})}{\\sigma_{1j}^2} \\mathbf{x}_{1j}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "We will check if the field $\\mu_{1j}'$ or `mueta` from the GLM.jl package matches our theoretical value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test gc.dμ == exp.(gc.η)                  # derivative of mean with respect to systematic component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Float64,1}:\n",
       " 2.3333333333333335"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function nb_gradient(y, X, dμ, σ2, μ)\n",
    "    grad = zeros(size(X, 2))\n",
    "    for j in 1:length(y)\n",
    "        grad += (y[j] - μ[j]) * dμ[j]/σ2[j] * X[j, :]\n",
    "    end\n",
    "    grad\n",
    "end\n",
    "\n",
    "# check if glm gradient is right\n",
    "term1_gradient = nb_gradient(gc.y, gc.X, gc.dμ, gc.varμ, gc.μ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term1_grad_fctn = GLMCopula.glm_gradient(gc, β, τ)\n",
    "@test term1_gradient == term1_grad_fctn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copula density specific gradient portion\n",
    "\n",
    "$$ \\text{Term 2} = \\frac{\\nabla \\mathbf{r_1(\\mathbf{\\beta})}^\\top\\mathbf{\\Gamma_1}\\mathbf{r_1(\\mathbf{\\beta})}}{1+\\frac{1}{2}\\mathbf{r_1}(\\mathbf{\\beta})^t \\mathbf{\\Gamma_i} \\mathbf{r_1(\\mathbf{\\beta})}}\n",
    "$$\n",
    "\n",
    "Notice the second term uses a critical value that will come up in the Hessian as well. For the first observation, $i = 1,$ we have $n_1 = 5$ and $p = 1$ in the simulated dataset. $\\nabla \\mathbf{r_1(\\mathbf{\\beta})}$ which is an $5 \\times 1$ matrix of differentials. \n",
    "\n",
    "Each column of $\\nabla \\mathbf{r_1(\\mathbf{\\beta})}^\\top$ is a $p \\times 1$ vector $\\nabla r_{1j}(\\mathbf{\\beta})$\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\nabla r_{1j}(\\mathbf{\\beta}) &=&  -\\frac{1}{\\sigma_{1j}(\\mathbf{\\beta})} \\nabla \\mu_{1j}(\\mathbf{\\beta})- \\frac{1}{2} \\frac{y_{1j}-\\mu_{1j}(\\mathbf{\\beta})}{\\sigma_{1j}^3(\\mathbf{\\beta})} \\nabla \\sigma_{1j}^2(\\mathbf{\\beta})\\\\\n",
    "&=&  -\\frac{1}{\\sigma_{1j}(\\mathbf{\\beta})} \\nabla \\mu_{1j}(\\mathbf{\\beta})- \\frac{1}{2\\sigma_{1j}^2(\\mathbf{\\beta})}r_{1j}(\\mathbf{\\beta}) \\nabla \\sigma_{1j}^2(\\mathbf{\\beta})\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\nabla \\mu_{1j}(\\mathbf{\\beta}) &=& e^{\\eta_{1j}(\\mathbf{\\beta})} * \\mathbf{x_{1j}}\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∇μβ1 = [2.0]\n",
      "∇μβ2 = [2.0]\n",
      "∇μβend = [2.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1-element Array{Float64,1}:\n",
       " 2.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for j = 1 and j = 2, ..., j = end; lets take a look at the first two columns \n",
    "∇μβ1 = exp.(gc.η[1]) .* gc.X[1, :]\n",
    "∇μβ2 = exp.(gc.η[2]) .* gc.X[2, :]\n",
    "# ...\n",
    "∇μβend = exp.(gc.η[end]) .* gc.X[end, :]\n",
    "\n",
    "@show ∇μβ1\n",
    "@show ∇μβ2\n",
    "@show ∇μβend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and  \n",
    "$$  \\begin{eqnarray*}\n",
    "    \\nabla \\sigma_{ij}^2(\\beta) = \\frac{d\\sigma_{ij}^2(\\beta)}{d\\mu_{ij}(\\beta)} \\frac{d\\mu_{ij}(\\beta)}{d\\eta_{ij}(\\beta)} \\frac{d\\eta_{ij}(\\beta)}{d\\beta} = (1 + \\frac{\\mu_{ij}}{r}) + \\frac{\\mu_{ij}}{r} * e^{\\eta_{ij}(\\beta)} \\mathbf{x}_{ij} \n",
    "\\end{eqnarray*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∇σ2β1 = [10.0]\n",
      "∇σ2β2 = [10.0]\n",
      "∇σ2βend = [10.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1-element Array{Float64,1}:\n",
       " 10.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for j = 1 and j = 2 ,... , j = end; lets take a look at the first two columns \n",
    "∇σ2β1 = ((1 + gc.μ[1] * inv(gc.d.r)) .+ gc.dμ[1] * inv(gc.d.r)) * gc.μ[1] .* gc.X[1, :]\n",
    "∇σ2β2 = ((1 + gc.μ[2] * inv(gc.d.r)) .+ gc.dμ[2] * inv(gc.d.r)) * gc.μ[2] .* gc.X[2, :]\n",
    "# ...\n",
    "∇σ2βend = ((1 + gc.μ[end] * inv(gc.d.r)) .+ gc.dμ[end] * inv(gc.d.r)) * gc.μ[end] .* gc.X[end, :]\n",
    "\n",
    "@show ∇σ2β1\n",
    "@show ∇σ2β2\n",
    "@show ∇σ2βend\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\nabla r_{1j}(\\mathbf{\\beta}) &=&  -\\frac{1}{\\sigma_{1j}(\\mathbf{\\beta})} \\nabla \\mu_{1j}(\\mathbf{\\beta})- \\frac{1}{2} \\frac{y_{1j}-\\mu_{1j}(\\mathbf{\\beta})}{\\sigma_{1j}^3(\\mathbf{\\beta})} \\nabla \\sigma_{1j}^2(\\mathbf{\\beta})\\\\\n",
    "&=&  -\\frac{1}{\\sigma_{1j}(\\mathbf{\\beta})} \\nabla \\mu_{1j}(\\mathbf{\\beta})- \\frac{1}{2\\sigma_{1j}^2(\\mathbf{\\beta})}r_{1j}(\\mathbf{\\beta}) \\nabla \\sigma_{1j}^2(\\mathbf{\\beta})\n",
    "\\end{eqnarray*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4762896722078403"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1/(sqrt(gc.varμ[2])) * ∇μβ2[1] - (0.5 * inv(gc.varμ[2])) * gc.res[2] * ∇σ2β2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∇resβ1 = -0.8164965809277261\n",
      "∇resβ2 = -0.4762896722078403\n",
      "∇resβend = -2.517531124527155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2.517531124527155"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇resβ1 = -1/(sqrt(gc.varμ[1])) * ∇μβ1[1] - (0.5 * inv(gc.varμ[1])) * gc.res[1] * ∇σ2β1[1]\n",
    "∇resβ2 = -1/(sqrt(gc.varμ[2])) * ∇μβ2[1] - (0.5 * inv(gc.varμ[2])) * gc.res[2] * ∇σ2β2[1]\n",
    "# ...\n",
    "∇resβend = -1/(sqrt(gc.varμ[end])) * ∇μβend[1] - (0.5 * inv(gc.varμ[end])) * gc.res[end] * ∇σ2βend[1]\n",
    "\n",
    "@show ∇resβ1\n",
    "@show ∇resβ2\n",
    "@show ∇resβend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_res_differential!(gc)\n",
    "@test gc.∇resβ[1, :] == [∇resβ1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test gc.∇resβ[2, :] == [∇resβ2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test gc.∇resβ[end, :] == [∇resβend]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient portion of Copula specific model\n",
    "\n",
    "$$\\begin{eqnarray*}\n",
    "\\text{Term 2} &=& \\sum_{i=1}^n\n",
    "\\frac{\\nabla \\mathbf{r_i(\\mathbf{\\beta})}\\mathbf{\\Gamma_i}\\mathbf{r_i(\\mathbf{\\beta})}}{1+\\frac{1}{2}\\mathbf{r_i}(\\mathbf{\\beta})^t \\mathbf{\\Gamma_i} \\mathbf{r_i(\\mathbf{\\beta})}}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "Again for observation $ i = 1$ we have:  \n",
    "\n",
    "$$ \\text{Term 2} = \\frac{\\nabla \\mathbf{r_1(\\mathbf{\\beta})}^\\top\\mathbf{\\Gamma_1}\\mathbf{r_1(\\mathbf{\\beta})}}{1+\\frac{1}{2}\\mathbf{r_1}(\\mathbf{\\beta})^t \\mathbf{\\Gamma_i} \\mathbf{r_1(\\mathbf{\\beta})}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do: Fix copula_gradient_addendum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_t2_numerator = [-196053.7009720775]\n",
      "quadratic_form = 86676.37306133953\n",
      "grad_t2_denominator = 2.3073806410564068e-5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1-element Array{Float64,1}:\n",
       " -4.523705142304332"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Γ_est = Σ[1] * gc.V[1] + Σ[2] * gc.V[2]\n",
    "\n",
    "grad_t2_numerator = transpose(gc.∇resβ) * Γ_est * gc.res       # new term ∇resβ^t * Γ * res\n",
    "@show grad_t2_numerator\n",
    "\n",
    "quadratic_form = transpose(gc.res) * Γ_est * gc.res\n",
    "@show quadratic_form \n",
    "@test quadratic_form ≈ quad_form_standardized_res # from the loglikelihood 'qsum'\n",
    "\n",
    "grad_t2_denominator = inv(1 + 0.5 * quadratic_form)\n",
    "@show grad_t2_denominator\n",
    "\n",
    "gradient_term2 = grad_t2_numerator * grad_t2_denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Float64,1}:\n",
       " -11.259253438412616"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_term2_function = GLMCopula.copula_gradient_addendum(gc, β, τ[1], Σ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\u001b[1mTest Failed\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[107]:1\u001b[22m\n",
      "  Expression: gradient_term2 ≈ gradient_term2_function\n",
      "   Evaluated: [-4.523705142304332] ≈ [-11.259253438412616]\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mThere was an error during testing\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mThere was an error during testing\u001b[39m",
      "",
      "Stacktrace:",
      " [1] record(::Test.FallbackTestSet, ::Union{Test.Error, Test.Fail}) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:737",
      " [2] do_test(::Test.ExecutionResult, ::Any) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:520",
      " [3] top-level scope at In[107]:1",
      " [4] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "@test gradient_term2 ≈ gradient_term2_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Float64,1}:\n",
       " -60.5223591702637"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_hard_code = term1_gradient + gradient_term2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Float64,1}:\n",
       " -8.925920105079282"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_gradient_my_function = copula_gradient(gc, β, τ, Σ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\u001b[1mTest Failed\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[32]:1\u001b[22m\n",
      "  Expression: full_gradient_my_function ≈ gradient_hard_code\n",
      "   Evaluated: [-8.925920105079282] ≈ [-60.5223591702637]\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mThere was an error during testing\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mThere was an error during testing\u001b[39m",
      "",
      "Stacktrace:",
      " [1] record(::Test.FallbackTestSet, ::Union{Test.Error, Test.Fail}) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:737",
      " [2] do_test(::Test.ExecutionResult, ::Any) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:520",
      " [3] top-level scope at In[32]:1",
      " [4] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "@test full_gradient_my_function ≈ gradient_hard_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's now use the ForwardDiff.jl package to check if our matrix calculus is correct.\n",
    "\n",
    "I want to start by checking my calculation of the gradient. \n",
    "\n",
    "    (1) I will modify the functions that reflect parts of the loglikelihood above in section 1 to use the package properly. \n",
    "    (2) I will then compare the results to that from my gradient functions above in section 2 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Test if the gradient of the component loglikelihood matches our gradient function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function poisson_density(β::Vector)\n",
    "    η = gc.X*β                        # systematic linear component\n",
    "    μ = exp.(η)   # mu = ginverse of XB = mean component for GLM = [p]\n",
    "    dμ = exp.(η)\n",
    "    varμ = dμ\n",
    "    logl = sum(gc.y .* log.(μ) .- μ)\n",
    "end\n",
    "\n",
    "logl_term3 = poisson_density(β)\n",
    "@show logl_term3\n",
    "\n",
    "g = x -> ForwardDiff.gradient(poisson_density, x)\n",
    "\n",
    "gradientmagictest = g(β)\n",
    "@show gradientmagictest\n",
    "@show term1_grad_fctn\n",
    "@test term1_grad_fctn == gradientmagictest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we check the gradient of the matrix of differentials residual vector\n",
    "\n",
    "Lets start with $i = 1, j = 1$ so the first observation of the $i^{th}$ group has the following gradient of the standardized residual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×1 Array{Float64,2}:\n",
       "  -0.8164965809277261\n",
       "  11.430952132988166\n",
       " -62.053740150507174\n",
       "  23.678400846904058\n",
       " -62.053740150507174"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_res_differential!(gc)\n",
    "gc.∇resβ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length(varμ) = 5\n",
      "gradientmagictest2 = [-0.8164965809277261]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1-element Array{Float64,1}:\n",
       " -0.8164965809277261"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function standardized_residual_firstobs(β::Vector)\n",
    "    η = gc.X*β                        # systematic linear component\n",
    "    μ = exp.(η) # mu = ginverse of XB = mean component for GLM = [p]\n",
    "    varμ = μ .* (1 .+ μ ./gc.d.r)\n",
    "    res = (gc.y[1] - μ[1]) / sqrt(varμ[1])\n",
    "end\n",
    "\n",
    "g2 = x -> ForwardDiff.gradient(standardized_residual_firstobs, x)\n",
    "gradientmagictest2 = g2(β)\n",
    "@show gradientmagictest2\n",
    "\n",
    "# @test gc.∇resβ[1, :] == gradientmagictest2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4082482904638631"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardized_residual_secondobs(β)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradientmagictest22 = [-0.47628967220784024]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1-element Array{Float64,1}:\n",
       " -0.47628967220784024"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function standardized_residual_secondobs(β::Vector)\n",
    "    η = gc.X*β                        # systematic linear component\n",
    "    μ = exp.(η) # mu = ginverse of XB = mean component for GLM = [p]\n",
    "    varμ = μ .* (1 .+ μ ./gc.d.r)\n",
    "    res = (gc.y[2] - μ[2]) / sqrt(varμ[2])\n",
    "    res\n",
    "end\n",
    "\n",
    "g_second = x -> ForwardDiff.gradient(standardized_residual_secondobs, x)\n",
    "gradientmagictest22 = g_second(β)\n",
    "@show gradientmagictest22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradientmagictest_5 = [-2.5175311245271557]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1-element Array{Float64,1}:\n",
       " -2.5175311245271557"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function standardized_residual_lastobs(β::Vector)\n",
    "    η = gc.X*β                        # systematic linear component\n",
    "    μ = exp.(η) # mu = ginverse of XB = mean component for GLM = [p]\n",
    "    varμ = μ .* (1 .+ μ ./gc.d.r)\n",
    "    res = (gc.y[5] - μ[5]) / sqrt(varμ[5])\n",
    "    res\n",
    "end\n",
    "\n",
    "g_last = x -> ForwardDiff.gradient(standardized_residual_lastobs, x)\n",
    "gradientmagictest_5 = g_last(β)\n",
    "@show gradientmagictest_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now I will check the part of the Loglikelihood that is specific to our density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function copula_loglikelihood_addendum1(β::Vector)\n",
    "  m = length(gc.V)\n",
    "  η = gc.X*β                        # systematic linear component\n",
    "  μ = exp.(η) # mu = ginverse of XB = mean component for GLM = [p]\n",
    "  varμ = exp.(η)\n",
    "  res = (gc.y .- μ) ./ sqrt.(varμ)\n",
    "  trace_gamma = tr(Γ_est)\n",
    "\n",
    "  term1 = -log(1 + 0.5 * trace_gamma)\n",
    "  quad_form_standardized_res = transpose(res)* Γ_est * res\n",
    "  term2 = log(1 + 0.5 * quad_form_standardized_res)\n",
    "  logl_hard_coded_obs1 = term1 + term2\n",
    "  logl_hard_coded_obs1\n",
    "end\n",
    "\n",
    "g3 = x -> ForwardDiff.gradient(copula_loglikelihood_addendum1, x)\n",
    "\n",
    "@show copula_loglikelihood_addendum1(β)\n",
    "\n",
    "gradientmagictest3 = g3(β)\n",
    "@show gradientmagictest3\n",
    "@show gradient_term2_function\n",
    "@test gradient_term2_function ≈ gradientmagictest3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now I will put together both the parts of the loglikelihood and both the parts of the gradient to check alltogether now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function full_loglikelihood(β::Vector)\n",
    "    logl = 0.0\n",
    "    logl = poisson_density(β) + copula_loglikelihood_addendum1(β)\n",
    "    logl\n",
    "end\n",
    "\n",
    "@show full_loglikelihood(β)\n",
    "\n",
    "g4 = x -> ForwardDiff.gradient(full_loglikelihood, x)\n",
    "\n",
    "gradientmagictest4 = g4(β)\n",
    "@show gradientmagictest4\n",
    "\n",
    "full_gradient_function = copula_gradient(gc, β, τ, Σ)\n",
    "@show full_gradient_function\n",
    "@test full_gradient_function ≈ gradientmagictest4"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
