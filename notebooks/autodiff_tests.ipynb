{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try autodiff with multivariate GWAS\n",
    "\n",
    "1. We want to estimate a general covariance matrix $\\Gamma = LL^t$\n",
    "2. The loglikelihood therefore is a function of $\\beta$ and $L$\n",
    "3. We need to be able to:\n",
    "    + autodiff a logl function that calls BLAS internally and has in-place operations\n",
    "    + autodiff a logl function that takes $L$ (cholesky factor) as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vech"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Enzyme\n",
    "using LinearAlgebra\n",
    "using BenchmarkTools\n",
    "\n",
    "\"\"\"\n",
    "    vech!(v::AbstractVector, A::AbstractVecOrMat)\n",
    "    vech!(v::AbstractVector, A::Cholesky)\n",
    "\n",
    "Overwrite vector `v` by the entries from lower triangular part of `A`. \n",
    "Source = https://github.com/OpenMendel/WiSER.jl/blob/77e723b4769eb54f9eaa72aab038b4b5366365cd/src/multivariate_calculus.jl#L2\n",
    "\"\"\"\n",
    "function vech!(v::AbstractVector, A::AbstractVecOrMat)\n",
    "    m, n = size(A, 1), size(A, 2)\n",
    "    idx = 1\n",
    "    @inbounds for j in 1:n, i in j:m\n",
    "        v[idx] = A[i, j]\n",
    "        idx += 1\n",
    "    end\n",
    "    v\n",
    "end\n",
    "function vech!(v::AbstractVector, L::Cholesky)\n",
    "    Ldata = L.factors\n",
    "    if L.uplo === 'L'\n",
    "        vech!(v, Ldata)\n",
    "    else\n",
    "        error(\"L.uplo !== 'L'! Construct cholesky factors using cholesky(x, :L)\")\n",
    "    end\n",
    "    return v\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    un_vech!(A::AbstractMatrix, v::AbstractVector)\n",
    "    un_vech!(A::Cholesky, v::AbstractVector)\n",
    "\n",
    "Overwrite lower triangular part of `A` by the entries from `v`. Upper triangular\n",
    "part of `A` is untouched.  \n",
    "\"\"\"\n",
    "function un_vech!(A::AbstractMatrix, v::AbstractVector)\n",
    "    m, n = size(A, 1), size(A, 2)\n",
    "    idx = 1\n",
    "    @inbounds for j in 1:n, i in j:m\n",
    "        A[i, j] = v[idx]\n",
    "        idx += 1\n",
    "    end\n",
    "    A\n",
    "end\n",
    "function un_vech!(L::Cholesky, v::AbstractVector)\n",
    "    un_vech!(L.factors, v)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    vech(A::AbstractVecOrMat) -> AbstractVector\n",
    "\n",
    "Return the entries from lower triangular part of `A` as a vector.\n",
    "Source = https://github.com/OpenMendel/WiSER.jl/blob/77e723b4769eb54f9eaa72aab038b4b5366365cd/src/multivariate_calculus.jl#L2\n",
    "\"\"\"\n",
    "function vech(A::AbstractVecOrMat)\n",
    "    m, n = size(A, 1), size(A, 2)\n",
    "    vech!(similar(A, n * m - (n * (n - 1)) >> 1), A)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Enzyme.jl` with BLAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000588 seconds (6 allocations: 78.266 KiB)\n",
      "  0.000427 seconds (9 allocations: 3.968 MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mUsing fallback BLAS replacements for ([\"dsymv_64_\"]), performance may be degraded\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Enzyme.Compiler ~/.julia/packages/GPUCompiler/kqxyC/src/utils.jl:59\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50×2 Matrix{Float64}:\n",
       "  10394.5    10394.5\n",
       "  -9499.72   -9499.72\n",
       "   1758.3     1758.3\n",
       "  -9888.78   -9888.78\n",
       "  -3352.47   -3352.47\n",
       "   2688.75    2688.75\n",
       "  -4977.85   -4977.85\n",
       "  -1718.61   -1718.61\n",
       "   2680.03    2680.03\n",
       "  -3743.46   -3743.46\n",
       "  -2161.22   -2161.22\n",
       "  14151.1    14151.1\n",
       "   1875.09    1875.09\n",
       "      ⋮     \n",
       "   1365.16    1365.16\n",
       " -11158.0   -11158.0\n",
       " -12188.4   -12188.4\n",
       "  -8963.68   -8963.68\n",
       "   3879.96    3879.96\n",
       "   3234.32    3234.32\n",
       "  -9421.35   -9421.35\n",
       "  -9140.11   -9140.11\n",
       " -13256.7   -13256.7\n",
       "   2129.72    2129.72\n",
       " -18850.8   -18850.8\n",
       "  -3807.75   -3807.75"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# objective = 0.5 || y - X*beta ||^2\n",
    "function ols(y, X, beta, storage=zeros(size(X, 1)))\n",
    "    mul!(storage, X, beta)\n",
    "    storage .= y .- storage\n",
    "    return 0.5 * sum(abs2, storage)\n",
    "end\n",
    "\n",
    "# simulate data\n",
    "n = 10000\n",
    "p = 50\n",
    "X = randn(n, p)\n",
    "y = randn(n)\n",
    "beta = randn(p)\n",
    "storage = zeros(n)\n",
    "ols(y, X, beta)\n",
    "\n",
    "# autodiff grad (precompile)\n",
    "grad_storage = zeros(length(beta))\n",
    "Enzyme.autodiff(\n",
    "    Reverse, ols, \n",
    "    Const(y), \n",
    "    Const(X), \n",
    "    Duplicated(beta, grad_storage), \n",
    "    Duplicated(storage, zero(storage))\n",
    ")\n",
    "grad_storage .= 0\n",
    "\n",
    "# time\n",
    "@time Enzyme.autodiff(\n",
    "    Reverse, ols, \n",
    "    Const(y), \n",
    "    Const(X), \n",
    "    Duplicated(beta, grad_storage), \n",
    "    Duplicated(storage, zero(storage))\n",
    ")\n",
    "\n",
    "# analytical grad\n",
    "@time true_grad = -X' * (y - X*beta);\n",
    "\n",
    "# check answers\n",
    "[true_grad grad_storage]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DifferentianInterface with BLAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mUsing fallback BLAS replacements for ([\"dsymv_64_\"]), performance may be degraded\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Enzyme.Compiler ~/.julia/packages/GPUCompiler/kqxyC/src/utils.jl:59\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50-element Vector{Float64}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " ⋮\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# objective = 0.5 || y - X*beta ||^2\n",
    "function ols(y, X, beta, storage=zeros(size(X, 1)))\n",
    "    mul!(storage, X, beta)\n",
    "    storage .= y .- storage\n",
    "    return 0.5 * sum(abs2, storage)\n",
    "end\n",
    "\n",
    "# simulate data\n",
    "n = 10000\n",
    "p = 50\n",
    "X = randn(n, p)\n",
    "y = randn(n)\n",
    "beta = randn(p)\n",
    "storage = zeros(n)\n",
    "ols(y, X, beta)\n",
    "\n",
    "# differention interface\n",
    "ols(β) = ols(y, X, β, storage)\n",
    "beta = zeros(p)\n",
    "DifferentiationInterface.gradient(ols, AutoEnzyme(), beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Enzyme.jl` with cholesky inputs\n",
    "\n",
    "Suppose our objective is\n",
    "\n",
    "$$f(\\beta, L) = \\frac{1}{2}\\|y - X\\beta\\|^2_2 + \\|vech(L)\\|^2$$\n",
    "\n",
    "where $L$ represents the cholesky factorization of some symmetric PD matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "787870.1077377998"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# objective = 0.5 || y - X*beta ||^2\n",
    "function f(y, X, vechL, beta, storage=zeros(size(X, 1)))\n",
    "    mul!(storage, X, beta)\n",
    "    storage .= y .- storage\n",
    "    return 0.5 * sum(abs2, storage) + sum(abs2, vechL)\n",
    "end\n",
    "\n",
    "# helper functions\n",
    "function vech!(v::AbstractVector, A::AbstractVecOrMat)\n",
    "    m, n = size(A, 1), size(A, 2)\n",
    "    idx = 1\n",
    "    @inbounds for j in 1:n, i in j:m\n",
    "        v[idx] = A[i, j]\n",
    "        idx += 1\n",
    "    end\n",
    "    v\n",
    "end\n",
    "function vech!(v::AbstractVector, L::Cholesky)\n",
    "    Ldata = L.factors\n",
    "    if L.uplo === 'L'\n",
    "        vech!(v, Ldata)\n",
    "    else\n",
    "        error(\"L.uplo !== 'L'! Construct cholesky factors using cholesky(x, :L)\")\n",
    "    end\n",
    "    return v\n",
    "end\n",
    "\n",
    "# simulate data\n",
    "n = 10000\n",
    "p = 50\n",
    "X = randn(n, p)\n",
    "y = randn(n)\n",
    "beta = randn(p)\n",
    "storage = zeros(n)\n",
    "L = cholesky(Symmetric(X'*X, :L))\n",
    "vechL = zeros((p * (p+1) >> 1))\n",
    "vech!(vechL, L)\n",
    "f(y, X, vechL, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000831 seconds (7 allocations: 78.281 KiB)\n",
      "  0.000591 seconds (9 allocations: 3.968 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50×2 Matrix{Float64}:\n",
       "  14890.3    14890.3\n",
       "  10285.8    10285.8\n",
       " -26034.3   -26034.3\n",
       "   6992.24    6992.24\n",
       "  -1519.94   -1519.94\n",
       "  -6055.18   -6055.18\n",
       " -13556.5   -13556.5\n",
       "  28973.6    28973.6\n",
       "  -7394.89   -7394.89\n",
       " -14834.1   -14834.1\n",
       " -20203.1   -20203.1\n",
       "   5781.82    5781.82\n",
       "  22452.7    22452.7\n",
       "      ⋮     \n",
       " -12271.6   -12271.6\n",
       "   5718.2     5718.2\n",
       "  -9557.47   -9557.47\n",
       " -12149.0   -12149.0\n",
       "  15954.4    15954.4\n",
       "   2491.68    2491.68\n",
       "   3878.5     3878.5\n",
       "  -1308.08   -1308.08\n",
       "  14682.4    14682.4\n",
       "  10457.0    10457.0\n",
       " -11036.1   -11036.1\n",
       "  -1376.77   -1376.77"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# autodiff grad wrt beta\n",
    "grad_storage = zeros(length(beta))\n",
    "@time Enzyme.autodiff(\n",
    "    Reverse, f, \n",
    "    Const(y), \n",
    "    Const(X), \n",
    "    Const(vechL), \n",
    "    Duplicated(beta, grad_storage), \n",
    "    Duplicated(storage, zero(storage))\n",
    ")\n",
    "\n",
    "# analytical grad\n",
    "@time true_grad = -X' * (y - X*beta);\n",
    "\n",
    "# check answers\n",
    "[true_grad grad_storage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000178 seconds (5 allocations: 96 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1250-element Vector{Float64}:\n",
       " 198.978438493076\n",
       "  -3.005542319968958\n",
       "  -0.0825790062683518\n",
       "   1.0329102936395052\n",
       "  -0.6551968970842044\n",
       "  -0.5547129753000754\n",
       "  -0.06393618603027097\n",
       "  -2.4727939986170666\n",
       "   1.3388437722889768\n",
       "   0.753763500042582\n",
       "  -1.757953505419059\n",
       "  -4.740126646347488\n",
       "   2.1198570600669284\n",
       "   ⋮\n",
       "  -4.861655513503298\n",
       " 200.05821860257626\n",
       "   0.6786321432915907\n",
       "   0.09306695899661727\n",
       "  -3.3575663500732804\n",
       "  -1.6330792230109883\n",
       "   1.7992931683189446\n",
       "   0.8905176836865358\n",
       "   1.5859112930741317\n",
       " 198.08436377096575\n",
       "   2.7783077526059974\n",
       "   0.41758512181906965"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# autodiff grad wrt L\n",
    "gradL = zeros((p * (p+1) >> 1))\n",
    "\n",
    "@time Enzyme.autodiff(\n",
    "    Reverse, f, \n",
    "    Const(y), \n",
    "    Const(X), \n",
    "    Duplicated(vechL, gradL), \n",
    "    Const(beta), \n",
    "    Const(storage)\n",
    ")\n",
    "gradL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rewrite objective to use only 1 input `par`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f (generic function with 3 methods)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# objective = 0.5 || y - X*beta ||^2 + ||vech(L)||^2\n",
    "function f(y, X, par, storage=zeros(size(X, 1)))\n",
    "    n, p = size(X)\n",
    "    beta = @view(par[1:p])\n",
    "    vechL = @view(par[p+1:end])\n",
    "    mul!(storage, X, beta)\n",
    "    storage .= y .- storage\n",
    "    return 0.5 * sum(abs2, storage) + sum(abs2, vechL)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000797 seconds (6 allocations: 78.266 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# autodiff grad wrt beta & vechL\n",
    "grad_storage = zeros(length(beta) + length(vechL))\n",
    "par = [beta; vechL]\n",
    "@time Enzyme.autodiff(\n",
    "    Reverse, f, \n",
    "    Const(y), \n",
    "    Const(X), \n",
    "    Duplicated(par, grad_storage), \n",
    "    Duplicated(storage, zero(storage))\n",
    ")\n",
    "grad_storage[1:p] ≈ true_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_storage[p+1:end] ≈ gradL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Iterating lower triangular matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vech! (generic function with 2 methods)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hua's code\n",
    "function vech(A::AbstractVecOrMat)\n",
    "    m, n = size(A, 1), size(A, 2)\n",
    "    vech!(similar(A, n * m - (n * (n - 1)) >> 1), A)\n",
    "end\n",
    "function vech!(v::AbstractVector, A::AbstractVecOrMat)\n",
    "    m, n = size(A, 1), size(A, 2)\n",
    "    idx = 1\n",
    "    @inbounds for j in 1:n, i in j:m\n",
    "        v[idx] = A[i, j]\n",
    "        idx += 1\n",
    "    end\n",
    "    v\n",
    "end\n",
    "\n",
    "# vech routines for cholesky factors\n",
    "function vech!(v::Vector{Float64}, L::Cholesky)\n",
    "    d = size(L, 1)\n",
    "    idx = 1\n",
    "    if L.uplo === 'L'\n",
    "        Ldata = L.factors\n",
    "        for j in 1:d, i in j:d\n",
    "            v[idx] = Ldata[i, j]\n",
    "            idx += 1\n",
    "        end\n",
    "    else\n",
    "        error(\"L.uplo !== 'L'! Construct cholesky factors using cholesky(x, :L)\")\n",
    "    end\n",
    "    return v\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all(L.L * Transpose(L.L) .≈ sigma) = true\n",
      "all(v1 .== vech(L.L)) = true\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m93.084 μs\u001b[22m\u001b[39m … \u001b[35m196.542 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m93.666 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m94.178 μs\u001b[22m\u001b[39m ± \u001b[32m  2.442 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m▂\u001b[39m▇\u001b[39m█\u001b[34m▇\u001b[39m\u001b[39m▄\u001b[32m▂\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\u001b[39m▂\u001b[39m▃\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\n",
       "  \u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▆\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▇\u001b[39m▇\u001b[39m▄\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▄\u001b[39m▅\u001b[39m▆\u001b[39m▅\u001b[39m▁\u001b[39m▄\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▆\u001b[39m \u001b[39m█\n",
       "  93.1 μs\u001b[90m       \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m       105 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data\n",
    "n = 1000\n",
    "x = randn(n, n)\n",
    "sigma = Symmetric(x'*x, :L)\n",
    "L = cholesky(sigma)\n",
    "\n",
    "# test cholesky\n",
    "@show all(L.L*Transpose(L.L) .≈ sigma)\n",
    "\n",
    "# check answers\n",
    "v1 = zeros((n * (n+1)) >> 1)\n",
    "vech!(v1, L)\n",
    "@show all(v1 .== vech(L.L))\n",
    "\n",
    "# timings\n",
    "@benchmark vech!($v1, $L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = @allocated vech!(v1, L);\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute $tr(\\Gamma)$ given $\\Gamma = LL'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.204814183212857"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = randn(5, 5)\n",
    "sigma = Symmetric(x'*x, :L)\n",
    "L = cholesky(sigma)\n",
    "\n",
    "tr(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.204814183212857"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearAlgebra.tr(L::Cholesky) = sum(abs2, vec(L.L))\n",
    "tr(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  32.737 ns (0 allocations: 0 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18.204814183212857"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function tr2(L::Cholesky)\n",
    "    s = zero(eltype(L.factors))\n",
    "    for Lij in LowerTriangular(L.factors)\n",
    "        s += abs2(Lij)\n",
    "    end\n",
    "    return s\n",
    "end\n",
    "@btime tr2($L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enzyme.jl on `Cholesky`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f (generic function with 2 methods)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function f(par::Vector, beta_storage::Vector, L_storage::Cholesky)\n",
    "    p = length(beta_storage)\n",
    "    beta_storage .= par[1:p]          # copy elements of `par` to `beta_storage`\n",
    "    un_vech!(L_storage, par[p+1:end]) # copy elements of `par` to `L_storage`\n",
    "    return f(beta_storage, L_storage)\n",
    "end\n",
    "function f(beta::Vector, L::Cholesky)\n",
    "    vechL = vech(L.L)\n",
    "    return 0.5 * (sum(abs2, beta) + sum(abs2, vechL))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0039780498943"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate obj\n",
    "beta = randn(5)\n",
    "x = randn(5, 5)\n",
    "L = cholesky(Symmetric(x'*x, :L))\n",
    "f(beta, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0039780498943"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par = [beta; vech(L.L)]\n",
    "beta .= 0       # destroy beta\n",
    "L.factors .= 0  # destroy L\n",
    "f(par, beta, L) # check objective is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20-element Vector{Float64}:\n",
       " -0.4328244198389204\n",
       "  1.7568333325595742\n",
       " -0.6032695430036253\n",
       " -0.35899553893071334\n",
       " -1.2367436525087776\n",
       "  4.437233082178529\n",
       "  0.2784219130963045\n",
       " -3.5871067916762884\n",
       "  0.23156177976363368\n",
       " -2.025996374320321\n",
       "  3.8996960669664724\n",
       " -1.500879349830168\n",
       "  2.113128000492451\n",
       " -0.8035957402607469\n",
       "  2.2656624712795845\n",
       " -2.4021367716300173\n",
       "  0.9931116778274178\n",
       "  1.065913083291953\n",
       " -1.3442657287242177\n",
       "  5.714082490206185"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# differentiate f(par, beta, L) with respect to par\n",
    "grad_storage = zeros(length(par))\n",
    "beta_storage = similar(beta)\n",
    "L_storage = cholesky(Symmetric(x'*x, :L))  # Dummy initialization\n",
    "Enzyme.autodiff(\n",
    "    Reverse, f, \n",
    "    Duplicated(par, grad_storage),\n",
    "    Duplicated(beta_storage, copy(beta_storage)), \n",
    "    Duplicated(L_storage, copy(L_storage))\n",
    ")\n",
    "grad_storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enzyme.jl on `struct`s\n",
    "\n",
    "+ In practice, data and intermediate variables are often stored in `struct`s\n",
    "    + Some fields are fixed, e.g. data\n",
    "    + Some fields are not, e.g. temporary storages\n",
    "+ Can we autodiff through these structs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "struct MyDataStruct\n",
    "    X::Matrix{Float64}\n",
    "    y::Vector{Float64}\n",
    "end\n",
    "\n",
    "struct MyStruct\n",
    "    data::MyDataStruct\n",
    "    beta::Vector{Float64}\n",
    "    L::Cholesky{Float64, Matrix{Float64}}\n",
    "    storage::Vector{Float64}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243607.98092798426"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function ols(par, data::MyDataStruct)\n",
    "    X = data.X\n",
    "    y = data.y\n",
    "    n, p = size(X)\n",
    "    beta = @view(par[1:p])\n",
    "    vechL = @view(par[p+1:end])\n",
    "    \n",
    "    # allocate all the temporary storages needed\n",
    "    L = cholesky(randn(p, p), check=false)\n",
    "    un_vech!(L, vechL)\n",
    "    r = y - X*beta\n",
    "    \n",
    "    return 0.5 * sum(abs2, r) + logdet(L)\n",
    "end\n",
    "\n",
    "# simulate data\n",
    "n = 10000\n",
    "p = 50\n",
    "X = randn(n, p)\n",
    "y = randn(n)\n",
    "beta = randn(p)\n",
    "storage = zeros(n)\n",
    "data = MyDataStruct(X, y)\n",
    "L = cholesky(Symmetric(X'*X, :L))\n",
    "s = MyStruct(data, beta, L, storage)\n",
    "par = [beta; vech(L.L)]\n",
    "ols(par, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000646 seconds (31 allocations: 372.531 KiB)\n",
      "  0.012192 seconds (9 allocations: 3.968 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50×2 Matrix{Float64}:\n",
       "  10875.8     10875.8\n",
       "   7397.42     7397.42\n",
       "  -3686.16    -3686.16\n",
       "  -6935.19    -6935.19\n",
       "   4511.6      4511.6\n",
       " -12729.9    -12729.9\n",
       "   3680.21     3680.21\n",
       "   -828.017    -828.017\n",
       "   1867.43     1867.43\n",
       "  14481.1     14481.1\n",
       "   4089.1      4089.1\n",
       "  11120.5     11120.5\n",
       "   1886.01     1886.01\n",
       "      ⋮      \n",
       " -11548.8    -11548.8\n",
       "  -4045.51    -4045.51\n",
       "   8216.68     8216.68\n",
       "   9122.9      9122.9\n",
       " -11029.6    -11029.6\n",
       " -15141.6    -15141.6\n",
       "   3569.41     3569.41\n",
       " -18680.5    -18680.5\n",
       "   3727.33     3727.33\n",
       "   7264.5      7264.5\n",
       "  19416.0     19416.0\n",
       "   9707.4      9707.4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# autodiff through struct\n",
    "grad_storage = zeros(length(par))\n",
    "@time Enzyme.autodiff(\n",
    "    Reverse, ols, \n",
    "    Duplicated(par, grad_storage), \n",
    "    Const(data),\n",
    ")\n",
    "\n",
    "# analytical grad\n",
    "@time true_grad = -X' * (y - X*beta);\n",
    "\n",
    "# check answers\n",
    "[true_grad[1:p] grad_storage[1:p]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1275-element Vector{Float64}:\n",
       " 0.020094456598901383\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " ⋮\n",
       " 0.0\n",
       " 0.0\n",
       " 0.020166284363359866\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.019983043808502302\n",
       " 0.0\n",
       " 0.0\n",
       " 0.020059291836159857\n",
       " 0.0\n",
       " 0.020048841239755876"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_storage[p+1:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enzyme.jl on MultivariateCopulaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using Distributions\n",
    "using GLM\n",
    "using Random\n",
    "using LinearAlgebra\n",
    "using Enzyme\n",
    "\n",
    "struct MultivariateCopulaData{T, D, L}\n",
    "    # data\n",
    "    Y::Matrix{T}    # n × d matrix of phenotypes, each row is a sample phenotype\n",
    "    X::Matrix{T}    # n × p matrix of non-genetic covariates, each row is a sample covariate\n",
    "    vecdist::Vector{D} # length d vector of marginal distributions for each phenotype\n",
    "    veclink::Vector{L} # length d vector of link functions for each phenotype's marginal distribution\n",
    "    # data dimension\n",
    "    n::Int # sample size\n",
    "    d::Int # number of phenotypes per sample\n",
    "    p::Int # number of (non-genetic) covariates per sample\n",
    "    m::Int # number of parameters in cholesky matrix L\n",
    "end\n",
    "\n",
    "# computes trace of Γ = L.L*L.L'\n",
    "function LinearAlgebra.tr(L::Cholesky)\n",
    "    s = zero(eltype(L.factors))\n",
    "    for Lij in LowerTriangular(L.factors)\n",
    "        s += abs2(Lij)\n",
    "    end\n",
    "    return s\n",
    "end\n",
    "\n",
    "# overwrites lower triangular part of `A` by `v`\n",
    "function un_vech!(A::AbstractMatrix, v::AbstractVector)\n",
    "    m, n = size(A, 1), size(A, 2)\n",
    "    idx = 1\n",
    "    for j in 1:n, i in j:m\n",
    "        A[i, j] = v[idx]\n",
    "        idx += 1\n",
    "    end\n",
    "    A\n",
    "end\n",
    "function un_vech!(L::Cholesky, v::AbstractVector)\n",
    "    un_vech!(L.factors, v)\n",
    "end\n",
    "\n",
    "function update_res!(data::MultivariateCopulaData, i::Int, std_res::Vector, η::Matrix, ϕ::Vector)\n",
    "    yi = @view(data.Y[i, :])\n",
    "    ηi = @view(η[i, :])\n",
    "    nuisance_counter = 1\n",
    "    for j in eachindex(yi)\n",
    "        μ_j = GLM.linkinv(data.veclink[j], ηi[j])\n",
    "        varμ_j = GLM.glmvar(data.vecdist[j], μ_j) # Note: for negative binomial, d.r is used\n",
    "        res_j = yi[j] - μ_j\n",
    "        std_res[j] = res_j / sqrt(varμ_j)\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "loglik_obs(::Bernoulli, y, μ, wt, ϕ) = wt*GLM.logpdf(Bernoulli(μ), y)\n",
    "loglik_obs(::Binomial, y, μ, wt, ϕ) = GLM.logpdf(Binomial(Int(wt), μ), Int(y*wt))\n",
    "loglik_obs(::Gamma, y, μ, wt, ϕ) = wt*GLM.logpdf(Gamma(inv(ϕ), μ*ϕ), y)\n",
    "loglik_obs(::InverseGaussian, y, μ, wt, ϕ) = wt*GLM.logpdf(InverseGaussian(μ, inv(ϕ)), y)\n",
    "loglik_obs(::Normal, y, μ, wt, ϕ) = wt*GLM.logpdf(Normal(μ, sqrt(abs(ϕ))), y)\n",
    "loglik_obs(::Poisson, y, μ, wt, ϕ) = logpdf(Poisson(μ), y)\n",
    "\n",
    "function component_loglikelihood(\n",
    "    data::MultivariateCopulaData, i::Int, η::Matrix, ϕ::Vector\n",
    "    )\n",
    "    yi = data.Y[i, :]\n",
    "    ηi = η[i, :]\n",
    "    logl = 0.0\n",
    "    for j in eachindex(yi)\n",
    "        dist = data.vecdist[j]\n",
    "        link = data.veclink[j]\n",
    "        μ_ij = GLM.linkinv(link, ηi[j])\n",
    "        logl += loglik_obs(dist, yi[j], μ_ij, 1.0, 1.0)\n",
    "    end\n",
    "    return logl::Float64\n",
    "end\n",
    "\n",
    "function loglikelihood!(\n",
    "    par::Vector, # first p*d are β, next m are for vech(L), next s are for nuisance\n",
    "    data::MultivariateCopulaData,\n",
    "    )\n",
    "    # allocate storages based on `par`\n",
    "    n, p, m, d = data.n, data.p, data.m, data.d\n",
    "    B = zeros(p, d)\n",
    "    copyto!(B, 1, par, 1, p * d)\n",
    "    L = cholesky(zeros(d, d), check=false)\n",
    "    un_vech!(L, @view(par[p * d + 1:p * d + m]))\n",
    "    ϕ = par[p * d + m + 1:end]\n",
    "    std_res = zeros(d)\n",
    "    η = zeros(n, d)\n",
    "    storage_d = zeros(d)    \n",
    "\n",
    "    # loglikelihood for each sample\n",
    "    mul!(η, data.X, B)\n",
    "    logl = zero(eltype(data.X))\n",
    "    for i in 1:data.n\n",
    "        # update res and std_res\n",
    "        update_res!(data, i, std_res, η, ϕ)\n",
    "        # loglikelihood term 2, i.e. sum sum ln(f_ij | β)\n",
    "        logl = component_loglikelihood(data, i, η, ϕ)\n",
    "        # loglikelihood term 1, i.e. -sum ln(1 + 0.5tr(Γ))\n",
    "        logl -= log(1 + 0.5tr(L))\n",
    "        # loglikelihood term 3 i.e. sum ln(1 + 0.5 r*Γ*r)\n",
    "        mul!(storage_d, Transpose(L.L), std_res)\n",
    "        logl += log(1 + 0.5sum(abs2, storage_d))\n",
    "    end\n",
    "    return logl\n",
    "end\n",
    "\n",
    "# create instance of MultivariateCopulaData\n",
    "n = 10000\n",
    "d = 5\n",
    "p = 10\n",
    "m = (d*(d+1)) >> 1\n",
    "X = randn(n, p)\n",
    "possible_distributions = [Bernoulli, Poisson, Normal]\n",
    "vecdist = rand(possible_distributions, d)\n",
    "veclink = [canonicallink(vecdist[j]()) for j in 1:d]\n",
    "if typeof(vecdist) <: Vector{UnionAll}\n",
    "    vecdist = [vecdist[j]() for j in 1:d]\n",
    "end\n",
    "\n",
    "# simulate Y\n",
    "Y = zeros(n, d)\n",
    "for j in 1:d\n",
    "    dist = vecdist[j]\n",
    "    for i in 1:n\n",
    "        Y[i, j] = rand(dist)\n",
    "    end\n",
    "end\n",
    "\n",
    "# vecdist = [Normal() for _ in 1:d]\n",
    "# veclink = [IdentityLink() for _ in 1:d]\n",
    "data = MultivariateCopulaData(Y, X, vecdist, veclink, n, d, p, m);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loglikelihood!(par, data) = -22.787101329064896\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "Enzyme execution failed.\nMismatched activity for:   %value_phi69 = phi {} addrspace(10)* [ %71, %idxend102 ], [ addrspacecast ({}* inttoptr (i64 4851506176 to {}*) to {} addrspace(10)*), %L198.preheader ] const val: {} addrspace(10)* addrspacecast ({}* inttoptr (i64 4851506176 to {}*) to {} addrspace(10)*)\n value=0.0 of type Float64\nYou may be using a constant variable as temporary storage for active memory (https://enzyme.mit.edu/julia/stable/faq/#Activity-of-temporary-storage). If not, please open an issue, and either rewrite this variable to not be conditionally active or use Enzyme.API.runtimeActivity!(true) as a workaround for now\n\nStacktrace:\n [1] getproperty\n   @ ./Base.jl:37\n [2] component_loglikelihood\n   @ ./In[26]:70\n",
     "output_type": "error",
     "traceback": [
      "Enzyme execution failed.\nMismatched activity for:   %value_phi69 = phi {} addrspace(10)* [ %71, %idxend102 ], [ addrspacecast ({}* inttoptr (i64 4851506176 to {}*) to {} addrspace(10)*), %L198.preheader ] const val: {} addrspace(10)* addrspacecast ({}* inttoptr (i64 4851506176 to {}*) to {} addrspace(10)*)\n value=0.0 of type Float64\nYou may be using a constant variable as temporary storage for active memory (https://enzyme.mit.edu/julia/stable/faq/#Activity-of-temporary-storage). If not, please open an issue, and either rewrite this variable to not be conditionally active or use Enzyme.API.runtimeActivity!(true) as a workaround for now\n\nStacktrace:\n [1] getproperty\n   @ ./Base.jl:37\n [2] component_loglikelihood\n   @ ./In[26]:70\n",
      "",
      "Stacktrace:",
      "  [1] throwerr(cstr::Cstring)",
      "    @ Enzyme.Compiler ~/.julia/packages/Enzyme/srACB/src/compiler.jl:1325",
      "  [2] getindex",
      "    @ ./essentials.jl:13 [inlined]",
      "  [3] component_loglikelihood",
      "    @ ./In[26]:70",
      "  [4] loglikelihood!",
      "    @ ./In[26]:100 [inlined]",
      "  [5] loglikelihood!",
      "    @ ./In[26]:0 [inlined]",
      "  [6] diffejulia_loglikelihood__9946_inner_1wrap",
      "    @ ./In[26]:0",
      "  [7] macro expansion",
      "    @ ~/.julia/packages/Enzyme/srACB/src/compiler.jl:5719 [inlined]",
      "  [8] enzyme_call",
      "    @ ~/.julia/packages/Enzyme/srACB/src/compiler.jl:5385 [inlined]",
      "  [9] CombinedAdjointThunk",
      "    @ ~/.julia/packages/Enzyme/srACB/src/compiler.jl:5264 [inlined]",
      " [10] autodiff",
      "    @ ~/.julia/packages/Enzyme/srACB/src/Enzyme.jl:291 [inlined]",
      " [11] autodiff",
      "    @ ~/.julia/packages/Enzyme/srACB/src/Enzyme.jl:315 [inlined]",
      " [12] autodiff(::ReverseMode{false, FFIABI, false}, ::typeof(loglikelihood!), ::Duplicated{Vector{Float64}}, ::Const{MultivariateCopulaData{Float64, UnivariateDistribution, Link}})",
      "    @ Enzyme ~/.julia/packages/Enzyme/srACB/src/Enzyme.jl:300",
      " [13] top-level scope",
      "    @ In[27]:7"
     ]
    }
   ],
   "source": [
    "# obj\n",
    "par = randn(p*d+m)\n",
    "@show loglikelihood!(par, data)\n",
    "\n",
    "# compute grad with Enzyme.jl\n",
    "grad_storage = zeros(length(par))\n",
    "Enzyme.autodiff(\n",
    "    Reverse, loglikelihood!,\n",
    "    Duplicated(par, grad_storage),\n",
    "    Const(data)\n",
    ")\n",
    "@show grad_storage[1:p*d]\n",
    "@show grad_storage[p*d+1:end];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.725361506249175"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Enzyme\n",
    "using Distributions\n",
    "using GLM\n",
    "using Random\n",
    "import GLM.loglik_obs\n",
    "\n",
    "struct MultiResponse{T, D, L}\n",
    "    y::Vector{T} # d by 1 vector\n",
    "    vecdist::Vector{D} # length d vector of marginal distributions, one for each y[i]\n",
    "    veclink::Vector{L} # length d vector of link functions, one for each y[i]\n",
    "end\n",
    "\n",
    "function component_loglikelihood(data::MultiResponse, η::Vector)\n",
    "    logl = 0.0\n",
    "    for j in eachindex(data.y)\n",
    "        dist = data.vecdist[j]\n",
    "        link = data.veclink[j]\n",
    "        μ_j = GLM.linkinv(link, η[j])\n",
    "        logl += loglik_obs(dist, y[j], μ_j, 1.0, 1.0)::Float64\n",
    "    end\n",
    "    return logl # type annotation prevents \"Duplicate return not supported\" error\n",
    "end\n",
    "\n",
    "# simulate data\n",
    "d = 10\n",
    "possible_distributions = [Bernoulli(), Poisson(), Normal()]\n",
    "vecdist = rand(possible_distributions, d)\n",
    "veclink = [canonicallink(vecdist[j]) for j in 1:d]\n",
    "y = zeros(d)\n",
    "for j in 1:d\n",
    "    dist = vecdist[j]\n",
    "    y[j] = rand(dist)\n",
    "end\n",
    "data = MultiResponse(y, vecdist, veclink)\n",
    "\n",
    "# eval obj\n",
    "η = randn(d)\n",
    "component_loglikelihood(data, η)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Float64}:\n",
       "  0.29876007665027543\n",
       "  0.5877054458897542\n",
       " -0.9098816118368459\n",
       "  0.6951580633937648\n",
       "  1.1104443083587645\n",
       "  0.2900115294652468\n",
       " -0.49009064441604466\n",
       " -0.14379185622547597\n",
       " -0.8386788794861753\n",
       " -2.2824990291522864"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute grad with Enzyme.jl\n",
    "grad_storage = zeros(length(η))\n",
    "Enzyme.autodiff(\n",
    "    Reverse, component_loglikelihood,\n",
    "    Const(data),\n",
    "    Duplicated(η, grad_storage)\n",
    ")\n",
    "grad_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-20.18930291405734"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Enzyme\n",
    "using Distributions\n",
    "using GLM\n",
    "using Random\n",
    "import GLM.loglik_obs\n",
    "\n",
    "function f(x::Vector, y, vecdist, veclink)\n",
    "    logl = 0.0\n",
    "    for j in eachindex(y)\n",
    "        dist = vecdist[j]\n",
    "        link = veclink[j]\n",
    "        μ_j = GLM.linkinv(link, x[j])\n",
    "        logl += loglik_obs(dist, y[j], μ_j, 1.0, 1.0)\n",
    "    end\n",
    "#     return logl::Float64 # type annotation prevents \"Duplicate return not supported\" error\n",
    "    return logl\n",
    "end\n",
    "\n",
    "# simulate data\n",
    "d = 10\n",
    "possible_distributions = [Bernoulli(), Poisson(), Normal()]\n",
    "vecdist = rand(possible_distributions, d)\n",
    "veclink = [canonicallink(vecdist[j]) for j in 1:d]\n",
    "y = [rand(dist) for dist in vecdist] |> Vector{Float64}\n",
    "\n",
    "# eval obj\n",
    "x = randn(d)\n",
    "f(x, y, vecdist, veclink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Float64}:\n",
       " -0.3309293141867698\n",
       "  1.0\n",
       " -0.32500156692931625\n",
       "  1.0\n",
       "  1.0\n",
       "  0.0\n",
       " -0.6129602928216916\n",
       "  4.0\n",
       "  1.0\n",
       "  2.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MethodInstance for f(::Vector{Float64}, ::Vector{Float64}, ::Vector{UnivariateDistribution}, ::Vector{Link})\n",
      "  from f(\u001b[90mx\u001b[39m::\u001b[1mVector\u001b[22m, \u001b[90my\u001b[39m, \u001b[90mvecdist\u001b[39m, \u001b[90mveclink\u001b[39m)\u001b[90m @\u001b[39m \u001b[90mMain\u001b[39m \u001b[90m\u001b[4mIn[37]:7\u001b[24m\u001b[39m\n",
      "Arguments\n",
      "  #self#\u001b[36m::Core.Const(f)\u001b[39m\n",
      "  x\u001b[36m::Vector{Float64}\u001b[39m\n",
      "  y\u001b[36m::Vector{Float64}\u001b[39m\n",
      "  vecdist\u001b[36m::Vector{UnivariateDistribution}\u001b[39m\n",
      "  veclink\u001b[36m::Vector{Link}\u001b[39m\n",
      "Locals\n",
      "  @_6\u001b[33m\u001b[1m::Union{Nothing, Tuple{Int64, Int64}}\u001b[22m\u001b[39m\n",
      "  logl\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "  j\u001b[36m::Int64\u001b[39m\n",
      "  μ_j\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "  link\u001b[91m\u001b[1m::Link\u001b[22m\u001b[39m\n",
      "  dist\u001b[91m\u001b[1m::UnivariateDistribution\u001b[22m\u001b[39m\n",
      "Body\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m1 ─\u001b[39m       (logl = 0.0)\n",
      "\u001b[90m│  \u001b[39m %2  = Main.eachindex(y)\u001b[36m::Base.OneTo{Int64}\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       (@_6 = Base.iterate(%2))\n",
      "\u001b[90m│  \u001b[39m %4  = (@_6 === nothing)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %5  = Base.not_int(%4)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m└──\u001b[39m       goto #4 if not %5\n",
      "\u001b[90m2 ┄\u001b[39m %7  = @_6\u001b[36m::Tuple{Int64, Int64}\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       (j = Core.getfield(%7, 1))\n",
      "\u001b[90m│  \u001b[39m %9  = Core.getfield(%7, 2)\u001b[36m::Int64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       (dist = Base.getindex(vecdist, j))\n",
      "\u001b[90m│  \u001b[39m       (link = Base.getindex(veclink, j))\n",
      "\u001b[90m│  \u001b[39m %12 = GLM.linkinv\u001b[36m::Core.Const(GLM.linkinv)\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %13 = link\u001b[91m\u001b[1m::Link\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %14 = Base.getindex(x, j)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       (μ_j = (%12)(%13, %14))\n",
      "\u001b[90m│  \u001b[39m %16 = logl\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %17 = dist\u001b[91m\u001b[1m::UnivariateDistribution\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %18 = Base.getindex(y, j)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %19 = μ_j\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %20 = Main.loglik_obs(%17, %18, %19, 1.0, 1.0)\u001b[91m\u001b[1m::Any\u001b[22m\u001b[39m\n",
      "\u001b[90m│  \u001b[39m       (logl = %16 + %20)\n",
      "\u001b[90m│  \u001b[39m       (@_6 = Base.iterate(%2, %9))\n",
      "\u001b[90m│  \u001b[39m %23 = (@_6 === nothing)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %24 = Base.not_int(%23)\u001b[36m::Bool\u001b[39m\n",
      "\u001b[90m└──\u001b[39m       goto #4 if not %24\n",
      "\u001b[90m3 ─\u001b[39m       goto #2\n",
      "\u001b[90m4 ┄\u001b[39m       return logl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@code_warntype f(x, y, vecdist, veclink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MethodInstance for GLM.loglik_obs(::Bernoulli{Float64}, ::Bool, ::Float64, ::Float64, ::Float64)\n",
      "  from loglik_obs(::\u001b[1mBernoulli\u001b[22m, \u001b[90my\u001b[39m, \u001b[90mμ\u001b[39m, \u001b[90mwt\u001b[39m, \u001b[90mϕ\u001b[39m)\u001b[90m @\u001b[39m \u001b[90mGLM\u001b[39m \u001b[90m~/.julia/packages/GLM/vM20T/src/\u001b[39m\u001b[90m\u001b[4mglmtools.jl:527\u001b[24m\u001b[39m\n",
      "Arguments\n",
      "  #self#\u001b[36m::Core.Const(GLM.loglik_obs)\u001b[39m\n",
      "  _\u001b[36m::Bernoulli{Float64}\u001b[39m\n",
      "  y\u001b[36m::Bool\u001b[39m\n",
      "  μ\u001b[36m::Float64\u001b[39m\n",
      "  wt\u001b[36m::Float64\u001b[39m\n",
      "  ϕ\u001b[36m::Float64\u001b[39m\n",
      "Body\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m1 ─\u001b[39m %1 = GLM.Bernoulli(μ)\u001b[36m::Bernoulli{Float64}\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %2 = GLM.logpdf(%1, y)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m│  \u001b[39m %3 = (wt * %2)\u001b[36m::Float64\u001b[39m\n",
      "\u001b[90m└──\u001b[39m      return %3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@code_warntype loglik_obs(Bernoulli(), true, 0.5, 1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Float64}:\n",
       " -0.7459511440030229\n",
       "  1.5542812469558198\n",
       " -0.08221167111277394\n",
       "  0.25824707444595857\n",
       " -1.6895010599606508\n",
       "  0.6905515909519077\n",
       " -1.7728286543952865\n",
       " -0.8917142836857651\n",
       "  0.7447009319673791\n",
       "  0.15132394231963636"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute grad with Enzyme.jl\n",
    "grad_storage = zeros(length(x))\n",
    "Enzyme.autodiff(\n",
    "    Reverse, f, Active, \n",
    "    Duplicated(x, grad_storage),\n",
    "    Const(y),\n",
    "    Const(vecdist),\n",
    "    Const(veclink),\n",
    ")\n",
    "grad_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.10.3",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
