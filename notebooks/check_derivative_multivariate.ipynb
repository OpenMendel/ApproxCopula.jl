{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using autodiff to check gradient/Hessians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling QuasiCopula [c47b6ae2-b804-4668-9957-eb588c99ffbc]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_make_snparray (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Revise\n",
    "using DataFrames, Random, GLM, QuasiCopula\n",
    "using ForwardDiff, Test, LinearAlgebra\n",
    "using LinearAlgebra: BlasReal, copytri!\n",
    "using ToeplitzMatrices\n",
    "using BenchmarkTools\n",
    "using SnpArrays\n",
    "using ForwardDiff\n",
    "# using MendelPlots\n",
    "ENV[\"COLUMNS\"] = 240\n",
    "\n",
    "\n",
    "BLAS.set_num_threads(1)\n",
    "Threads.nthreads()\n",
    "\n",
    "function simulate_random_snparray(s::Union{String, UndefInitializer}, n::Int64,\n",
    "    p::Int64; mafs::Vector{Float64}=zeros(Float64, p), min_ma::Int = 5)\n",
    "\n",
    "    #first simulate a random {0, 1, 2} matrix with each SNP drawn from Binomial(2, r[i])\n",
    "    A1 = BitArray(undef, n, p) \n",
    "    A2 = BitArray(undef, n, p) \n",
    "    for j in 1:p\n",
    "        minor_alleles = 0\n",
    "        maf = 0\n",
    "        while minor_alleles <= min_ma\n",
    "            maf = 0.5rand()\n",
    "            for i in 1:n\n",
    "                A1[i, j] = rand(Bernoulli(maf))\n",
    "                A2[i, j] = rand(Bernoulli(maf))\n",
    "            end\n",
    "            minor_alleles = sum(view(A1, :, j)) + sum(view(A2, :, j))\n",
    "        end\n",
    "        mafs[j] = maf\n",
    "    end\n",
    "\n",
    "    #fill the SnpArray with the corresponding x_tmp entry\n",
    "    return _make_snparray(s, A1, A2)\n",
    "end\n",
    "\n",
    "function _make_snparray(s::Union{String, UndefInitializer}, A1::BitArray, A2::BitArray)\n",
    "    n, p = size(A1)\n",
    "    x = SnpArray(s, n, p)\n",
    "    for i in 1:(n*p)\n",
    "        c = A1[i] + A2[i]\n",
    "        if c == 0\n",
    "            x[i] = 0x00\n",
    "        elseif c == 1\n",
    "            x[i] = 0x02\n",
    "        elseif c == 2\n",
    "            x[i] = 0x03\n",
    "        else\n",
    "            throw(MissingException(\"matrix shouldn't have missing values!\"))\n",
    "        end\n",
    "    end\n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×2 Matrix{Any}:\n",
       "  1.0      Bernoulli\n",
       " -1.26735  Normal\n",
       "  0.0      Poisson"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simulate data\n",
    "p = 5    # number of fixed effects, including intercept\n",
    "m = 2    # number of variance componentsac\n",
    "n = 1000 # number of sample\n",
    "d = 3    # number of phenotypes per sample\n",
    "q = 1000 # number of SNPs\n",
    "k = 0   # number of causal SNPs\n",
    "\n",
    "# sample d marginal distributions for each phenotype within samples\n",
    "Random.seed!(2022)\n",
    "possible_distributions = [Bernoulli, Poisson, Normal]\n",
    "vecdist = rand(possible_distributions, d)\n",
    "veclink = [canonicallink(vecdist[j]()) for j in 1:d]\n",
    "\n",
    "# simulate nongenetic coefficient and variance component params\n",
    "Random.seed!(2022)\n",
    "Btrue = rand(Uniform(-0.5, 0.5), p, d)\n",
    "θtrue = [0.1, 0.1]\n",
    "V1 = ones(d, d)\n",
    "V2 = Matrix(I, d, d)\n",
    "Γ = θtrue[1] * V1 + θtrue[2] * V2\n",
    "\n",
    "# simulate non-genetic design matrix\n",
    "Random.seed!(2022)\n",
    "X = [ones(n) randn(n, p - 1)]\n",
    "\n",
    "# simulate random SnpArray with q SNPs and randomly choose k SNPs to be causal\n",
    "Random.seed!(2022)\n",
    "G = simulate_random_snparray(undef, n, q)\n",
    "Gfloat = convert(Matrix{Float64}, G, center=true, scale=true)\n",
    "γtrue = zeros(q, d)\n",
    "causal_snps = sample(1:q, k, replace=false) |> sort\n",
    "for j in 1:d\n",
    "    γtrue[causal_snps, j] .= rand([-1, 1], k)\n",
    "end\n",
    "\n",
    "# sample phenotypes\n",
    "Y = zeros(n, d)\n",
    "y = Vector{Float64}(undef, d)\n",
    "for i in 1:n\n",
    "    Xi = X[i, :]\n",
    "    Gi = Gfloat[i, :]\n",
    "    η = Btrue' * Xi + γtrue' * Gi\n",
    "    vecd_tmp = Vector{UnivariateDistribution}(undef, d)\n",
    "    for j in 1:d\n",
    "        dist = vecdist[j]\n",
    "        μj = GLM.linkinv(canonicallink(dist()), η[j])\n",
    "        vecd_tmp[j] = dist(μj)\n",
    "    end\n",
    "    multivariate_dist = MultivariateMix(vecd_tmp, Γ)\n",
    "    res = Vector{Float64}(undef, d)\n",
    "    rand(multivariate_dist, y, res)\n",
    "    Y[i, :] .= y\n",
    "end\n",
    "\n",
    "# form model\n",
    "V = m == 1 ? [V1] : [V1, V2]\n",
    "qc_model = MultivariateCopulaVCModel(Y, X, V, vecdist, veclink)\n",
    "# initialize_model!(qc_model)\n",
    "\n",
    "[qc_model.Y[5, :] vecdist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is $\\nabla_\\beta res$ calculated correctly? \n",
    "\n",
    "We can check using ForwardDiff\n",
    "\n",
    "The function is \n",
    "\n",
    "$$res_{ij}(\\beta) = \\frac{y_{ij} - \\mu_{ij}}{\\sqrt{\\sigma_{ij}^2(\\beta)}}$$\n",
    "\n",
    "### Normal\n",
    "\n",
    "Assumes y, X are given. We calculate the residuals for just 1 sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resβ(yi, xi, vec(B)) = [-2.6474612012464025, 1.5524540653281953, 0.10154420769843686]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45×2 Matrix{Float64}:\n",
       " -1.0       -1.0\n",
       "  0.308648   0.308648\n",
       " -2.26841   -2.26841\n",
       " -0.316064  -0.316064\n",
       " -0.66411   -0.66411\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  ⋮         \n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       " -1.0       -1.0\n",
       "  0.308648   0.308648\n",
       " -2.26841   -2.26841\n",
       " -0.316064  -0.316064\n",
       " -0.66411   -0.66411"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data\n",
    "xi = qc_model.X[1, :] # p by 1\n",
    "yi = qc_model.Y[1, :] # d by 1\n",
    "\n",
    "# objective\n",
    "function resβ(y, x, vecB::AbstractVector)\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(IdentityLink(), η)\n",
    "    varμ = GLM.glmvar.(Normal(), μ)\n",
    "    return (y - μ) ./ sqrt.(varμ)\n",
    "end\n",
    "resβ(B::AbstractMatrix) = resβ(yi, xi, vec(B))\n",
    "resβ(B::AbstractVector) = resβ(yi, xi, B)\n",
    "\n",
    "B = randn(p, d)\n",
    "@show resβ(yi, xi, vec(B))\n",
    "\n",
    "# autodiff gradient\n",
    "∇resβ_autodiff = x -> ForwardDiff.jacobian(resβ, x)\n",
    "correct = ∇resβ_autodiff(vec(B))'\n",
    "\n",
    "# mathematical gradient\n",
    "function ∇resβ(x, y, vecB::AbstractVector{T}) where T\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(IdentityLink(), η)\n",
    "    varμ = GLM.glmvar.(Normal(), μ)\n",
    "    res = y - μ\n",
    "    std_res = res ./ sqrt.(varμ)\n",
    "    dμ = GLM.mueta.(IdentityLink(), η)\n",
    "    out = zeros(T, d*p, d)\n",
    "    @inbounds for j in 1:d\n",
    "        for k in 1:p\n",
    "            out[(j-1)*p + k, j] = QuasiCopula.update_∇res_ij(Normal(), x[k], \n",
    "                std_res[j], μ[j], dμ[j], varμ[j])\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "math_result = ∇resβ(xi, yi, vec(B))\n",
    "\n",
    "# compare results\n",
    "[vec(math_result) vec(correct)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resβ(yi, xi, vec(B)) = [-1.699553635820773, -2.9658266436544203, 2.621786668608018]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45×2 Matrix{Float64}:\n",
       " -0.849777  -0.849777\n",
       "  0.262282   0.262282\n",
       " -1.92764   -1.92764\n",
       " -0.268584  -0.268584\n",
       " -0.564345  -0.564345\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  ⋮         \n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       " -1.31089   -1.31089\n",
       "  0.404604   0.404604\n",
       " -2.97365   -2.97365\n",
       " -0.414327  -0.414327\n",
       " -0.870577  -0.870577"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data\n",
    "xi = qc_model.X[1, :] # p by 1\n",
    "yi = qc_model.Y[1, :] # d by 1\n",
    "\n",
    "# objective\n",
    "function resβ(y, x, vecB::AbstractVector)\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(LogitLink(), η)\n",
    "    varμ = GLM.glmvar.(Bernoulli(), μ)\n",
    "    return (y - μ) ./ sqrt.(varμ)\n",
    "end\n",
    "resβ(B::AbstractMatrix) = resβ(yi, xi, vec(B))\n",
    "resβ(B::AbstractVector) = resβ(yi, xi, B)\n",
    "\n",
    "B = randn(p, d)\n",
    "@show resβ(yi, xi, vec(B))\n",
    "\n",
    "# autodiff gradient\n",
    "∇resβ_autodiff = x -> ForwardDiff.jacobian(resβ, x)\n",
    "correct = ∇resβ_autodiff(vec(B))'\n",
    "\n",
    "# mathematical gradient\n",
    "function ∇resβ(x, y, vecB::AbstractVector{T}) where T\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(LogitLink(), η)\n",
    "    varμ = GLM.glmvar.(Bernoulli(), μ)\n",
    "    res = y - μ\n",
    "    std_res = res ./ sqrt.(varμ)\n",
    "    dμ = GLM.mueta.(LogitLink(), η)\n",
    "    out = zeros(T, d*p, d)\n",
    "    @inbounds for j in 1:d\n",
    "        for k in 1:p\n",
    "            out[(j-1)*p + k, j] = QuasiCopula.update_∇res_ij(Bernoulli(), x[k], \n",
    "                std_res[j], μ[j], dμ[j], varμ[j])\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "math_result = ∇resβ(xi, yi, vec(B))\n",
    "\n",
    "# compare results\n",
    "[vec(math_result) vec(correct)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resβ(yi, xi, vec(B)) = [-0.6311261621867231, -2.784614111314093, 18.689464943875688]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45×2 Matrix{Float64}:\n",
       "  -0.315563    -0.315563\n",
       "   0.0973979    0.0973979\n",
       "  -0.715827    -0.715827\n",
       "  -0.0997383   -0.0997383\n",
       "  -0.209568    -0.209568\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   ⋮          \n",
       "   0.0         -0.0\n",
       "   0.0         -0.0\n",
       "   0.0         -0.0\n",
       "   0.0         -0.0\n",
       "   0.0         -0.0\n",
       "   0.0         -0.0\n",
       "   0.0         -0.0\n",
       "  -9.39809     -9.39809\n",
       "   2.9007       2.9007\n",
       " -21.3187     -21.3187\n",
       "  -2.9704      -2.9704\n",
       "  -6.24136     -6.24136"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data\n",
    "xi = qc_model.X[1, :] # p by 1\n",
    "yi = qc_model.Y[1, :] # d by 1\n",
    "\n",
    "# objective\n",
    "function resβ(y, x, vecB::AbstractVector)\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(LogLink(), η)\n",
    "    varμ = GLM.glmvar.(Poisson(), μ)\n",
    "    return (y - μ) ./ sqrt.(varμ)\n",
    "end\n",
    "resβ(B::AbstractMatrix) = resβ(yi, xi, vec(B))\n",
    "resβ(B::AbstractVector) = resβ(yi, xi, B)\n",
    "\n",
    "B = randn(p, d)\n",
    "@show resβ(yi, xi, vec(B))\n",
    "\n",
    "# autodiff gradient\n",
    "∇resβ_autodiff = x -> ForwardDiff.jacobian(resβ, x)\n",
    "correct = ∇resβ_autodiff(vec(B))'\n",
    "\n",
    "# mathematical gradient\n",
    "function ∇resβ(x, y, vecB::AbstractVector{T}) where T\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(LogLink(), η)\n",
    "    varμ = GLM.glmvar.(Poisson(), μ)\n",
    "    res = y - μ\n",
    "    std_res = res ./ sqrt.(varμ)\n",
    "    dμ = GLM.mueta.(LogLink(), η)\n",
    "    out = zeros(T, d*p, d)\n",
    "    @inbounds for j in 1:d\n",
    "        for k in 1:p\n",
    "            out[(j-1)*p + k, j] = QuasiCopula.update_∇res_ij(Poisson(), x[k], \n",
    "                std_res[j], μ[j], dμ[j], varμ[j])\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "math_result = ∇resβ(xi, yi, vec(B))\n",
    "\n",
    "# compare results\n",
    "[vec(math_result) vec(correct)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check $\\nabla_{\\beta} L$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15×2 Matrix{Float64}:\n",
       " 0.292198    0.292198\n",
       " 0.201006    0.201006\n",
       " 0.194317    0.194317\n",
       " 0.0109756   0.0109756\n",
       " 0.349726    0.349726\n",
       " 0.185337    0.185337\n",
       " 0.127495    0.127495\n",
       " 0.123252    0.123252\n",
       " 0.00696167  0.00696167\n",
       " 0.221825    0.221825\n",
       " 4.75121     4.75121\n",
       " 3.2684      3.2684\n",
       " 3.15963     3.15963\n",
       " 0.178466    0.178466\n",
       " 5.68662     5.68662"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data\n",
    "i = 10\n",
    "xi = qc_model.X[i, :] # p by 1\n",
    "yi = qc_model.Y[i, :] # d by 1\n",
    "\n",
    "function A_mul_b!(c::AbstractVector{T}, A::AbstractMatrix, b::AbstractVector) where T\n",
    "    n, p = size(A)\n",
    "    fill!(c, zero(T))\n",
    "    for j in 1:p, i in 1:n\n",
    "        c[i] += A[i, j] * b[j]\n",
    "    end\n",
    "    return c\n",
    "end\n",
    "\n",
    "# loglikelihood for a single sample\n",
    "function loglikelihood(y, x, vecB::AbstractVector{T}, qc_model) where T\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    m = qc_model.m\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(qc_model.veclink, η)\n",
    "    varμ = GLM.glmvar.(qc_model.vecdist, μ)\n",
    "    res = y - μ\n",
    "    std_res = res ./ sqrt.(varμ)\n",
    "    dμ = GLM.mueta.(LogLink(), η)\n",
    "    storage_d = zeros(T, d)\n",
    "    q = zeros(T, m)\n",
    "    # GLM loglikelihood (term 2)\n",
    "    logl = zero(T)\n",
    "    @inbounds for j in eachindex(y)\n",
    "        logl += QuasiCopula.loglik_obs(qc_model.vecdist[j], y[j], μ[j], one(T), one(T))\n",
    "    end\n",
    "    # loglikelihood term 1 i.e. -sum ln(1 + 0.5tr(Γ(θ)))\n",
    "    tsum = dot(qc_model.θ, qc_model.t) # tsum = 0.5tr(Γ)\n",
    "    logl += -log(1 + tsum)\n",
    "    # loglikelihood term 3 i.e. sum ln(1 + 0.5 r*Γ*r)\n",
    "    @inbounds for k in 1:qc_model.m # loop over m variance components\n",
    "        mul!(storage_d, qc_model.V[k], std_res) # storage_d = V[k] * r\n",
    "#         if needgrad\n",
    "#             BLAS.gemv!('N', θ[k], qc.∇resβ, qc.storage_d, one(T), qc.∇vecB) # ∇β = ∇r*Γ*r\n",
    "#         end\n",
    "        q[k] = dot(std_res, storage_d) / 2 # q[k] = 0.5 r * V[k] * r\n",
    "    end\n",
    "    qsum = dot(qc_model.θ, q) # qsum = 0.5 r*Γ*r\n",
    "    logl += log(1 + qsum)\n",
    "    return logl\n",
    "end\n",
    "loglikelihood(B::AbstractMatrix) = loglikelihood(yi, xi, vec(B), qc_model)\n",
    "loglikelihood(B::AbstractVector) = loglikelihood(yi, xi, B, qc_model)\n",
    "\n",
    "# autodiff gradient\n",
    "logl_autodiff = x -> ForwardDiff.gradient(loglikelihood, x)\n",
    "correct = logl_autodiff(vec(B))\n",
    "\n",
    "# gradient from math\n",
    "qc_model.B .= B\n",
    "loglikelihood!(qc_model, true, false)\n",
    "\n",
    "[correct qc_model.data[i].∇vecB]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check $\\nabla_{\\theta} L$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       " -0.338581  -0.338581\n",
       " -0.208853  -0.208853"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data\n",
    "i = 5\n",
    "xi = qc_model.X[i, :] # p by 1\n",
    "yi = qc_model.Y[i, :] # d by 1\n",
    "\n",
    "function A_mul_b!(c::AbstractVector{T}, A::AbstractMatrix, b::AbstractVector) where T\n",
    "    n, p = size(A)\n",
    "    fill!(c, zero(T))\n",
    "    for j in 1:p, i in 1:n\n",
    "        c[i] += A[i, j] * b[j]\n",
    "    end\n",
    "    return c\n",
    "end\n",
    "\n",
    "# loglikelihood for a single sample\n",
    "function loglikelihood(y, x, θ::AbstractVector{T}, qc_model) where T\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    m = qc_model.m\n",
    "    B = qc_model.B\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(qc_model.veclink, η)\n",
    "    varμ = GLM.glmvar.(qc_model.vecdist, μ)\n",
    "    res = y - μ\n",
    "    std_res = res ./ sqrt.(varμ)\n",
    "    dμ = GLM.mueta.(LogLink(), η)\n",
    "    storage_d = zeros(T, d)\n",
    "    q = zeros(T, m)\n",
    "    # GLM loglikelihood (term 2)\n",
    "    logl = zero(T)\n",
    "    @inbounds for j in eachindex(y)\n",
    "        logl += QuasiCopula.loglik_obs(qc_model.vecdist[j], y[j], μ[j], one(T), one(T))\n",
    "    end\n",
    "    # loglikelihood term 1 i.e. -sum ln(1 + 0.5tr(Γ(θ)))\n",
    "    tsum = dot(θ, qc_model.t) # tsum = 0.5tr(Γ)\n",
    "    logl += -log(1 + tsum)\n",
    "    # loglikelihood term 3 i.e. sum ln(1 + 0.5 r*Γ*r)\n",
    "    @inbounds for k in 1:qc_model.m # loop over m variance components\n",
    "        mul!(storage_d, qc_model.V[k], std_res) # storage_d = V[k] * r\n",
    "#         if needgrad\n",
    "#             BLAS.gemv!('N', θ[k], qc.∇resβ, qc.storage_d, one(T), qc.∇vecB) # ∇β = ∇r*Γ*r\n",
    "#         end\n",
    "        q[k] = dot(std_res, storage_d) / 2 # q[k] = 0.5 r * V[k] * r\n",
    "    end\n",
    "    qsum = dot(θ, q) # qsum = 0.5 r*Γ*r\n",
    "    logl += log(1 + qsum)\n",
    "    return logl\n",
    "end\n",
    "loglikelihood(θ::AbstractVector) = loglikelihood(yi, xi, θ, qc_model)\n",
    "\n",
    "# autodiff gradient\n",
    "logl_autodiff = x -> ForwardDiff.gradient(loglikelihood, x)\n",
    "\n",
    "θ = rand(2)\n",
    "correct = logl_autodiff(θ)\n",
    "\n",
    "# gradient from math\n",
    "qc_model.θ .= θ\n",
    "loglikelihood!(qc_model, true, false)\n",
    "\n",
    "[correct qc_model.data[i].∇θ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
