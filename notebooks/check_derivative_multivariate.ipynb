{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using autodiff to check gradient/Hessians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling QuasiCopula [c47b6ae2-b804-4668-9957-eb588c99ffbc]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Revise\n",
    "using DataFrames, Random, GLM, QuasiCopula\n",
    "using ForwardDiff, LinearAlgebra\n",
    "using ToeplitzMatrices\n",
    "using BenchmarkTools\n",
    "using SnpArrays\n",
    "using ForwardDiff\n",
    "# using MendelPlots\n",
    "ENV[\"COLUMNS\"] = 240\n",
    "\n",
    "BLAS.set_num_threads(1)\n",
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000×4 Matrix{Float64}:\n",
       " 1.0  0.0    4.50974   -13.2746\n",
       " 0.0  1.0   -3.98109    -0.0887145\n",
       " 0.0  0.0   -5.50458     2.07538\n",
       " 1.0  1.0    4.26426   -10.6924\n",
       " 0.0  1.0   24.5941      8.02716\n",
       " 1.0  1.0   -1.9564     -9.11461\n",
       " 0.0  0.0   -2.24566     2.20784\n",
       " 1.0  0.0    4.09903     2.56163\n",
       " 1.0  1.0  -10.0673     15.4169\n",
       " 0.0  1.0    8.80747    -9.22851\n",
       " 0.0  0.0    3.62388   -12.995\n",
       " 1.0  0.0    4.78672     5.71522\n",
       " 0.0  0.0    0.592567   -9.55532\n",
       " ⋮                     \n",
       " 0.0  0.0    4.96956     2.98844\n",
       " 0.0  1.0   -6.87342     3.39349\n",
       " 0.0  0.0    8.20093     7.38732\n",
       " 0.0  1.0    9.62711     0.159582\n",
       " 1.0  0.0    6.9844      0.196057\n",
       " 1.0  0.0    7.41004     7.18247\n",
       " 0.0  0.0  -12.6771     -9.44202\n",
       " 0.0  0.0   -9.14128    -8.51743\n",
       " 0.0  1.0    0.15375     2.9925\n",
       " 0.0  0.0   26.5356      6.72687\n",
       " 0.0  1.0  -12.5527      2.99434\n",
       " 1.0  1.0   -3.4743      7.59344"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 0 # number of causal SNPs\n",
    "p = 3\n",
    "d = 4\n",
    "\n",
    "qc_model, G, Btrue, θtrue, γtrue, τtrue = simulate_multivariate_traits(\n",
    "    n = 5000, # sample size\n",
    "    p = p, # number of fixed effects, including intercept\n",
    "    m = 1, # number of variance components\n",
    "    d = d, # number of phenotypes\n",
    "    q = 1000, # number of SNPs\n",
    "    k = k, # number of causal SNPs\n",
    "    seed = 1,\n",
    "    τtrue = 0.01,\n",
    "    possible_distributions = [Bernoulli, Normal]\n",
    ")\n",
    "\n",
    "qc_model.Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare loglikelihood/gradient with longitudinal (single observation)\n",
    "\n",
    "To test this, we simulate a single multivariate gaussian Copula, and compare its loglikelihood with longitudinal gaussian copula with only 1 observation per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " 0.009775278594465796"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5000\n",
    "dist = Normal\n",
    "\n",
    "qc_model1, G, Btrue, θtrue, γtrue, τtrue = simulate_multivariate_traits(\n",
    "    n = n, # sample size\n",
    "    p = 3, # number of fixed effects, including intercept\n",
    "    m = 1, # number of variance components\n",
    "    d = 1, # number of phenotypes\n",
    "    q = 1000, # number of SNPs\n",
    "    k = k, # number of causal SNPs\n",
    "    seed = 123,\n",
    "    τtrue = 0.01,\n",
    "    possible_distributions = [dist]\n",
    ")\n",
    "\n",
    "qc_model2, G, Btrue, θtrue, γtrue, τtrue = simulate_longitudinal_traits(\n",
    "    n = n, # sample size\n",
    "    p = 3, # number of fixed effects, including intercept\n",
    "    m = 1, # number of variance components\n",
    "    d_max = 1, # number of observations per sample\n",
    "    q = 1000, # number of SNPs\n",
    "    k = k, # number of causal SNPs\n",
    "    seed = 123,\n",
    "    τtrue = 0.01,\n",
    "    y_distribution = dist,\n",
    ")\n",
    "\n",
    "# force longitudinal qc_model to share the same y/X/θ/τ as multivariate case\n",
    "qc_model2.β .= qc_model1.B\n",
    "for i in 1:n\n",
    "    copyto!(qc_model2.data[i].y, qc_model1.Y[i, :])\n",
    "    copyto!(qc_model2.data[i].X, qc_model1.X[i, :])\n",
    "#     copyto!(qc_model2.data[i].η, qc_model1.data[i].η)\n",
    "#     copyto!(qc_model2.data[i].μ, qc_model1.data[i].μ)\n",
    "#     copyto!(qc_model2.data[i].res, qc_model1.data[i].res)\n",
    "end\n",
    "qc_model2.θ .= qc_model1.θ\n",
    "qc_model1.ϕ .= qc_model2.τ\n",
    "# qc_model2.τ .= qc_model1.ϕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loglikelihood!(qc_model1, true, false) = -18930.965914285898\n",
      "loglikelihood!(qc_model2, true, false) = -18930.965914285898\n"
     ]
    }
   ],
   "source": [
    "@show loglikelihood!(qc_model1, true, false)\n",
    "@show loglikelihood!(qc_model2, true, false);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qc_model1.∇vecB = [-0.9563351570448801, -0.39865893560309557, 0.006400758476562237]\n",
      "qc_model2.∇β = [-0.9563351570448801, -0.3986589356030947, 0.006400758476562223]\n"
     ]
    }
   ],
   "source": [
    "@show qc_model1.∇vecB\n",
    "@show qc_model2.∇β;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qc_model1.∇θ = [-354.56438108432167]\n",
      "qc_model2.∇θ = [-354.56438108432167]\n"
     ]
    }
   ],
   "source": [
    "@show qc_model1.∇θ\n",
    "@show qc_model2.∇θ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qc_model1.∇ϕ = [66371.51597804665]\n",
      "qc_model2.∇τ = [66371.51597804665]\n"
     ]
    }
   ],
   "source": [
    "@show qc_model1.∇ϕ\n",
    "@show qc_model2.∇τ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is $\\nabla_\\beta res$ calculated correctly? \n",
    "\n",
    "We can check using ForwardDiff\n",
    "\n",
    "The function is \n",
    "\n",
    "$$res_{ij}(\\beta) = \\frac{y_{ij} - \\mu_{ij}}{\\sqrt{\\sigma_{ij}^2(\\beta)}}$$\n",
    "\n",
    "### Normal\n",
    "\n",
    "Assumes y, X are given. We calculate the (standardized) residuals for just 1 sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resβ(yi, xi, vec(B)) = [1.3884090998930962, -0.16822204638920013, 2.241041968786522, 0.04559962991400112]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48×2 Matrix{Float64}:\n",
       " -1.0        -1.0\n",
       " -0.100418   -0.100418\n",
       "  0.0470154   0.0470154\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0         0.0\n",
       "  ⋮          \n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       " -1.0        -1.0\n",
       " -0.100418   -0.100418\n",
       "  0.0470154   0.0470154"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data\n",
    "xi = qc_model.X[1, :] # p by 1\n",
    "yi = qc_model.Y[1, :] # d by 1\n",
    "\n",
    "# objective\n",
    "function resβ(y, x, vecB::AbstractVector)\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(IdentityLink(), η)\n",
    "    varμ = GLM.glmvar.(Normal(), μ)\n",
    "    return (y - μ) ./ sqrt.(varμ)\n",
    "end\n",
    "resβ(B::AbstractMatrix) = resβ(yi, xi, vec(B))\n",
    "resβ(B::AbstractVector) = resβ(yi, xi, B)\n",
    "\n",
    "B = randn(p, d)\n",
    "@show resβ(yi, xi, vec(B))\n",
    "\n",
    "# autodiff gradient\n",
    "∇resβ_autodiff = x -> ForwardDiff.jacobian(resβ, x)\n",
    "correct = ∇resβ_autodiff(vec(B))'\n",
    "\n",
    "# mathematical gradient\n",
    "function ∇resβ(x, y, vecB::AbstractVector{T}) where T\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(IdentityLink(), η)\n",
    "    varμ = GLM.glmvar.(Normal(), μ)\n",
    "    res = y - μ\n",
    "    std_res = res ./ sqrt.(varμ)\n",
    "    dμ = GLM.mueta.(IdentityLink(), η)\n",
    "    out = zeros(T, d*p, d)\n",
    "    @inbounds for j in 1:d\n",
    "        for k in 1:p\n",
    "            out[(j-1)*p + k, j] = QuasiCopula.update_∇res_ij(Normal(), x[k], \n",
    "                std_res[j], μ[j], dμ[j], varμ[j])\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "math_result = ∇resβ(xi, yi, vec(B))\n",
    "\n",
    "# compare results\n",
    "[vec(math_result) vec(correct)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resβ(yi, xi, vec(B)) = [-1.699553635820773, -2.9658266436544203, 2.621786668608018]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45×2 Matrix{Float64}:\n",
       " -0.849777  -0.849777\n",
       "  0.262282   0.262282\n",
       " -1.92764   -1.92764\n",
       " -0.268584  -0.268584\n",
       " -0.564345  -0.564345\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  ⋮         \n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       " -1.31089   -1.31089\n",
       "  0.404604   0.404604\n",
       " -2.97365   -2.97365\n",
       " -0.414327  -0.414327\n",
       " -0.870577  -0.870577"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data\n",
    "xi = qc_model.X[1, :] # p by 1\n",
    "yi = qc_model.Y[1, :] # d by 1\n",
    "\n",
    "# objective\n",
    "function resβ(y, x, vecB::AbstractVector)\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(LogitLink(), η)\n",
    "    varμ = GLM.glmvar.(Bernoulli(), μ)\n",
    "    return (y - μ) ./ sqrt.(varμ)\n",
    "end\n",
    "resβ(B::AbstractMatrix) = resβ(yi, xi, vec(B))\n",
    "resβ(B::AbstractVector) = resβ(yi, xi, B)\n",
    "\n",
    "B = randn(p, d)\n",
    "@show resβ(yi, xi, vec(B))\n",
    "\n",
    "# autodiff gradient\n",
    "∇resβ_autodiff = x -> ForwardDiff.jacobian(resβ, x)\n",
    "correct = ∇resβ_autodiff(vec(B))'\n",
    "\n",
    "# mathematical gradient\n",
    "function ∇resβ(x, y, vecB::AbstractVector{T}) where T\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(LogitLink(), η)\n",
    "    varμ = GLM.glmvar.(Bernoulli(), μ)\n",
    "    res = y - μ\n",
    "    std_res = res ./ sqrt.(varμ)\n",
    "    dμ = GLM.mueta.(LogitLink(), η)\n",
    "    out = zeros(T, d*p, d)\n",
    "    @inbounds for j in 1:d\n",
    "        for k in 1:p\n",
    "            out[(j-1)*p + k, j] = QuasiCopula.update_∇res_ij(Bernoulli(), x[k], \n",
    "                std_res[j], μ[j], dμ[j], varμ[j])\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "math_result = ∇resβ(xi, yi, vec(B))\n",
    "\n",
    "# compare results\n",
    "[vec(math_result) vec(correct)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resβ(yi, xi, vec(B)) = [-0.6311261621867231, -2.784614111314093, 18.689464943875688]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45×2 Matrix{Float64}:\n",
       "  -0.315563    -0.315563\n",
       "   0.0973979    0.0973979\n",
       "  -0.715827    -0.715827\n",
       "  -0.0997383   -0.0997383\n",
       "  -0.209568    -0.209568\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   ⋮          \n",
       "   0.0         -0.0\n",
       "   0.0         -0.0\n",
       "   0.0         -0.0\n",
       "   0.0         -0.0\n",
       "   0.0         -0.0\n",
       "   0.0         -0.0\n",
       "   0.0         -0.0\n",
       "  -9.39809     -9.39809\n",
       "   2.9007       2.9007\n",
       " -21.3187     -21.3187\n",
       "  -2.9704      -2.9704\n",
       "  -6.24136     -6.24136"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data\n",
    "xi = qc_model.X[1, :] # p by 1\n",
    "yi = qc_model.Y[1, :] # d by 1\n",
    "\n",
    "# objective\n",
    "function resβ(y, x, vecB::AbstractVector)\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(LogLink(), η)\n",
    "    varμ = GLM.glmvar.(Poisson(), μ)\n",
    "    return (y - μ) ./ sqrt.(varμ)\n",
    "end\n",
    "resβ(B::AbstractMatrix) = resβ(yi, xi, vec(B))\n",
    "resβ(B::AbstractVector) = resβ(yi, xi, B)\n",
    "\n",
    "B = randn(p, d)\n",
    "@show resβ(yi, xi, vec(B))\n",
    "\n",
    "# autodiff gradient\n",
    "∇resβ_autodiff = x -> ForwardDiff.jacobian(resβ, x)\n",
    "correct = ∇resβ_autodiff(vec(B))'\n",
    "\n",
    "# mathematical gradient\n",
    "function ∇resβ(x, y, vecB::AbstractVector{T}) where T\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(LogLink(), η)\n",
    "    varμ = GLM.glmvar.(Poisson(), μ)\n",
    "    res = y - μ\n",
    "    std_res = res ./ sqrt.(varμ)\n",
    "    dμ = GLM.mueta.(LogLink(), η)\n",
    "    out = zeros(T, d*p, d)\n",
    "    @inbounds for j in 1:d\n",
    "        for k in 1:p\n",
    "            out[(j-1)*p + k, j] = QuasiCopula.update_∇res_ij(Poisson(), x[k], \n",
    "                std_res[j], μ[j], dμ[j], varμ[j])\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "math_result = ∇resβ(xi, yi, vec(B))\n",
    "\n",
    "# compare results\n",
    "[vec(math_result) vec(correct)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check $\\nabla_{\\beta} L$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12×2 Matrix{Float64}:\n",
       "  -0.125531    -0.125531\n",
       "   0.237507     0.237507\n",
       "   0.0716134    0.0716134\n",
       "   0.554527     0.554527\n",
       "  -1.04917     -1.04917\n",
       "  -0.316348    -0.316348\n",
       "   7.83048      7.83048\n",
       " -14.8154     -14.8154\n",
       "  -4.46715     -4.46715\n",
       "  -9.23224     -9.23224\n",
       "  17.4675      17.4675\n",
       "   5.26683      5.26683"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data\n",
    "i = 10\n",
    "xi = qc_model.X[i, :] # p by 1\n",
    "yi = qc_model.Y[i, :] # d by 1\n",
    "\n",
    "function A_mul_b!(c::AbstractVector{T}, A::AbstractMatrix, b::AbstractVector) where T\n",
    "    n, p = size(A)\n",
    "    fill!(c, zero(T))\n",
    "    for j in 1:p, i in 1:n\n",
    "        c[i] += A[i, j] * b[j]\n",
    "    end\n",
    "    return c\n",
    "end\n",
    "\n",
    "# loglikelihood for a single sample\n",
    "function loglikelihood(y, x, vecB::AbstractVector{T}, qc_model) where T\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    m = qc_model.m\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(qc_model.veclink, η)\n",
    "    varμ = GLM.glmvar.(qc_model.vecdist, μ)\n",
    "    res = y - μ\n",
    "    std_res = zeros(T, length(res))\n",
    "    nuisance_counter = 1\n",
    "    for j in eachindex(res)\n",
    "        if typeof(qc_model.vecdist[j]) <: Normal\n",
    "            τ = abs(qc_model.ϕ[nuisance_counter])\n",
    "            std_res[j] = res[j] * sqrt(τ)\n",
    "            nuisance_counter += 1\n",
    "        else\n",
    "            std_res[j] = res[j] / sqrt(varμ[j])\n",
    "        end\n",
    "    end\n",
    "    storage_d = zeros(T, d)\n",
    "    q = zeros(T, m)\n",
    "    # GLM loglikelihood (term 2)\n",
    "    nuisance_counter = 1\n",
    "    logl = zero(T)\n",
    "    @inbounds for j in eachindex(y)\n",
    "        dist = qc_model.vecdist[j]\n",
    "        if typeof(dist) <: Normal\n",
    "            τ = inv(qc_model.ϕ[nuisance_counter])\n",
    "            logl += QuasiCopula.loglik_obs(dist, y[j], μ[j], one(T), τ)\n",
    "            nuisance_counter += 1\n",
    "        else\n",
    "            logl += QuasiCopula.loglik_obs(dist, y[j], μ[j], one(T), one(T))\n",
    "        end\n",
    "    end\n",
    "    # loglikelihood term 1 i.e. -sum ln(1 + 0.5tr(Γ(θ)))\n",
    "    tsum = dot(qc_model.θ, qc_model.t) # tsum = 0.5tr(Γ)\n",
    "    logl += -log(1 + tsum)\n",
    "    # loglikelihood term 3 i.e. sum ln(1 + 0.5 r*Γ*r)\n",
    "    @inbounds for k in 1:qc_model.m # loop over m variance components\n",
    "        mul!(storage_d, qc_model.V[k], std_res) # storage_d = V[k] * r\n",
    "        q[k] = dot(std_res, storage_d) / 2 # q[k] = 0.5 r * V[k] * r\n",
    "    end\n",
    "    qsum = dot(qc_model.θ, q) # qsum = 0.5 r*Γ*r\n",
    "    logl += log(1 + qsum)\n",
    "    return logl\n",
    "end\n",
    "loglikelihood(B::AbstractMatrix) = loglikelihood(yi, xi, vec(B), qc_model)\n",
    "loglikelihood(B::AbstractVector) = loglikelihood(yi, xi, B, qc_model)\n",
    "\n",
    "qc_model.ϕ .= 1.1\n",
    "\n",
    "# autodiff gradient\n",
    "Random.seed!(2023)\n",
    "B = randn(p, d)\n",
    "logl_autodiff = x -> ForwardDiff.gradient(loglikelihood, x)\n",
    "correct = logl_autodiff(vec(B))\n",
    "\n",
    "# gradient from math\n",
    "qc_model.B .= B\n",
    "loglikelihood!(qc_model, true, false)\n",
    "\n",
    "[correct qc_model.data[i].∇vecB]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check $\\nabla_{\\theta} L$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×2 Matrix{Float64}:\n",
       " 3.55748  3.55748"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data\n",
    "i = 5\n",
    "xi = qc_model.X[i, :] # p by 1\n",
    "yi = qc_model.Y[i, :] # d by 1\n",
    "\n",
    "function A_mul_b!(c::AbstractVector{T}, A::AbstractMatrix, b::AbstractVector) where T\n",
    "    n, p = size(A)\n",
    "    fill!(c, zero(T))\n",
    "    for j in 1:p, i in 1:n\n",
    "        c[i] += A[i, j] * b[j]\n",
    "    end\n",
    "    return c\n",
    "end\n",
    "\n",
    "# loglikelihood for a single sample\n",
    "function loglikelihood(y, x, θ::AbstractVector{T}, qc_model) where T\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    m = qc_model.m\n",
    "    B = qc_model.B\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(qc_model.veclink, η)\n",
    "    varμ = GLM.glmvar.(qc_model.vecdist, μ)\n",
    "    res = y - μ\n",
    "    std_res = zeros(T, length(res))\n",
    "    nuisance_counter = 1\n",
    "    for j in eachindex(res)\n",
    "        if typeof(qc_model.vecdist[j]) <: Normal\n",
    "            τ = abs(qc_model.ϕ[nuisance_counter])\n",
    "            std_res[j] = res[j] * sqrt(τ)\n",
    "            nuisance_counter += 1\n",
    "        else\n",
    "            std_res[j] = res[j] / sqrt(varμ[j])\n",
    "        end\n",
    "    end\n",
    "    storage_d = zeros(T, d)\n",
    "    q = zeros(T, m)\n",
    "    # GLM loglikelihood (term 2)\n",
    "    logl = zero(T)\n",
    "    @inbounds for j in eachindex(y)\n",
    "        logl += QuasiCopula.loglik_obs(qc_model.vecdist[j], y[j], μ[j], one(T), one(T))\n",
    "    end\n",
    "    # loglikelihood term 1 i.e. -sum ln(1 + 0.5tr(Γ(θ)))\n",
    "    tsum = dot(θ, qc_model.t) # tsum = 0.5tr(Γ)\n",
    "    logl += -log(1 + tsum)\n",
    "    # loglikelihood term 3 i.e. sum ln(1 + 0.5 r*Γ*r)\n",
    "    @inbounds for k in 1:qc_model.m # loop over m variance components\n",
    "        mul!(storage_d, qc_model.V[k], std_res) # storage_d = V[k] * r\n",
    "        q[k] = dot(std_res, storage_d) / 2 # q[k] = 0.5 r * V[k] * r\n",
    "    end\n",
    "    qsum = dot(θ, q) # qsum = 0.5 r*Γ*r\n",
    "    logl += log(1 + qsum)\n",
    "    return logl\n",
    "end\n",
    "loglikelihood(θ::AbstractVector) = loglikelihood(yi, xi, θ, qc_model)\n",
    "\n",
    "# autodiff gradient\n",
    "logl_autodiff = x -> ForwardDiff.gradient(loglikelihood, x)\n",
    "\n",
    "θ = [rand()]\n",
    "correct = logl_autodiff(θ)\n",
    "\n",
    "# gradient from math\n",
    "qc_model.θ .= θ\n",
    "loglikelihood!(qc_model, true, false)\n",
    "\n",
    "[correct qc_model.data[i].∇θ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Check $\\nabla_{\\phi} L$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       " 1.39017   2.41363\n",
       " 0.585787  2.41363"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data\n",
    "i = 5\n",
    "xi = qc_model.X[i, :] # p by 1\n",
    "yi = qc_model.Y[i, :] # d by 1\n",
    "\n",
    "function A_mul_b!(c::AbstractVector{T}, A::AbstractMatrix, b::AbstractVector) where T\n",
    "    n, p = size(A)\n",
    "    fill!(c, zero(T))\n",
    "    for j in 1:p, i in 1:n\n",
    "        c[i] += A[i, j] * b[j]\n",
    "    end\n",
    "    return c\n",
    "end\n",
    "\n",
    "# loglikelihood for a single sample\n",
    "function loglikelihood(y, x, ϕ::AbstractVector{T}, qc_model) where T\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    m = qc_model.m\n",
    "    B = qc_model.B\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(qc_model.veclink, η)\n",
    "    varμ = GLM.glmvar.(qc_model.vecdist, μ)\n",
    "    res = y - μ\n",
    "    std_res = zeros(T, length(res))\n",
    "    nuisance_counter = 1\n",
    "    for j in eachindex(res)\n",
    "        if typeof(qc_model.vecdist[j]) <: Normal\n",
    "            τ = abs(ϕ[nuisance_counter])\n",
    "            std_res[j] = res[j] * sqrt(τ)\n",
    "            nuisance_counter += 1\n",
    "        else\n",
    "            std_res[j] = res[j] / sqrt(varμ[j])\n",
    "        end\n",
    "    end\n",
    "    storage_d = zeros(T, d)\n",
    "    q = zeros(T, m)\n",
    "    # GLM loglikelihood (term 2)\n",
    "    logl = zero(T)\n",
    "    @inbounds for j in eachindex(y)\n",
    "        logl += QuasiCopula.loglik_obs(qc_model.vecdist[j], y[j], μ[j], one(T), one(T))\n",
    "    end\n",
    "    # loglikelihood term 1 i.e. -sum ln(1 + 0.5tr(Γ(θ)))\n",
    "    tsum = dot(qc_model.θ, qc_model.t) # tsum = 0.5tr(Γ)\n",
    "    logl += -log(1 + tsum)\n",
    "    # loglikelihood term 3 i.e. sum ln(1 + 0.5 r*Γ*r)\n",
    "    @inbounds for k in 1:qc_model.m # loop over m variance components\n",
    "        mul!(storage_d, qc_model.V[k], std_res) # storage_d = V[k] * r\n",
    "        q[k] = dot(std_res, storage_d) / 2 # q[k] = 0.5 r * V[k] * r\n",
    "    end\n",
    "    qsum = dot(qc_model.θ, q) # qsum = 0.5 r*Γ*r\n",
    "    logl += log(1 + qsum)\n",
    "    return logl\n",
    "end\n",
    "loglikelihood(ϕ::AbstractVector) = loglikelihood(yi, xi, ϕ, qc_model)\n",
    "\n",
    "# autodiff gradient\n",
    "logl_autodiff = x -> ForwardDiff.gradient(loglikelihood, x)\n",
    "\n",
    "ϕ = rand(2)\n",
    "correct = logl_autodiff(ϕ)\n",
    "\n",
    "# gradient from math\n",
    "qc_model.ϕ .= ϕ\n",
    "loglikelihood!(qc_model, true, false)\n",
    "\n",
    "[correct qc_model.data[i].∇ϕ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
