{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using autodiff to check gradient/Hessians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Revise\n",
    "using DataFrames, Random, GLM, QuasiCopula\n",
    "using ForwardDiff, LinearAlgebra\n",
    "using ToeplitzMatrices\n",
    "using BenchmarkTools\n",
    "using SnpArrays\n",
    "using ForwardDiff\n",
    "import QuasiCopula.At_mul_b!\n",
    "import QuasiCopula.A_mul_b!\n",
    "# using MendelPlots\n",
    "ENV[\"COLUMNS\"] = 240\n",
    "\n",
    "BLAS.set_num_threads(1)\n",
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000×4 Matrix{Float64}:\n",
       " 0.0  -10.8406      0.0    3.52788\n",
       " 0.0  -12.1464      0.0    3.48389\n",
       " 4.0   10.5989      0.0    6.47314\n",
       " 2.0   -8.76693     0.0   17.1554\n",
       " 1.0  -16.6232      0.0  -17.4332\n",
       " 0.0   -7.19898     0.0    3.38804\n",
       " 3.0    1.96538     1.0    8.68306\n",
       " 3.0    3.30507     1.0   21.3263\n",
       " 0.0   -3.57901     1.0   -4.05763\n",
       " 3.0    2.31113     1.0   11.8259\n",
       " 3.0   -4.11159     0.0   -6.89613\n",
       " 3.0   -1.34987     1.0   -3.61462\n",
       " 0.0  -10.1702      1.0  -17.9964\n",
       " ⋮                       \n",
       " 1.0   10.7987      0.0   11.739\n",
       " 2.0    7.16974     1.0   -6.80915\n",
       " 7.0   15.6318      1.0    0.424624\n",
       " 2.0   -8.42642     0.0  -12.8363\n",
       " 1.0   11.5634      1.0   10.6037\n",
       " 6.0    0.0723925   1.0   -8.55484\n",
       " 1.0  -16.0325      1.0   -6.60887\n",
       " 0.0  -12.0291      0.0   -8.0167\n",
       " 1.0    0.00185311  0.0  -10.5867\n",
       " 1.0   13.5349      0.0  -22.1925\n",
       " 3.0  -25.1235      0.0   -4.59481\n",
       " 0.0    5.89153     0.0   -4.76879"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 0 # number of causal SNPs\n",
    "\n",
    "qc_model, G, Btrue, θtrue, γtrue, τtrue = simulate_multivariate_traits(\n",
    "    n = 5000, # sample size\n",
    "    p = 3, # number of fixed effects, including intercept\n",
    "    m = 2, # number of variance components\n",
    "    d = 4, # number of phenotypes\n",
    "    q = 1000, # number of SNPs\n",
    "    k = k, # number of causal SNPs\n",
    "    seed = 6,\n",
    "    τtrue = 0.01,\n",
    "    possible_distributions = [Normal, Bernoulli, Poisson],\n",
    "    θtrue = [0.7, 0.1]\n",
    ")\n",
    "\n",
    "qc_model.Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loglikelihood function friendly to autodiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loglikelihood (generic function with 2 methods)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loglikelihood(\n",
    "    par::AbstractVector{T}, # length pd+m+s+d. m is num of VCs, s is num of nuisance params, d is SNP effect on d phenotypes\n",
    "    qc_model::MultivariateCopulaVCModel, # fitted null model\n",
    "#     z::AbstractVector # n × 1 genotype vector\n",
    "    ) where T\n",
    "    n = length(qc_model.data)\n",
    "#     n == length(z) || error(\"Expected n == length(z)\")\n",
    "\n",
    "    # parameters\n",
    "    p, d = size(qc_model.B)\n",
    "    m = qc_model.m                     # number of variance components\n",
    "    s = qc_model.s                     # number of nuisance parameters \n",
    "    B = reshape(par[1:p*d], p, d)      # nongenetic covariates\n",
    "    θ = par[p*d+1:p*d+m]               # vc parameters\n",
    "    τ = par[p*d+m+1:p*d+m+s]           # nuisance parameters\n",
    "#     γ = par[end-d+1:end]               # genetic beta\n",
    "\n",
    "    # storages friendly to autodiff\n",
    "    ηstore = zeros(T, d)\n",
    "    μstore = zeros(T, d)\n",
    "    varμstore = zeros(T, d)\n",
    "    resstore = zeros(T, d)\n",
    "    std_resstore = zeros(T, d)\n",
    "    storage_d = zeros(T, d)\n",
    "    qstore = zeros(T, m)\n",
    "\n",
    "    logl = 0.0\n",
    "    for i in 1:n\n",
    "        # data for sample i\n",
    "        xi = @view(qc_model.X[i, :])\n",
    "        yi = @view(qc_model.Y[i, :])\n",
    "        # update η, μ, res, to include effect of SNP\n",
    "        At_mul_b!(ηstore, B, xi)\n",
    "#         ηstore .+= γ .* z[i]\n",
    "        μstore .= GLM.linkinv.(qc_model.veclink, ηstore)\n",
    "        varμstore .= GLM.glmvar.(qc_model.vecdist, μstore)\n",
    "        resstore .= yi .- μstore\n",
    "        # update std_res (gaussian case needs separate treatment)\n",
    "        nuisance_counter = 1\n",
    "        for j in eachindex(std_resstore)\n",
    "            if typeof(qc_model.vecdist[j]) <: Normal\n",
    "                τj = abs(τ[nuisance_counter])\n",
    "                std_resstore[j] = resstore[j] * sqrt(τj)\n",
    "                nuisance_counter += 1\n",
    "            else\n",
    "                std_resstore[j] = resstore[j] / sqrt(varμstore[j])\n",
    "            end\n",
    "        end\n",
    "#         std_resstore .= resstore ./ sqrt.(varμstore)\n",
    "        # GLM loglikelihood (term 2)\n",
    "        nuisance_counter = 1\n",
    "        for j in eachindex(yi)\n",
    "            dist = qc_model.vecdist[j]\n",
    "            if typeof(dist) <: Normal\n",
    "                τj = inv(τ[nuisance_counter])\n",
    "                logl += QuasiCopula.loglik_obs(dist, yi[j], μstore[j], one(T), τj)\n",
    "                nuisance_counter += 1\n",
    "            else\n",
    "                logl += QuasiCopula.loglik_obs(dist, yi[j], μstore[j], one(T), one(T))\n",
    "            end\n",
    "        end\n",
    "        # loglikelihood term 1 i.e. -sum ln(1 + 0.5tr(Γ(θ)))\n",
    "        tsum = dot(θ, qc_model.t) # tsum = 0.5tr(Γ)\n",
    "        logl += -log(1 + tsum)\n",
    "        # loglikelihood term 3 i.e. sum ln(1 + 0.5 r*Γ*r)\n",
    "        @inbounds for k in 1:qc_model.m # loop over m variance components\n",
    "            mul!(storage_d, qc_model.V[k], std_resstore) # storage_d = V[k] * r\n",
    "            qstore[k] = dot(std_resstore, storage_d) / 2 # q[k] = 0.5 r * V[k] * r\n",
    "        end\n",
    "        qsum = dot(θ, qstore) # qsum = 0.5 r*Γ*r\n",
    "        logl += log(1 + qsum)\n",
    "    end\n",
    "\n",
    "    return logl\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check autodiff loglikelihood returns same result as closed-form loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loglikelihood!(qc_model, false, false) = -211482.41236799132\n",
      "loglikelihood(par, qc_model) = -211482.4123679753\n"
     ]
    }
   ],
   "source": [
    "qc_model.θ .= rand(m)\n",
    "qc_model.ϕ .= rand(2)\n",
    "\n",
    "# closed form logl\n",
    "@show loglikelihood!(qc_model, false, false)\n",
    "\n",
    "# autodiff logl\n",
    "par = [vec(qc_model.B); qc_model.θ; qc_model.ϕ]\n",
    "@show loglikelihood(par, qc_model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check $\\nabla_{vecB}L$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12×2 Matrix{Float64}:\n",
       " -248.563    -248.563\n",
       "   -8.41366    -8.41366\n",
       "   -1.65427    -1.65427\n",
       "   -7.21292    -7.21292\n",
       "   -6.51406    -6.51406\n",
       "   -3.74985    -3.74985\n",
       "   34.0733     34.0733\n",
       "   14.6616     14.6616\n",
       "   -4.23803    -4.23803\n",
       "   -8.02525    -8.02525\n",
       "   -0.16478    -0.16478\n",
       "   -7.38809    -7.38809"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# autodiff grad\n",
    "autodiff_loglikelihood(vecB) = loglikelihood([vecB; qc_model.θ; qc_model.ϕ], qc_model)\n",
    "∇logl(x) = ForwardDiff.gradient(autodiff_loglikelihood, x)\n",
    "\n",
    "# closed form grad\n",
    "loglikelihood!(qc_model, true, false)\n",
    "\n",
    "[qc_model.∇vecB ∇logl(vec(qc_model.B))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check $\\nabla_{\\theta}L$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       " 1842.33  1842.33\n",
       " 3663.83  3663.83"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# autodiff grad\n",
    "autodiff_loglikelihood(θ) = loglikelihood([vec(qc_model.B); θ; qc_model.ϕ], qc_model)\n",
    "∇logl(x) = ForwardDiff.gradient(autodiff_loglikelihood, x)\n",
    "\n",
    "# closed form grad\n",
    "loglikelihood!(qc_model, true, false)\n",
    "\n",
    "[qc_model.∇θ ∇logl(qc_model.θ)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check $\\nabla_{\\tau}L$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       "      -3.02368e5  -3.0931e5\n",
       " -297004.0        -3.06836e5"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# autodiff grad\n",
    "autodiff_loglikelihood(τ) = loglikelihood([vec(qc_model.B); qc_model.θ; τ], qc_model)\n",
    "∇logl(x) = ForwardDiff.gradient(autodiff_loglikelihood, x)\n",
    "\n",
    "# closed form grad\n",
    "loglikelihood!(qc_model, true, false)\n",
    "\n",
    "[qc_model.∇ϕ ∇logl(qc_model.ϕ)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " -311333.9222124512\n",
       " -289504.48901533167"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qc_model.∇ϕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " -314591.360309837\n",
       " -304319.4364207705"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇logl(qc_model.ϕ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare loglikelihood/gradient with longitudinal (single observation)\n",
    "\n",
    "To test this, we simulate a single multivariate gaussian Copula, and compare its loglikelihood with longitudinal gaussian copula with only 1 observation per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " 0.009775278594465796"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5000\n",
    "dist = Normal\n",
    "\n",
    "qc_model1, G, Btrue, θtrue, γtrue, τtrue = simulate_multivariate_traits(\n",
    "    n = n, # sample size\n",
    "    p = 3, # number of fixed effects, including intercept\n",
    "    m = 1, # number of variance components\n",
    "    d = 1, # number of phenotypes\n",
    "    q = 1000, # number of SNPs\n",
    "    k = k, # number of causal SNPs\n",
    "    seed = 123,\n",
    "    τtrue = 0.01,\n",
    "    possible_distributions = [dist]\n",
    ")\n",
    "\n",
    "qc_model2, G, Btrue, θtrue, γtrue, τtrue = simulate_longitudinal_traits(\n",
    "    n = n, # sample size\n",
    "    p = 3, # number of fixed effects, including intercept\n",
    "    m = 1, # number of variance components\n",
    "    d_max = 1, # number of observations per sample\n",
    "    q = 1000, # number of SNPs\n",
    "    k = k, # number of causal SNPs\n",
    "    seed = 123,\n",
    "    τtrue = 0.01,\n",
    "    y_distribution = dist,\n",
    ")\n",
    "\n",
    "# force longitudinal qc_model to share the same y/X/θ/τ as multivariate case\n",
    "qc_model2.β .= qc_model1.B\n",
    "for i in 1:n\n",
    "    copyto!(qc_model2.data[i].y, qc_model1.Y[i, :])\n",
    "    copyto!(qc_model2.data[i].X, qc_model1.X[i, :])\n",
    "#     copyto!(qc_model2.data[i].η, qc_model1.data[i].η)\n",
    "#     copyto!(qc_model2.data[i].μ, qc_model1.data[i].μ)\n",
    "#     copyto!(qc_model2.data[i].res, qc_model1.data[i].res)\n",
    "end\n",
    "qc_model2.θ .= qc_model1.θ\n",
    "qc_model1.ϕ .= qc_model2.τ\n",
    "# qc_model2.τ .= qc_model1.ϕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loglikelihood!(qc_model1, true, false) = -18930.965914285898\n",
      "loglikelihood!(qc_model2, true, false) = -18930.965914285898\n"
     ]
    }
   ],
   "source": [
    "@show loglikelihood!(qc_model1, true, false)\n",
    "@show loglikelihood!(qc_model2, true, false);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qc_model1.∇vecB = [-0.9563351570448801, -0.39865893560309557, 0.006400758476562237]\n",
      "qc_model2.∇β = [-0.9563351570448801, -0.3986589356030947, 0.006400758476562223]\n"
     ]
    }
   ],
   "source": [
    "@show qc_model1.∇vecB\n",
    "@show qc_model2.∇β;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qc_model1.∇θ = [-354.56438108432167]\n",
      "qc_model2.∇θ = [-354.56438108432167]\n"
     ]
    }
   ],
   "source": [
    "@show qc_model1.∇θ\n",
    "@show qc_model2.∇θ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qc_model1.∇ϕ = [66371.51597804665]\n",
      "qc_model2.∇τ = [66371.51597804665]\n"
     ]
    }
   ],
   "source": [
    "@show qc_model1.∇ϕ\n",
    "@show qc_model2.∇τ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is $\\nabla_\\beta res$ calculated correctly? \n",
    "\n",
    "We can check using ForwardDiff\n",
    "\n",
    "The function is \n",
    "\n",
    "$$res_{ij}(\\beta) = \\frac{y_{ij} - \\mu_{ij}}{\\sqrt{\\sigma_{ij}^2(\\beta)}}$$\n",
    "\n",
    "### Normal\n",
    "\n",
    "Assumes y, X are given. We calculate the (standardized) residuals for just 1 sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resβ(yi, xi, vec(B)) = [1.3884090998930962, -0.16822204638920013, 2.241041968786522, 0.04559962991400112]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48×2 Matrix{Float64}:\n",
       " -1.0        -1.0\n",
       " -0.100418   -0.100418\n",
       "  0.0470154   0.0470154\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0         0.0\n",
       "  ⋮          \n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       " -1.0        -1.0\n",
       " -0.100418   -0.100418\n",
       "  0.0470154   0.0470154"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data\n",
    "xi = qc_model.X[1, :] # p by 1\n",
    "yi = qc_model.Y[1, :] # d by 1\n",
    "\n",
    "# objective\n",
    "function resβ(y, x, vecB::AbstractVector)\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(IdentityLink(), η)\n",
    "    varμ = GLM.glmvar.(Normal(), μ)\n",
    "    return (y - μ) ./ sqrt.(varμ)\n",
    "end\n",
    "resβ(B::AbstractMatrix) = resβ(yi, xi, vec(B))\n",
    "resβ(B::AbstractVector) = resβ(yi, xi, B)\n",
    "\n",
    "B = randn(p, d)\n",
    "@show resβ(yi, xi, vec(B))\n",
    "\n",
    "# autodiff gradient\n",
    "∇resβ_autodiff = x -> ForwardDiff.jacobian(resβ, x)\n",
    "correct = ∇resβ_autodiff(vec(B))'\n",
    "\n",
    "# mathematical gradient\n",
    "function ∇resβ(x, y, vecB::AbstractVector{T}) where T\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(IdentityLink(), η)\n",
    "    varμ = GLM.glmvar.(Normal(), μ)\n",
    "    res = y - μ\n",
    "    std_res = res ./ sqrt.(varμ)\n",
    "    dμ = GLM.mueta.(IdentityLink(), η)\n",
    "    out = zeros(T, d*p, d)\n",
    "    @inbounds for j in 1:d\n",
    "        for k in 1:p\n",
    "            out[(j-1)*p + k, j] = QuasiCopula.update_∇res_ij(Normal(), x[k], \n",
    "                std_res[j], μ[j], dμ[j], varμ[j])\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "math_result = ∇resβ(xi, yi, vec(B))\n",
    "\n",
    "# compare results\n",
    "[vec(math_result) vec(correct)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resβ(yi, xi, vec(B)) = [-1.699553635820773, -2.9658266436544203, 2.621786668608018]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45×2 Matrix{Float64}:\n",
       " -0.849777  -0.849777\n",
       "  0.262282   0.262282\n",
       " -1.92764   -1.92764\n",
       " -0.268584  -0.268584\n",
       " -0.564345  -0.564345\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  ⋮         \n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       " -1.31089   -1.31089\n",
       "  0.404604   0.404604\n",
       " -2.97365   -2.97365\n",
       " -0.414327  -0.414327\n",
       " -0.870577  -0.870577"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data\n",
    "xi = qc_model.X[1, :] # p by 1\n",
    "yi = qc_model.Y[1, :] # d by 1\n",
    "\n",
    "# objective\n",
    "function resβ(y, x, vecB::AbstractVector)\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(LogitLink(), η)\n",
    "    varμ = GLM.glmvar.(Bernoulli(), μ)\n",
    "    return (y - μ) ./ sqrt.(varμ)\n",
    "end\n",
    "resβ(B::AbstractMatrix) = resβ(yi, xi, vec(B))\n",
    "resβ(B::AbstractVector) = resβ(yi, xi, B)\n",
    "\n",
    "B = randn(p, d)\n",
    "@show resβ(yi, xi, vec(B))\n",
    "\n",
    "# autodiff gradient\n",
    "∇resβ_autodiff = x -> ForwardDiff.jacobian(resβ, x)\n",
    "correct = ∇resβ_autodiff(vec(B))'\n",
    "\n",
    "# mathematical gradient\n",
    "function ∇resβ(x, y, vecB::AbstractVector{T}) where T\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(LogitLink(), η)\n",
    "    varμ = GLM.glmvar.(Bernoulli(), μ)\n",
    "    res = y - μ\n",
    "    std_res = res ./ sqrt.(varμ)\n",
    "    dμ = GLM.mueta.(LogitLink(), η)\n",
    "    out = zeros(T, d*p, d)\n",
    "    @inbounds for j in 1:d\n",
    "        for k in 1:p\n",
    "            out[(j-1)*p + k, j] = QuasiCopula.update_∇res_ij(Bernoulli(), x[k], \n",
    "                std_res[j], μ[j], dμ[j], varμ[j])\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "math_result = ∇resβ(xi, yi, vec(B))\n",
    "\n",
    "# compare results\n",
    "[vec(math_result) vec(correct)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resβ(yi, xi, vec(B)) = [-0.6311261621867231, -2.784614111314093, 18.689464943875688]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45×2 Matrix{Float64}:\n",
       "  -0.315563    -0.315563\n",
       "   0.0973979    0.0973979\n",
       "  -0.715827    -0.715827\n",
       "  -0.0997383   -0.0997383\n",
       "  -0.209568    -0.209568\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   ⋮          \n",
       "   0.0         -0.0\n",
       "   0.0         -0.0\n",
       "   0.0         -0.0\n",
       "   0.0         -0.0\n",
       "   0.0         -0.0\n",
       "   0.0         -0.0\n",
       "   0.0         -0.0\n",
       "  -9.39809     -9.39809\n",
       "   2.9007       2.9007\n",
       " -21.3187     -21.3187\n",
       "  -2.9704      -2.9704\n",
       "  -6.24136     -6.24136"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data\n",
    "xi = qc_model.X[1, :] # p by 1\n",
    "yi = qc_model.Y[1, :] # d by 1\n",
    "\n",
    "# objective\n",
    "function resβ(y, x, vecB::AbstractVector)\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(LogLink(), η)\n",
    "    varμ = GLM.glmvar.(Poisson(), μ)\n",
    "    return (y - μ) ./ sqrt.(varμ)\n",
    "end\n",
    "resβ(B::AbstractMatrix) = resβ(yi, xi, vec(B))\n",
    "resβ(B::AbstractVector) = resβ(yi, xi, B)\n",
    "\n",
    "B = randn(p, d)\n",
    "@show resβ(yi, xi, vec(B))\n",
    "\n",
    "# autodiff gradient\n",
    "∇resβ_autodiff = x -> ForwardDiff.jacobian(resβ, x)\n",
    "correct = ∇resβ_autodiff(vec(B))'\n",
    "\n",
    "# mathematical gradient\n",
    "function ∇resβ(x, y, vecB::AbstractVector{T}) where T\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(LogLink(), η)\n",
    "    varμ = GLM.glmvar.(Poisson(), μ)\n",
    "    res = y - μ\n",
    "    std_res = res ./ sqrt.(varμ)\n",
    "    dμ = GLM.mueta.(LogLink(), η)\n",
    "    out = zeros(T, d*p, d)\n",
    "    @inbounds for j in 1:d\n",
    "        for k in 1:p\n",
    "            out[(j-1)*p + k, j] = QuasiCopula.update_∇res_ij(Poisson(), x[k], \n",
    "                std_res[j], μ[j], dμ[j], varμ[j])\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "math_result = ∇resβ(xi, yi, vec(B))\n",
    "\n",
    "# compare results\n",
    "[vec(math_result) vec(correct)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check $\\nabla_{\\beta} L$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12×2 Matrix{Float64}:\n",
       "  -0.125531    -0.125531\n",
       "   0.237507     0.237507\n",
       "   0.0716134    0.0716134\n",
       "   0.554527     0.554527\n",
       "  -1.04917     -1.04917\n",
       "  -0.316348    -0.316348\n",
       "   7.83048      7.83048\n",
       " -14.8154     -14.8154\n",
       "  -4.46715     -4.46715\n",
       "  -9.23224     -9.23224\n",
       "  17.4675      17.4675\n",
       "   5.26683      5.26683"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data\n",
    "i = 10\n",
    "xi = qc_model.X[i, :] # p by 1\n",
    "yi = qc_model.Y[i, :] # d by 1\n",
    "\n",
    "function A_mul_b!(c::AbstractVector{T}, A::AbstractMatrix, b::AbstractVector) where T\n",
    "    n, p = size(A)\n",
    "    fill!(c, zero(T))\n",
    "    for j in 1:p, i in 1:n\n",
    "        c[i] += A[i, j] * b[j]\n",
    "    end\n",
    "    return c\n",
    "end\n",
    "\n",
    "# loglikelihood for a single sample\n",
    "function loglikelihood(y, x, vecB::AbstractVector{T}, qc_model) where T\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    m = qc_model.m\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(qc_model.veclink, η)\n",
    "    varμ = GLM.glmvar.(qc_model.vecdist, μ)\n",
    "    res = y - μ\n",
    "    std_res = zeros(T, length(res))\n",
    "    nuisance_counter = 1\n",
    "    for j in eachindex(res)\n",
    "        if typeof(qc_model.vecdist[j]) <: Normal\n",
    "            τ = abs(qc_model.ϕ[nuisance_counter])\n",
    "            std_res[j] = res[j] * sqrt(τ)\n",
    "            nuisance_counter += 1\n",
    "        else\n",
    "            std_res[j] = res[j] / sqrt(varμ[j])\n",
    "        end\n",
    "    end\n",
    "    storage_d = zeros(T, d)\n",
    "    q = zeros(T, m)\n",
    "    # GLM loglikelihood (term 2)\n",
    "    nuisance_counter = 1\n",
    "    logl = zero(T)\n",
    "    @inbounds for j in eachindex(y)\n",
    "        dist = qc_model.vecdist[j]\n",
    "        if typeof(dist) <: Normal\n",
    "            τ = inv(qc_model.ϕ[nuisance_counter])\n",
    "            logl += QuasiCopula.loglik_obs(dist, y[j], μ[j], one(T), τ)\n",
    "            nuisance_counter += 1\n",
    "        else\n",
    "            logl += QuasiCopula.loglik_obs(dist, y[j], μ[j], one(T), one(T))\n",
    "        end\n",
    "    end\n",
    "    # loglikelihood term 1 i.e. -sum ln(1 + 0.5tr(Γ(θ)))\n",
    "    tsum = dot(qc_model.θ, qc_model.t) # tsum = 0.5tr(Γ)\n",
    "    logl += -log(1 + tsum)\n",
    "    # loglikelihood term 3 i.e. sum ln(1 + 0.5 r*Γ*r)\n",
    "    @inbounds for k in 1:qc_model.m # loop over m variance components\n",
    "        mul!(storage_d, qc_model.V[k], std_res) # storage_d = V[k] * r\n",
    "        q[k] = dot(std_res, storage_d) / 2 # q[k] = 0.5 r * V[k] * r\n",
    "    end\n",
    "    qsum = dot(qc_model.θ, q) # qsum = 0.5 r*Γ*r\n",
    "    logl += log(1 + qsum)\n",
    "    return logl\n",
    "end\n",
    "loglikelihood(B::AbstractMatrix) = loglikelihood(yi, xi, vec(B), qc_model)\n",
    "loglikelihood(B::AbstractVector) = loglikelihood(yi, xi, B, qc_model)\n",
    "\n",
    "qc_model.ϕ .= 1.1\n",
    "\n",
    "# autodiff gradient\n",
    "Random.seed!(2023)\n",
    "B = randn(p, d)\n",
    "logl_autodiff = x -> ForwardDiff.gradient(loglikelihood, x)\n",
    "correct = logl_autodiff(vec(B))\n",
    "\n",
    "# gradient from math\n",
    "qc_model.B .= B\n",
    "loglikelihood!(qc_model, true, false)\n",
    "\n",
    "[correct qc_model.data[i].∇vecB]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check $\\nabla_{\\theta} L$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×2 Matrix{Float64}:\n",
       " 3.55748  3.55748"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data\n",
    "i = 5\n",
    "xi = qc_model.X[i, :] # p by 1\n",
    "yi = qc_model.Y[i, :] # d by 1\n",
    "\n",
    "function A_mul_b!(c::AbstractVector{T}, A::AbstractMatrix, b::AbstractVector) where T\n",
    "    n, p = size(A)\n",
    "    fill!(c, zero(T))\n",
    "    for j in 1:p, i in 1:n\n",
    "        c[i] += A[i, j] * b[j]\n",
    "    end\n",
    "    return c\n",
    "end\n",
    "\n",
    "# loglikelihood for a single sample\n",
    "function loglikelihood(y, x, θ::AbstractVector{T}, qc_model) where T\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    m = qc_model.m\n",
    "    B = qc_model.B\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(qc_model.veclink, η)\n",
    "    varμ = GLM.glmvar.(qc_model.vecdist, μ)\n",
    "    res = y - μ\n",
    "    std_res = zeros(T, length(res))\n",
    "    nuisance_counter = 1\n",
    "    for j in eachindex(res)\n",
    "        if typeof(qc_model.vecdist[j]) <: Normal\n",
    "            τ = abs(qc_model.ϕ[nuisance_counter])\n",
    "            std_res[j] = res[j] * sqrt(τ)\n",
    "            nuisance_counter += 1\n",
    "        else\n",
    "            std_res[j] = res[j] / sqrt(varμ[j])\n",
    "        end\n",
    "    end\n",
    "    storage_d = zeros(T, d)\n",
    "    q = zeros(T, m)\n",
    "    # GLM loglikelihood (term 2)\n",
    "    logl = zero(T)\n",
    "    @inbounds for j in eachindex(y)\n",
    "        logl += QuasiCopula.loglik_obs(qc_model.vecdist[j], y[j], μ[j], one(T), one(T))\n",
    "    end\n",
    "    # loglikelihood term 1 i.e. -sum ln(1 + 0.5tr(Γ(θ)))\n",
    "    tsum = dot(θ, qc_model.t) # tsum = 0.5tr(Γ)\n",
    "    logl += -log(1 + tsum)\n",
    "    # loglikelihood term 3 i.e. sum ln(1 + 0.5 r*Γ*r)\n",
    "    @inbounds for k in 1:qc_model.m # loop over m variance components\n",
    "        mul!(storage_d, qc_model.V[k], std_res) # storage_d = V[k] * r\n",
    "        q[k] = dot(std_res, storage_d) / 2 # q[k] = 0.5 r * V[k] * r\n",
    "    end\n",
    "    qsum = dot(θ, q) # qsum = 0.5 r*Γ*r\n",
    "    logl += log(1 + qsum)\n",
    "    return logl\n",
    "end\n",
    "loglikelihood(θ::AbstractVector) = loglikelihood(yi, xi, θ, qc_model)\n",
    "\n",
    "# autodiff gradient\n",
    "logl_autodiff = x -> ForwardDiff.gradient(loglikelihood, x)\n",
    "\n",
    "θ = [rand()]\n",
    "correct = logl_autodiff(θ)\n",
    "\n",
    "# gradient from math\n",
    "qc_model.θ .= θ\n",
    "loglikelihood!(qc_model, true, false)\n",
    "\n",
    "[correct qc_model.data[i].∇θ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Check $\\nabla_{\\phi} L$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       " 1.59779   -3.52058\n",
       " 0.455338  -3.52058"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data\n",
    "i = 5\n",
    "xi = qc_model.X[i, :] # p by 1\n",
    "yi = qc_model.Y[i, :] # d by 1\n",
    "\n",
    "function A_mul_b!(c::AbstractVector{T}, A::AbstractMatrix, b::AbstractVector) where T\n",
    "    n, p = size(A)\n",
    "    fill!(c, zero(T))\n",
    "    for j in 1:p, i in 1:n\n",
    "        c[i] += A[i, j] * b[j]\n",
    "    end\n",
    "    return c\n",
    "end\n",
    "\n",
    "# loglikelihood for a single sample\n",
    "function loglikelihood(y, x, ϕ::AbstractVector{T}, qc_model) where T\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    m = qc_model.m\n",
    "    B = qc_model.B\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(qc_model.veclink, η)\n",
    "    varμ = GLM.glmvar.(qc_model.vecdist, μ)\n",
    "    res = y - μ\n",
    "    std_res = zeros(T, length(res))\n",
    "    nuisance_counter = 1\n",
    "    for j in eachindex(res)\n",
    "        if typeof(qc_model.vecdist[j]) <: Normal\n",
    "            τ = abs(ϕ[nuisance_counter])\n",
    "            std_res[j] = res[j] * sqrt(τ)\n",
    "            nuisance_counter += 1\n",
    "        else\n",
    "            std_res[j] = res[j] / sqrt(varμ[j])\n",
    "        end\n",
    "    end\n",
    "    storage_d = zeros(T, d)\n",
    "    q = zeros(T, m)\n",
    "    # GLM loglikelihood (term 2)\n",
    "    logl = zero(T)\n",
    "    @inbounds for j in eachindex(y)\n",
    "        logl += QuasiCopula.loglik_obs(qc_model.vecdist[j], y[j], μ[j], one(T), one(T))\n",
    "    end\n",
    "    # loglikelihood term 1 i.e. -sum ln(1 + 0.5tr(Γ(θ)))\n",
    "    tsum = dot(qc_model.θ, qc_model.t) # tsum = 0.5tr(Γ)\n",
    "    logl += -log(1 + tsum)\n",
    "    # loglikelihood term 3 i.e. sum ln(1 + 0.5 r*Γ*r)\n",
    "    @inbounds for k in 1:qc_model.m # loop over m variance components\n",
    "        mul!(storage_d, qc_model.V[k], std_res) # storage_d = V[k] * r\n",
    "        q[k] = dot(std_res, storage_d) / 2 # q[k] = 0.5 r * V[k] * r\n",
    "    end\n",
    "    qsum = dot(qc_model.θ, q) # qsum = 0.5 r*Γ*r\n",
    "    logl += log(1 + qsum)\n",
    "    return logl\n",
    "end\n",
    "loglikelihood(ϕ::AbstractVector) = loglikelihood(yi, xi, ϕ, qc_model)\n",
    "\n",
    "# autodiff gradient\n",
    "logl_autodiff = x -> ForwardDiff.gradient(loglikelihood, x)\n",
    "\n",
    "ϕ = rand(2)\n",
    "correct = logl_autodiff(ϕ)\n",
    "\n",
    "# gradient from math\n",
    "qc_model.ϕ .= ϕ\n",
    "loglikelihood!(qc_model, true, false)\n",
    "\n",
    "[correct qc_model.data[i].∇ϕ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
