{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using autodiff to check gradient/Hessians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Revise\n",
    "using DataFrames, Random, GLM, QuasiCopula\n",
    "using ForwardDiff, LinearAlgebra\n",
    "using ToeplitzMatrices\n",
    "using BenchmarkTools\n",
    "using SnpArrays\n",
    "using ForwardDiff\n",
    "# using MendelPlots\n",
    "ENV[\"COLUMNS\"] = 240\n",
    "\n",
    "BLAS.set_num_threads(1)\n",
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 0 # number of causal SNPs\n",
    "maf = 0.3\n",
    "p = 3\n",
    "d = 4\n",
    "\n",
    "qc_model, G, Btrue, θtrue, γtrue, τtrue = simulate_multivariate_traits(\n",
    "    n = 5000, # sample size\n",
    "    p = p, # number of fixed effects, including intercept\n",
    "    m = 1, # number of variance components\n",
    "    d = d, # number of phenotypes\n",
    "    q = 1000, # number of SNPs\n",
    "    k = k, # number of causal SNPs\n",
    "    seed = 2023,\n",
    "    τtrue = 0.01,\n",
    "    possible_distributions = [Bernoulli, Poisson, Normal]\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is loglikelihood implemented correctly?\n",
    "\n",
    "To test this, we simulate a single multivariate gaussian Copula, and compare its loglikelihood with longitudinal gaussian copula with only 1 observation per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " 1.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5000\n",
    "\n",
    "qc_model1, G, Btrue, θtrue, γtrue, τtrue = simulate_multivariate_traits(\n",
    "    n = n, # sample size\n",
    "    p = 3, # number of fixed effects, including intercept\n",
    "    m = 1, # number of variance components\n",
    "    d = 1, # number of phenotypes\n",
    "    q = 1000, # number of SNPs\n",
    "    k = k, # number of causal SNPs\n",
    "    seed = 2023,\n",
    "    τtrue = 0.01,\n",
    "    possible_distributions = [Normal]\n",
    ")\n",
    "\n",
    "qc_model2, G, Btrue, θtrue, γtrue, τtrue = simulate_longitudinal_traits(\n",
    "    n = n, # sample size\n",
    "    p = 3, # number of fixed effects, including intercept\n",
    "    m = 1, # number of variance components\n",
    "    d_max = 1, # number of observations per sample\n",
    "    q = 1000, # number of SNPs\n",
    "    k = k, # number of causal SNPs\n",
    "    seed = 2023,\n",
    "    τtrue = 0.01,\n",
    "    y_distribution = Normal,\n",
    ")\n",
    "\n",
    "# force longitudinal qc_model to share the same y/X/θ/τ as multivariate case\n",
    "for i in 1:n\n",
    "    copyto!(qc_model2.data[i].y, qc_model1.Y[i, :])\n",
    "    copyto!(qc_model2.data[i].X, qc_model1.X[i, :])\n",
    "end\n",
    "qc_model2.θ .= qc_model1.θ\n",
    "qc_model2.τ .= qc_model1.ϕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000×2 Matrix{Float64}:\n",
       "  -4.35162   -4.35162\n",
       "  -4.87728   -4.87728\n",
       "   1.892      1.892\n",
       "  -8.44168   -8.44168\n",
       "   5.00282    5.00282\n",
       "  -6.28996   -6.28996\n",
       "   2.48012    2.48012\n",
       "   5.39039    5.39039\n",
       "  20.9844    20.9844\n",
       "  -5.22089   -5.22089\n",
       " -20.0763   -20.0763\n",
       " -14.0114   -14.0114\n",
       "  -5.6128    -5.6128\n",
       "   ⋮        \n",
       "  -2.81213   -2.81213\n",
       "  -2.18985   -2.18985\n",
       "  -2.28793   -2.28793\n",
       "  -2.78477   -2.78477\n",
       "   2.93928    2.93928\n",
       "  10.5193    10.5193\n",
       "   7.13238    7.13238\n",
       " -15.9023   -15.9023\n",
       " -24.1438   -24.1438\n",
       "   2.52053    2.52053\n",
       "  -1.52918   -1.52918\n",
       " -12.7906   -12.7906"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[qc_model1.Y vcat([qc_model2.data[i].y for i in 1:5000]...)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loglikelihood!(qc_model1, false, false) = -265911.4748951471\n",
      "loglikelihood!(qc_model2, false, false) = -270985.42927297653\n"
     ]
    }
   ],
   "source": [
    "@show loglikelihood!(qc_model1, false, false)\n",
    "@show loglikelihood!(qc_model2, false, false);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is $\\nabla_\\beta res$ calculated correctly? \n",
    "\n",
    "We can check using ForwardDiff\n",
    "\n",
    "The function is \n",
    "\n",
    "$$res_{ij}(\\beta) = \\frac{y_{ij} - \\mu_{ij}}{\\sqrt{\\sigma_{ij}^2(\\beta)}}$$\n",
    "\n",
    "### Normal\n",
    "\n",
    "Assumes y, X are given. We calculate the (standardized) residuals for just 1 sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resβ(yi, xi, vec(B)) = [1.3884090998930962, -0.16822204638920013, 2.241041968786522, 0.04559962991400112]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48×2 Matrix{Float64}:\n",
       " -1.0        -1.0\n",
       " -0.100418   -0.100418\n",
       "  0.0470154   0.0470154\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0         0.0\n",
       "  ⋮          \n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       "  0.0        -0.0\n",
       " -1.0        -1.0\n",
       " -0.100418   -0.100418\n",
       "  0.0470154   0.0470154"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data\n",
    "xi = qc_model.X[1, :] # p by 1\n",
    "yi = qc_model.Y[1, :] # d by 1\n",
    "\n",
    "# objective\n",
    "function resβ(y, x, vecB::AbstractVector)\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(IdentityLink(), η)\n",
    "    varμ = GLM.glmvar.(Normal(), μ)\n",
    "    return (y - μ) ./ sqrt.(varμ)\n",
    "end\n",
    "resβ(B::AbstractMatrix) = resβ(yi, xi, vec(B))\n",
    "resβ(B::AbstractVector) = resβ(yi, xi, B)\n",
    "\n",
    "B = randn(p, d)\n",
    "@show resβ(yi, xi, vec(B))\n",
    "\n",
    "# autodiff gradient\n",
    "∇resβ_autodiff = x -> ForwardDiff.jacobian(resβ, x)\n",
    "correct = ∇resβ_autodiff(vec(B))'\n",
    "\n",
    "# mathematical gradient\n",
    "function ∇resβ(x, y, vecB::AbstractVector{T}) where T\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(IdentityLink(), η)\n",
    "    varμ = GLM.glmvar.(Normal(), μ)\n",
    "    res = y - μ\n",
    "    std_res = res ./ sqrt.(varμ)\n",
    "    dμ = GLM.mueta.(IdentityLink(), η)\n",
    "    out = zeros(T, d*p, d)\n",
    "    @inbounds for j in 1:d\n",
    "        for k in 1:p\n",
    "            out[(j-1)*p + k, j] = QuasiCopula.update_∇res_ij(Normal(), x[k], \n",
    "                std_res[j], μ[j], dμ[j], varμ[j])\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "math_result = ∇resβ(xi, yi, vec(B))\n",
    "\n",
    "# compare results\n",
    "[vec(math_result) vec(correct)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resβ(yi, xi, vec(B)) = [-1.699553635820773, -2.9658266436544203, 2.621786668608018]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45×2 Matrix{Float64}:\n",
       " -0.849777  -0.849777\n",
       "  0.262282   0.262282\n",
       " -1.92764   -1.92764\n",
       " -0.268584  -0.268584\n",
       " -0.564345  -0.564345\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  0.0        0.0\n",
       "  ⋮         \n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       "  0.0       -0.0\n",
       " -1.31089   -1.31089\n",
       "  0.404604   0.404604\n",
       " -2.97365   -2.97365\n",
       " -0.414327  -0.414327\n",
       " -0.870577  -0.870577"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data\n",
    "xi = qc_model.X[1, :] # p by 1\n",
    "yi = qc_model.Y[1, :] # d by 1\n",
    "\n",
    "# objective\n",
    "function resβ(y, x, vecB::AbstractVector)\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(LogitLink(), η)\n",
    "    varμ = GLM.glmvar.(Bernoulli(), μ)\n",
    "    return (y - μ) ./ sqrt.(varμ)\n",
    "end\n",
    "resβ(B::AbstractMatrix) = resβ(yi, xi, vec(B))\n",
    "resβ(B::AbstractVector) = resβ(yi, xi, B)\n",
    "\n",
    "B = randn(p, d)\n",
    "@show resβ(yi, xi, vec(B))\n",
    "\n",
    "# autodiff gradient\n",
    "∇resβ_autodiff = x -> ForwardDiff.jacobian(resβ, x)\n",
    "correct = ∇resβ_autodiff(vec(B))'\n",
    "\n",
    "# mathematical gradient\n",
    "function ∇resβ(x, y, vecB::AbstractVector{T}) where T\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(LogitLink(), η)\n",
    "    varμ = GLM.glmvar.(Bernoulli(), μ)\n",
    "    res = y - μ\n",
    "    std_res = res ./ sqrt.(varμ)\n",
    "    dμ = GLM.mueta.(LogitLink(), η)\n",
    "    out = zeros(T, d*p, d)\n",
    "    @inbounds for j in 1:d\n",
    "        for k in 1:p\n",
    "            out[(j-1)*p + k, j] = QuasiCopula.update_∇res_ij(Bernoulli(), x[k], \n",
    "                std_res[j], μ[j], dμ[j], varμ[j])\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "math_result = ∇resβ(xi, yi, vec(B))\n",
    "\n",
    "# compare results\n",
    "[vec(math_result) vec(correct)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resβ(yi, xi, vec(B)) = [-0.6311261621867231, -2.784614111314093, 18.689464943875688]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45×2 Matrix{Float64}:\n",
       "  -0.315563    -0.315563\n",
       "   0.0973979    0.0973979\n",
       "  -0.715827    -0.715827\n",
       "  -0.0997383   -0.0997383\n",
       "  -0.209568    -0.209568\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   0.0          0.0\n",
       "   ⋮          \n",
       "   0.0         -0.0\n",
       "   0.0         -0.0\n",
       "   0.0         -0.0\n",
       "   0.0         -0.0\n",
       "   0.0         -0.0\n",
       "   0.0         -0.0\n",
       "   0.0         -0.0\n",
       "  -9.39809     -9.39809\n",
       "   2.9007       2.9007\n",
       " -21.3187     -21.3187\n",
       "  -2.9704      -2.9704\n",
       "  -6.24136     -6.24136"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data\n",
    "xi = qc_model.X[1, :] # p by 1\n",
    "yi = qc_model.Y[1, :] # d by 1\n",
    "\n",
    "# objective\n",
    "function resβ(y, x, vecB::AbstractVector)\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(LogLink(), η)\n",
    "    varμ = GLM.glmvar.(Poisson(), μ)\n",
    "    return (y - μ) ./ sqrt.(varμ)\n",
    "end\n",
    "resβ(B::AbstractMatrix) = resβ(yi, xi, vec(B))\n",
    "resβ(B::AbstractVector) = resβ(yi, xi, B)\n",
    "\n",
    "B = randn(p, d)\n",
    "@show resβ(yi, xi, vec(B))\n",
    "\n",
    "# autodiff gradient\n",
    "∇resβ_autodiff = x -> ForwardDiff.jacobian(resβ, x)\n",
    "correct = ∇resβ_autodiff(vec(B))'\n",
    "\n",
    "# mathematical gradient\n",
    "function ∇resβ(x, y, vecB::AbstractVector{T}) where T\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(LogLink(), η)\n",
    "    varμ = GLM.glmvar.(Poisson(), μ)\n",
    "    res = y - μ\n",
    "    std_res = res ./ sqrt.(varμ)\n",
    "    dμ = GLM.mueta.(LogLink(), η)\n",
    "    out = zeros(T, d*p, d)\n",
    "    @inbounds for j in 1:d\n",
    "        for k in 1:p\n",
    "            out[(j-1)*p + k, j] = QuasiCopula.update_∇res_ij(Poisson(), x[k], \n",
    "                std_res[j], μ[j], dμ[j], varμ[j])\n",
    "        end\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "math_result = ∇resβ(xi, yi, vec(B))\n",
    "\n",
    "# compare results\n",
    "[vec(math_result) vec(correct)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check $\\nabla_{\\beta} L$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15×2 Matrix{Float64}:\n",
       "  0.472462    0.472462\n",
       "  0.325011    0.325011\n",
       "  0.314195    0.314195\n",
       "  0.0177468   0.0177468\n",
       "  0.565479    0.565479\n",
       " -0.958411   -0.958411\n",
       " -0.6593     -0.6593\n",
       " -0.637359   -0.637359\n",
       " -0.0360001  -0.0360001\n",
       " -1.1471     -1.1471\n",
       "  4.56203     4.56203\n",
       "  3.13827     3.13827\n",
       "  3.03382     3.03382\n",
       "  0.171361    0.171361\n",
       "  5.4602      5.4602"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data\n",
    "i = 10\n",
    "xi = qc_model.X[i, :] # p by 1\n",
    "yi = qc_model.Y[i, :] # d by 1\n",
    "\n",
    "function A_mul_b!(c::AbstractVector{T}, A::AbstractMatrix, b::AbstractVector) where T\n",
    "    n, p = size(A)\n",
    "    fill!(c, zero(T))\n",
    "    for j in 1:p, i in 1:n\n",
    "        c[i] += A[i, j] * b[j]\n",
    "    end\n",
    "    return c\n",
    "end\n",
    "\n",
    "# loglikelihood for a single sample\n",
    "function loglikelihood(y, x, vecB::AbstractVector{T}, qc_model) where T\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    m = qc_model.m\n",
    "    B = reshape(vecB, p, d)\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(qc_model.veclink, η)\n",
    "    varμ = GLM.glmvar.(qc_model.vecdist, μ)\n",
    "    res = y - μ\n",
    "    std_res = res ./ sqrt.(varμ)\n",
    "    dμ = GLM.mueta.(LogLink(), η)\n",
    "    storage_d = zeros(T, d)\n",
    "    q = zeros(T, m)\n",
    "    # GLM loglikelihood (term 2)\n",
    "    logl = zero(T)\n",
    "    @inbounds for j in eachindex(y)\n",
    "        logl += QuasiCopula.loglik_obs(qc_model.vecdist[j], y[j], μ[j], one(T), one(T))\n",
    "    end\n",
    "    # loglikelihood term 1 i.e. -sum ln(1 + 0.5tr(Γ(θ)))\n",
    "    tsum = dot(qc_model.θ, qc_model.t) # tsum = 0.5tr(Γ)\n",
    "    logl += -log(1 + tsum)\n",
    "    #\n",
    "     \n",
    "    # loglikelihood term 3 i.e. sum ln(1 + 0.5 r*Γ*r)\n",
    "    @inbounds for k in 1:qc_model.m # loop over m variance components\n",
    "        mul!(storage_d, qc_model.V[k], std_res) # storage_d = V[k] * r\n",
    "#         if needgrad\n",
    "#             BLAS.gemv!('N', θ[k], qc.∇resβ, qc.storage_d, one(T), qc.∇vecB) # ∇β = ∇r*Γ*r\n",
    "#         end\n",
    "        q[k] = dot(std_res, storage_d) / 2 # q[k] = 0.5 r * V[k] * r\n",
    "    end\n",
    "    qsum = dot(qc_model.θ, q) # qsum = 0.5 r*Γ*r\n",
    "    logl += log(1 + qsum)\n",
    "    return logl\n",
    "end\n",
    "loglikelihood(B::AbstractMatrix) = loglikelihood(yi, xi, vec(B), qc_model)\n",
    "loglikelihood(B::AbstractVector) = loglikelihood(yi, xi, B, qc_model)\n",
    "\n",
    "# autodiff gradient\n",
    "logl_autodiff = x -> ForwardDiff.gradient(loglikelihood, x)\n",
    "correct = logl_autodiff(vec(B))\n",
    "\n",
    "# gradient from math\n",
    "qc_model.B .= B\n",
    "loglikelihood!(qc_model, true, false)\n",
    "\n",
    "[correct qc_model.data[i].∇vecB]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check $\\nabla_{\\theta} L$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       " -0.60808   -0.60808\n",
       " -0.496524  -0.496524"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data\n",
    "i = 5\n",
    "xi = qc_model.X[i, :] # p by 1\n",
    "yi = qc_model.Y[i, :] # d by 1\n",
    "\n",
    "function A_mul_b!(c::AbstractVector{T}, A::AbstractMatrix, b::AbstractVector) where T\n",
    "    n, p = size(A)\n",
    "    fill!(c, zero(T))\n",
    "    for j in 1:p, i in 1:n\n",
    "        c[i] += A[i, j] * b[j]\n",
    "    end\n",
    "    return c\n",
    "end\n",
    "\n",
    "# loglikelihood for a single sample\n",
    "function loglikelihood(y, x, θ::AbstractVector{T}, qc_model) where T\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    m = qc_model.m\n",
    "    B = qc_model.B\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(qc_model.veclink, η)\n",
    "    varμ = GLM.glmvar.(qc_model.vecdist, μ)\n",
    "    res = y - μ\n",
    "    std_res = res ./ sqrt.(varμ)\n",
    "    storage_d = zeros(T, d)\n",
    "    q = zeros(T, m)\n",
    "    # GLM loglikelihood (term 2)\n",
    "    logl = zero(T)\n",
    "    @inbounds for j in eachindex(y)\n",
    "        logl += QuasiCopula.loglik_obs(qc_model.vecdist[j], y[j], μ[j], one(T), one(T))\n",
    "    end\n",
    "    # loglikelihood term 1 i.e. -sum ln(1 + 0.5tr(Γ(θ)))\n",
    "    tsum = dot(θ, qc_model.t) # tsum = 0.5tr(Γ)\n",
    "    logl += -log(1 + tsum)\n",
    "    # loglikelihood term 3 i.e. sum ln(1 + 0.5 r*Γ*r)\n",
    "    @inbounds for k in 1:qc_model.m # loop over m variance components\n",
    "        mul!(storage_d, qc_model.V[k], std_res) # storage_d = V[k] * r\n",
    "#         if needgrad\n",
    "#             BLAS.gemv!('N', θ[k], qc.∇resβ, qc.storage_d, one(T), qc.∇vecB) # ∇β = ∇r*Γ*r\n",
    "#         end\n",
    "        q[k] = dot(std_res, storage_d) / 2 # q[k] = 0.5 r * V[k] * r\n",
    "    end\n",
    "    qsum = dot(θ, q) # qsum = 0.5 r*Γ*r\n",
    "    logl += log(1 + qsum)\n",
    "    return logl\n",
    "end\n",
    "loglikelihood(θ::AbstractVector) = loglikelihood(yi, xi, θ, qc_model)\n",
    "\n",
    "# autodiff gradient\n",
    "logl_autodiff = x -> ForwardDiff.gradient(loglikelihood, x)\n",
    "\n",
    "θ = rand(2)\n",
    "correct = logl_autodiff(θ)\n",
    "\n",
    "# gradient from math\n",
    "qc_model.θ .= θ\n",
    "loglikelihood!(qc_model, true, false)\n",
    "\n",
    "[correct qc_model.data[i].∇θ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Check $\\nabla_{\\phi} L$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample data\n",
    "i = 5\n",
    "xi = qc_model.X[i, :] # p by 1\n",
    "yi = qc_model.Y[i, :] # d by 1\n",
    "\n",
    "function A_mul_b!(c::AbstractVector{T}, A::AbstractMatrix, b::AbstractVector) where T\n",
    "    n, p = size(A)\n",
    "    fill!(c, zero(T))\n",
    "    for j in 1:p, i in 1:n\n",
    "        c[i] += A[i, j] * b[j]\n",
    "    end\n",
    "    return c\n",
    "end\n",
    "\n",
    "# loglikelihood for a single sample\n",
    "function loglikelihood(y, x, ϕ::AbstractVector{T}, qc_model) where T\n",
    "    p = length(x)\n",
    "    d = length(y)\n",
    "    m = qc_model.m\n",
    "    B = qc_model.B\n",
    "    η = B' * x\n",
    "    μ = GLM.linkinv.(qc_model.veclink, η)\n",
    "    varμ = GLM.glmvar.(qc_model.vecdist, μ)\n",
    "    res = y - μ\n",
    "    std_res = T[]\n",
    "    nuisance_counter = 1\n",
    "    for j in eachindex(res)\n",
    "        if typeof(qc_model.vecdist[j]) <: Normal\n",
    "            τ = abs(qc_model.ϕ[nuisance_counter])\n",
    "            push!(std_re, res * sqrt(τ))\n",
    "            nuisance_counter += 1\n",
    "        else\n",
    "            push!(std_res, res / sqrt(varμ[j]))\n",
    "        end\n",
    "    end\n",
    "#     std_res = res ./ sqrt.(varμ)\n",
    "    storage_d = zeros(T, d)\n",
    "    q = zeros(T, m)\n",
    "    # GLM loglikelihood (term 2)\n",
    "    logl = zero(T)\n",
    "    @inbounds for j in eachindex(y)\n",
    "        logl += QuasiCopula.loglik_obs(qc_model.vecdist[j], y[j], μ[j], one(T), one(T))\n",
    "    end\n",
    "    # loglikelihood term 1 i.e. -sum ln(1 + 0.5tr(Γ(θ)))\n",
    "    tsum = dot(θ, qc_model.t) # tsum = 0.5tr(Γ)\n",
    "    logl += -log(1 + tsum)\n",
    "    # also add contributions from nuisance parameters\n",
    "    for (j, idx) in enumerate(qc_model.nuisance_idx)\n",
    "        τ = abs(qc_model.ϕ[j])\n",
    "        rss = abs2(norm(qc.std_res[idx]))\n",
    "        logl += -(1 * log(2π) - 1 * log(abs(τ)) + rss) / 2\n",
    "    end\n",
    "    # loglikelihood term 3 i.e. sum ln(1 + 0.5 r*Γ*r)\n",
    "    @inbounds for k in 1:qc_model.m # loop over m variance components\n",
    "        mul!(storage_d, qc_model.V[k], std_res) # storage_d = V[k] * r\n",
    "#         if needgrad\n",
    "#             BLAS.gemv!('N', θ[k], qc.∇resβ, qc.storage_d, one(T), qc.∇vecB) # ∇β = ∇r*Γ*r\n",
    "#         end\n",
    "        q[k] = dot(std_res, storage_d) / 2 # q[k] = 0.5 r * V[k] * r\n",
    "    end\n",
    "    qsum = dot(θ, q) # qsum = 0.5 r*Γ*r\n",
    "    logl += log(1 + qsum)\n",
    "    return logl\n",
    "end\n",
    "loglikelihood(ϕ::AbstractVector) = loglikelihood(yi, xi, ϕ, qc_model)\n",
    "\n",
    "# autodiff gradient\n",
    "logl_autodiff = x -> ForwardDiff.gradient(loglikelihood, x)\n",
    "\n",
    "θ = rand(2)\n",
    "correct = logl_autodiff(θ)\n",
    "\n",
    "# gradient from math\n",
    "qc_model.θ .= θ\n",
    "loglikelihood!(qc_model, true, false)\n",
    "\n",
    "[correct qc_model.data[i].∇θ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
