{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Autodiff packages for speeds\n",
    "\n",
    "+ The goal is to differentiate a log-likelihood function - the workhorse of probability theory, mathematical statistics and machine learning\n",
    "    + $f: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m$\n",
    "    + Forward mode AD: efficient for $m >> n$ \n",
    "    + Reverse mode AD: efficient for $m << n$ \n",
    "    + In GWAS, \n",
    "        - $f$ is the loglikelihood function (i.e. $m = 1$)\n",
    "        - $n = (\\# \\text{ fixed effects}) + (\\# \\text{ VC params}) + (\\# \\text{ SNP effect}) \\approx 20$\n",
    "        - **Isn't it true that only the SNP effect should be allowed to vary? So $n = 1$?**\n",
    "+ Source: https://gist.github.com/ForceBru/63a08b62cb4bdf6a6d8bc23924929d48\n",
    "+ We add a few more recent packages (e.g. Enzyme) to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling ReverseDiff [37e2e3b7-166d-5795-8a7a-e32c996b4267]\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling Zygote [e88e6eb3-aa80-5325-afca-941959d7151f]\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling AdaptStaticArraysExt [e1699a77-9e31-5da8-bb3e-0a796f95f0a0]\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling ConstructionBaseStaticArraysExt [8497ba20-d017-5d93-8a79-2639523b7219]\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling StructArraysStaticArraysExt [d1e1e8be-46cf-5459-abb8-be6c7518b661]\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling Symbolics [0c5d862f-8b57-4792-8d23-62f2024744c7]\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling RecursiveArrayToolsZygoteExt [6283b665-1224-52f5-a8f0-5953a1198cc4]\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling PreallocationToolsReverseDiffExt [723d033e-e474-5c37-8984-530550ab56d4]\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling ZygoteExt [bd76389b-fe7c-5b99-904d-52391854d323]\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling BenchmarkTools [6e4b80f9-dd63-53aa-95a3-0cdb28fa8baf]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threads.nthreads() = 1\n",
      "\u001b[36m\u001b[1mProject\u001b[22m\u001b[39m QuasiCopula v0.1.1\n",
      "\u001b[32m\u001b[1mStatus\u001b[22m\u001b[39m `~/.julia/dev/QuasiCopula/Project.toml`\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[f65535da] \u001b[39mConvex v0.14.18\n",
      "  \u001b[90m[a93c6f00] \u001b[39mDataFrames v1.6.1\n",
      "  \u001b[90m[31c24e10] \u001b[39mDistributions v0.25.107\n",
      "  \u001b[90m[7da242da] \u001b[39mEnzyme v0.11.19\n",
      "  \u001b[90m[7a1cc6ca] \u001b[39mFFTW v1.8.0\n",
      "  \u001b[90m[f6369f11] \u001b[39mForwardDiff v0.10.36\n",
      "  \u001b[90m[38e38edf] \u001b[39mGLM v1.9.0\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[b6b21f68] \u001b[39mIpopt v0.8.0\n",
      "  \u001b[90m[bdcacae8] \u001b[39mLoopVectorization v0.12.166\n",
      "  \u001b[90m[fdba3010] \u001b[39mMathProgBase v0.7.8\n",
      "  \u001b[90m[92933f4c] \u001b[39mProgressMeter v1.10.0\n",
      "  \u001b[90m[189a3867] \u001b[39mReexport v1.2.2\n",
      "  \u001b[90m[4e780e97] \u001b[39mSnpArrays v0.3.21\n",
      "  \u001b[90m[276daf66] \u001b[39mSpecialFunctions v2.3.1\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[4c63d2b9] \u001b[39mStatsFuns v0.9.18\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[c751599d] \u001b[39mToeplitzMatrices v0.7.1\n",
      "  \u001b[90m[37e2e46d] \u001b[39mLinearAlgebra\n",
      "  \u001b[90m[9a3f8284] \u001b[39mRandom\n",
      "\u001b[36m\u001b[1mInfo\u001b[22m\u001b[39m Packages marked with \u001b[33m⌅\u001b[39m have new versions available but compatibility constraints restrict them from upgrading. To see why use `status --outdated`\n"
     ]
    }
   ],
   "source": [
    "# ml julia/1.9 python/3.9.0\n",
    "using Random, DelimitedFiles\n",
    "using ForwardDiff, ReverseDiff, Zygote, Symbolics, Enzyme\n",
    "using LinearAlgebra\n",
    "using BenchmarkTools\n",
    "using Pkg\n",
    "ENV[\"COLUMNS\"] = 240\n",
    "\n",
    "BLAS.set_num_threads(1)\n",
    "@show Threads.nthreads()\n",
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params0 = [0.6509560930859444, 0.17036894385064993, 0.21319596776697636, 0.4705968797513471, 0.9066124779371352, -0.7596053407203316, 0.4501019833316699, -0.03382219163257187, -0.01866041173235008, 1.4306488869677423, 0.7822675207825798, 1.238815697809096, 1.9650279191800957, 1.9106539785480954, 1.1385080309238362]\n",
      "objective(params0) = -7473.507394000162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mSettings\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  SEED = 42\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  N_SAMPLES = 10000\n",
      "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  N_COMPONENTS = 5\n",
      "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m  length(params0) = 15\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mGenerating gradient functions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_gradient(fname, K) = 5482\n",
      "generate_gradient(fname, K) = 9638\n",
      "generate_gradient(fname, K) = 14985\n",
      "generate_gradient(fname, K) = 21520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "my_gradient! (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========== Benchmark setup ==========\n",
    "SEED = 42\n",
    "N_SAMPLES = 10000\n",
    "N_COMPONENTS = 5\n",
    "\n",
    "rnd = Random.MersenneTwister(SEED)\n",
    "data = randn(rnd, N_SAMPLES)\n",
    "params0 = [rand(rnd, N_COMPONENTS); randn(rnd, N_COMPONENTS); 2rand(rnd, N_COMPONENTS)]\n",
    "\n",
    "# save file to be read into python later\n",
    "DelimitedFiles.writedlm(\"gen_data.csv\", data, ',')\n",
    "DelimitedFiles.writedlm(\"gen_params0.csv\", params0, ',')\n",
    "\n",
    "# ========== Objective function ==========\n",
    "\n",
    "normal_pdf(x::Real, mean::Real, var::Real) =\n",
    "    exp(-(x - mean)^2 / (2var)) / sqrt(2π * var)\n",
    "\n",
    "mixture_pdf(x::Real, weights::AbstractVector{<:Real}, means::AbstractVector{<:Real}, vars::AbstractVector{<:Real}) =\n",
    "    sum(\n",
    "        w * normal_pdf(x, mean, var)\n",
    "        for (w, mean, var) in zip(weights, means, vars)\n",
    "    )\n",
    "\n",
    "normal_pdf(x, mean, var) =\n",
    "    exp(-(x - mean)^2 / (2var)) / sqrt(2π * var)\n",
    "\n",
    "\n",
    "function mixture_loglikelihood(params::AbstractVector, data::AbstractVector)\n",
    "    K = length(params) ÷ 3\n",
    "    weights, means, stds = @views params[1:K], params[K+1:2K], params[2K+1:end]\n",
    "    mat = normal_pdf.(data, means', stds' .^2) # (N, K)\n",
    "    #@show size(mat)\n",
    "\n",
    "    # original objective (doesn't work)\n",
    "    sum(mat .* weights', dims=2) .|> log |> sum\n",
    "\n",
    "    # another form of original objective commented out by the original author (same issue)\n",
    "#     sum(\n",
    "#         sum(\n",
    "#             weight * normal_pdf(x, mean, std^2)\n",
    "#             for (weight, mean, std) in zip(weights, means, stds)\n",
    "#         ) |> log\n",
    "#         for x in data\n",
    "#     )\n",
    "\n",
    "    # objective re-written by me (same issue)\n",
    "#     obj = zero(eltype(mat))\n",
    "#     for x in data\n",
    "#         obj_i = zero(eltype(mat))\n",
    "#         for (weight, mean, std) in zip(weights, means, stds)\n",
    "#             obj_i += weight * normal_pdf(x, mean, std^2)\n",
    "#         end\n",
    "#         obj += log(obj_i)\n",
    "#     end\n",
    "#     return obj\n",
    "end\n",
    "        \n",
    "objective = params -> mixture_loglikelihood(params, data)\n",
    "        \n",
    "function generate_gradient(out_fname::AbstractString, K::Integer)\n",
    "    @assert K > 0\n",
    "    Symbolics.@variables x ws[1:K] mus[1:K] stds[1:K]\n",
    "\n",
    "    args=[x, ws, mus, stds]\n",
    "    expr = Symbolics.gradient(\n",
    "        mixture_pdf(x, ws, mus, collect(stds) .^2) |> log,\n",
    "        [ws; mus; stds]\n",
    "    )\n",
    "\n",
    "    fn, fn_mut = Symbolics.build_function(expr, args...)\n",
    "    \n",
    "    write(out_fname, string(fn_mut))\n",
    "end\n",
    "\n",
    "        \n",
    "@show params0\n",
    "@show objective(params0)\n",
    "@info \"Settings\" SEED N_SAMPLES N_COMPONENTS length(params0)\n",
    "\n",
    "        \n",
    "# ========== Gradient with Symbolics.jl ==========\n",
    "@info \"Generating gradient functions...\"\n",
    "GRAD_FNS = Union{Nothing, Function}[nothing]\n",
    "for K in 2:5\n",
    "    fname = \"grad_$K.jl\"\n",
    "    @show generate_gradient(fname, K)\n",
    "    push!(GRAD_FNS, include(fname))\n",
    "end\n",
    "\n",
    "function my_gradient!(out::AbstractVector{<:Real}, tmp::AbstractVector{<:Real}, xs::AbstractVector{<:Real}, params::AbstractVector{<:Real})\n",
    "    K = length(params) ÷ 3\n",
    "    grad! = GRAD_FNS[K]\n",
    "    weights, means, stds = @views params[1:K], params[K+1:2K], params[2K+1:end]\n",
    "\n",
    "    out .= 0\n",
    "    for x in xs\n",
    "        grad!(tmp, x, weights, means, stds)\n",
    "        out .+= tmp\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mComputing gradient w/ Symbolics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BenchmarkTools.Trial: 2355 samples with 1 evaluation.\n",
      " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m13.548 ms\u001b[22m\u001b[39m … \u001b[35m60.095 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 36.85%\n",
      " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m24.025 ms              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
      " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m25.324 ms\u001b[22m\u001b[39m ± \u001b[32m 8.043 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m1.59% ±  5.96%\n",
      "\n",
      "  \u001b[39m \u001b[39m▂\u001b[39m▃\u001b[39m \u001b[39m▂\u001b[39m▅\u001b[39m█\u001b[39m▆\u001b[39m▃\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m▂\u001b[39m \u001b[39m▂\u001b[39m \u001b[34m \u001b[39m\u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
      "  \u001b[39m▃\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m▆\u001b[32m█\u001b[39m\u001b[39m▇\u001b[39m▆\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▄\u001b[39m▅\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▄\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▄\u001b[39m▅\u001b[39m▃\u001b[39m▄\u001b[39m▃\u001b[39m▂\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m \u001b[39m▄\n",
      "  13.5 ms\u001b[90m         Histogram: frequency by time\u001b[39m        45.1 ms \u001b[0m\u001b[1m<\u001b[22m\n",
      "\n",
      " Memory estimate\u001b[90m: \u001b[39m\u001b[33m1.53 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m40000\u001b[39m.\n",
      "grad_storage = [5297.814324727771, 4763.559259051071, 3824.584066250456, 3896.8509982052637, 3408.9108396746533, 1058.3192613979916, -149.3750859436761, -22.473937315596725, -56.84715458264533, -1741.7742573028104, -603.9101820698644, -298.7284555458687, -285.90024618985814, -649.5577894738499, -202.70373627213493]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mComputing gradient w/ ForwardDiff\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BenchmarkTools.Trial: 4381 samples with 1 evaluation.\n",
      " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m 5.645 ms\u001b[22m\u001b[39m … \u001b[35m45.086 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m 0.00% … 70.33%\n",
      " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m11.848 ms              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m 0.00%\n",
      " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m13.605 ms\u001b[22m\u001b[39m ± \u001b[32m 5.503 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m11.24% ± 13.25%\n",
      "\n",
      "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▅\u001b[39m▅\u001b[39m█\u001b[39m█\u001b[39m▄\u001b[39m▄\u001b[39m▅\u001b[39m▇\u001b[39m▆\u001b[39m▇\u001b[34m▄\u001b[39m\u001b[39m▁\u001b[39m▂\u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
      "  \u001b[39m▂\u001b[39m▃\u001b[39m▃\u001b[39m▄\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[32m█\u001b[39m\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▄\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▄\n",
      "  5.65 ms\u001b[90m         Histogram: frequency by time\u001b[39m        30.3 ms \u001b[0m\u001b[1m<\u001b[22m\n",
      "\n",
      " Memory estimate\u001b[90m: \u001b[39m\u001b[33m14.65 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m13\u001b[39m.\n",
      "grad_storage = [5297.814324727781, 4763.559259051062, 3824.584066250455, 3896.850998205265, 3408.9108396746506, 1058.31926139799, -149.3750859436756, -22.473937315596658, -56.847154582645175, -1741.7742573028136, -603.9101820698634, -298.7284555458693, -285.90024618985785, -649.5577894738494, -202.70373627213496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mComputing gradient w/ ReverseDiff\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BenchmarkTools.Trial: 596 samples with 1 evaluation.\n",
      " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m 65.397 ms\u001b[22m\u001b[39m … \u001b[35m176.319 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
      " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m 96.394 ms               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
      " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m100.475 ms\u001b[22m\u001b[39m ± \u001b[32m 18.937 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
      "\n",
      "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\u001b[39m▅\u001b[39m█\u001b[39m▅\u001b[39m▃\u001b[39m▆\u001b[39m▅\u001b[39m▃\u001b[39m \u001b[39m▇\u001b[34m▅\u001b[39m\u001b[39m▃\u001b[39m▂\u001b[32m▂\u001b[39m\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
      "  \u001b[39m▂\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m▆\u001b[39m▅\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▄\u001b[39m▅\u001b[39m▄\u001b[39m▃\u001b[39m▄\u001b[39m▄\u001b[39m▅\u001b[39m▃\u001b[39m▄\u001b[39m▃\u001b[39m▂\u001b[39m▄\u001b[39m▃\u001b[39m▄\u001b[39m▃\u001b[39m▂\u001b[39m▄\u001b[39m▃\u001b[39m▂\u001b[39m▄\u001b[39m▃\u001b[39m▂\u001b[39m▃\u001b[39m▂\u001b[39m▁\u001b[39m▃\u001b[39m▂\u001b[39m \u001b[39m▄\n",
      "  65.4 ms\u001b[90m          Histogram: frequency by time\u001b[39m          159 ms \u001b[0m\u001b[1m<\u001b[22m\n",
      "\n",
      " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m.\n",
      "grad_storage = [5297.814324727782, 4763.559259051035, 3824.5840662504697, 3896.850998205266, 3408.9108396746446, 1058.319261397994, -149.37508594367515, -22.473937315596675, -56.847154582645295, -1741.7742573028147, -603.9101820698661, -298.728455545868, -285.90024618985916, -649.5577894738507, -202.70373627213405]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mComputing gradient w/ Zygote reverse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BenchmarkTools.Trial: 10000 samples with 1 evaluation.\n",
      " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m2.334 ms\u001b[22m\u001b[39m … \u001b[35m35.828 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 77.48%\n",
      " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m4.797 ms              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
      " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m5.136 ms\u001b[22m\u001b[39m ± \u001b[32m 2.152 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m7.14% ± 13.47%\n",
      "\n",
      "  \u001b[39m \u001b[39m \u001b[39m█\u001b[39m▅\u001b[39m \u001b[39m \u001b[39m▅\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▃\u001b[39m▄\u001b[39m \u001b[39m \u001b[39m▂\u001b[34m▃\u001b[39m\u001b[39m▃\u001b[32m▂\u001b[39m\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
      "  \u001b[39m▃\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m \u001b[39m▃\n",
      "  2.33 ms\u001b[90m        Histogram: frequency by time\u001b[39m        12.1 ms \u001b[0m\u001b[1m<\u001b[22m\n",
      "\n",
      " Memory estimate\u001b[90m: \u001b[39m\u001b[33m5.12 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m166\u001b[39m.\n",
      "grad_storage = ([5297.814324727781, 4763.559259051062, 3824.584066250455, 3896.850998205265, 3408.9108396746506, 1058.31926139799, -149.3750859436756, -22.473937315596658, -56.84715458264516, -1741.7742573028136, -603.9101820698637, -298.72845554586917, -285.9002461898578, -649.5577894738494, -202.70373627213468],)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mComputing gradient w/ Enzyme reverse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BenchmarkTools.Trial: 1 sample with 1 evaluation.\n",
      " Single result which took \u001b[34m3.826 ms\u001b[39m (0.00% GC) to evaluate,\n",
      " with a memory estimate of \u001b[33m1.83 MiB\u001b[39m, over \u001b[33m58\u001b[39m allocations.\n",
      "grad_storage = [5297.814324727782, 4763.559259051035, 3824.5840662504697, 3896.850998205266, 3408.9108396746446, 1058.3192613979938, -149.37508594367515, -22.473937315596682, -56.84715458264528, -1741.7742573028147, -603.9101820698656, -298.72845554586803, -285.9002461898592, -649.5577894738506, -202.70373627213408]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "@info \"Computing gradient w/ Symbolics\"\n",
    "let\n",
    "    grad_storage = similar(params0)\n",
    "    tmp = similar(params0)\n",
    "\n",
    "    # 1. Compile\n",
    "    my_gradient!(grad_storage, tmp, data, params0)\n",
    "    # 2. Benchmark\n",
    "    trial = run(@benchmarkable $my_gradient!($grad_storage, $tmp, $data, $params0) samples=10_000 evals=1 seconds=60)\n",
    "    show(stdout, MIME(\"text/plain\"), trial)\n",
    "    println()\n",
    "    @show grad_storage\n",
    "end\n",
    "\n",
    "@info \"Computing gradient w/ ForwardDiff\"\n",
    "let\n",
    "    grad_storage = similar(params0)\n",
    "    cfg_grad = ForwardDiff.GradientConfig(objective, params0, ForwardDiff.Chunk{length(params0)}())\n",
    "\n",
    "    # 1. Compile\n",
    "    ForwardDiff.gradient!(grad_storage, objective, params0, cfg_grad)\n",
    "    # 2. Benchmark\n",
    "    trial = run(@benchmarkable ForwardDiff.gradient!($grad_storage, $objective, $params0, $cfg_grad) samples=10_000 evals=1 seconds=60)\n",
    "    show(stdout, MIME(\"text/plain\"), trial)\n",
    "    println()\n",
    "    @show grad_storage\n",
    "end\n",
    "\n",
    "@info \"Computing gradient w/ ReverseDiff\"\n",
    "let\n",
    "    grad_storage = similar(params0)\n",
    "    objective_tape = ReverseDiff.GradientTape(objective, params0) |> ReverseDiff.compile\n",
    "\n",
    "    # 1. Compile\n",
    "    ReverseDiff.gradient!(grad_storage, objective_tape, params0)\n",
    "    # 2. Benchmark\n",
    "    trial = run(@benchmarkable ReverseDiff.gradient!($grad_storage, $objective_tape, $params0) samples=10_000 evals=1 seconds=60)\n",
    "    show(stdout, MIME(\"text/plain\"), trial)\n",
    "    println()\n",
    "    @show grad_storage\n",
    "end\n",
    "\n",
    "@info \"Computing gradient w/ Zygote reverse\"\n",
    "let\n",
    "    # 1. Compile\n",
    "    grad_storage = Zygote.gradient(objective, params0)\n",
    "    # 2. Benchmark\n",
    "    trial = run(@benchmarkable Zygote.gradient($objective, $params0) samples=10_000 evals=1 seconds=60)\n",
    "    show(stdout, MIME(\"text/plain\"), trial)\n",
    "    println()\n",
    "    @show grad_storage\n",
    "end\n",
    "\n",
    "@info \"Computing gradient w/ Enzyme reverse\"\n",
    "let\n",
    "    # 1. Compile\n",
    "    grad_storage = zeros(length(params0))\n",
    "    # 2. Benchmark\n",
    "    trial = run(@benchmarkable Enzyme.gradient!($Reverse, $grad_storage, $objective, $params0) samples=10_000 evals=1 seconds=60)\n",
    "    show(stdout, MIME(\"text/plain\"), trial)\n",
    "    println()\n",
    "    @show grad_storage\n",
    "end\n",
    "\n",
    "println(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mComputing gradient w/ Enzyme reverse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BenchmarkTools.Trial: 10000 samples with 1 evaluation.\n",
      " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m2.600 ms\u001b[22m\u001b[39m … \u001b[35m23.682 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 32.41%\n",
      " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m3.245 ms              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
      " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m3.525 ms\u001b[22m\u001b[39m ± \u001b[32m 1.188 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m4.77% ± 10.43%\n",
      "\n",
      "  \u001b[39m \u001b[39m▅\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[34m▅\u001b[39m\u001b[39m▂\u001b[39m▁\u001b[32m▂\u001b[39m\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
      "  \u001b[39m▅\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m \u001b[39m▃\n",
      "  2.6 ms\u001b[90m         Histogram: frequency by time\u001b[39m        9.73 ms \u001b[0m\u001b[1m<\u001b[22m\n",
      "\n",
      " Memory estimate\u001b[90m: \u001b[39m\u001b[33m1.83 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m58\u001b[39m.\n",
      "grad_storage = [5297.814324727782, 4763.559259051035, 3824.5840662504697, 3896.850998205266, 3408.9108396746446, 1058.3192613979938, -149.37508594367515, -22.473937315596682, -56.84715458264528, -1741.7742573028147, -603.9101820698656, -298.72845554586803, -285.9002461898592, -649.5577894738506, -202.70373627213408]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15-element Vector{Float64}:\n",
       "  5297.814324727782\n",
       "  4763.559259051035\n",
       "  3824.5840662504697\n",
       "  3896.850998205266\n",
       "  3408.9108396746446\n",
       "  1058.3192613979938\n",
       "  -149.37508594367515\n",
       "   -22.473937315596682\n",
       "   -56.84715458264528\n",
       " -1741.7742573028147\n",
       "  -603.9101820698656\n",
       "  -298.72845554586803\n",
       "  -285.9002461898592\n",
       "  -649.5577894738506\n",
       "  -202.70373627213408"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@info \"Computing gradient w/ Enzyme reverse\"\n",
    "let\n",
    "    # 1. Compile\n",
    "    grad_storage = zeros(length(params0))\n",
    "    # 2. Benchmark\n",
    "    trial = run(@benchmarkable Enzyme.gradient!($Reverse, $grad_storage, $objective, $params0) samples=10_000 evals=1 seconds=60)\n",
    "    show(stdout, MIME(\"text/plain\"), trial)\n",
    "    println()\n",
    "    @show grad_storage\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JAX (python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7473.507394000162\n",
      "[ 5297.81432473  4763.55925905  3824.58406625  3896.85099821\n",
      "  3408.91083967  1058.3192614   -149.37508594   -22.47393732\n",
      "   -56.84715458 -1741.7742573   -603.91018207  -298.72845555\n",
      "  -285.90024619  -649.55778947  -202.70373627]\n",
      "2515.012 μs ± 718.190 μs (10000 samples with 1 evaluation)\n"
     ]
    }
   ],
   "source": [
    "# install: /share/software/user/open/python/3.9.0/bin/pip3 install --upgrade \"jax[cpu]\"\n",
    "# test run: /share/software/user/open/python/3.9.0/bin/python3.9\n",
    "\n",
    "import timeit\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# Enable float64 support\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "@jax.jit\n",
    "def normal_pdf(data, mean, var):\n",
    "    return jnp.exp(-(data - mean)**2 / (2 * var)) / jnp.sqrt(2 * jnp.pi * var)\n",
    "\n",
    "@jax.jit\n",
    "def mixture_loglikelihood(params: jnp.ndarray, data: jnp.ndarray)  -> float:\n",
    "    K = len(params) // 3\n",
    "    weights, means, stds = params[:K], params[K:2*K], params[2*K:]\n",
    "    mat = normal_pdf(data, means.T, stds.T**2) # (N, K)\n",
    "    return jnp.log((mat * weights.T).sum(1)).sum()\n",
    "\n",
    "data = np.loadtxt(\"gen_data.csv\").flatten()[:, None]\n",
    "params0 = np.loadtxt(\"gen_params0.csv\").flatten()\n",
    "params0 = jnp.array(params0)\n",
    "\n",
    "objective = lambda params: mixture_loglikelihood(params, data)\n",
    "\n",
    "print(objective(params0))\n",
    "# Output: -443.40397372007186\n",
    "\n",
    "the_grad = jax.jit(jax.grad(objective))\n",
    "\n",
    "print(the_grad(params0))\n",
    "# Output: [289.73084956 199.27559525 236.68945778 292.06123402  -9.42979939\n",
    "#  26.72229565  -1.91803555  37.9874909  -24.09562015 -13.93568733\n",
    "# -38.00044666  12.87712892]\n",
    "\n",
    "# ========== Benchmark ==========\n",
    "N_SAMPLES, N_EVALS = 10_000, 1 # like in Julia\n",
    "bench_secs = timeit.repeat(\n",
    "    \"the_grad(params0)\", globals={'the_grad': the_grad, 'params0': params0},\n",
    "    repeat=N_SAMPLES, number=N_EVALS\n",
    ")\n",
    "bench_mus = 1_000_000 * np.array(bench_secs)\n",
    "\n",
    "print(f\"{bench_mus.mean():.3f} μs ± {bench_mus.std():.3f} μs ({N_SAMPLES} samples with {N_EVALS} evaluation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Symbolics.jl\n",
    "24.025 ms\n",
    "ForwardDiff.jl\n",
    "11.848 ms\n",
    "ReverseDiff.jl\n",
    "96.394 ms\n",
    "Zygote.jl (reverse)\n",
    "4.797 ms\n",
    "Enzyme.jl (reverse mode)\n",
    "3.245 ms\n",
    "JAX (python)\n",
    "2.515 ms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does Enzyme.jl/Zygote.jl support BLAS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Enzyme\n",
    "using Zygote\n",
    "using LinearAlgebra\n",
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enzyme.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50×4 Matrix{Float64}:\n",
       "  223.421      223.421      223.421      223.421\n",
       "   56.115       56.115       56.115       56.115\n",
       "  162.285      162.285      162.285      162.285\n",
       "  -58.6251     -58.6251     -58.6251     -58.6251\n",
       "  109.732      109.732      109.732      109.732\n",
       " -152.867     -152.867     -152.867     -152.867\n",
       "   51.7608      51.7608      51.7608      51.7608\n",
       "  -64.8512     -64.8512     -64.8512     -64.8512\n",
       "   38.8877      38.8877      38.8877      38.8877\n",
       "  -62.3895     -62.3895     -62.3895     -62.3895\n",
       "   92.2303      92.2303      92.2303      92.2303\n",
       "  208.785      208.785      208.785      208.785\n",
       "   47.6175      47.6175      47.6175      47.6175\n",
       "    ⋮                                   \n",
       "  -26.5664     -26.5664     -26.5664     -26.5664\n",
       "   65.8905      65.8905      65.8905      65.8905\n",
       "  279.925      279.925      279.925      279.925\n",
       "  -18.8817     -18.8817     -18.8817     -18.8817\n",
       " -169.649     -169.649     -169.649     -169.649\n",
       " -134.628     -134.628     -134.628     -134.628\n",
       "  273.975      273.975      273.975      273.975\n",
       "    0.220214     0.220214     0.220214     0.220214\n",
       " -130.344     -130.344     -130.344     -130.344\n",
       "   -3.59516     -3.59516     -3.59516     -3.59516\n",
       "  204.023      204.023      204.023      204.023\n",
       " -268.678     -268.678     -268.678     -268.678"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# objective = 0.5 || y - X*beta ||^2\n",
    "function ols(y, X, beta)\n",
    "    storage = X * beta\n",
    "    obj = zero(eltype(beta))\n",
    "    for i in eachindex(y)\n",
    "        obj += abs2(y[i] - storage[i])\n",
    "    end\n",
    "    return 0.5obj\n",
    "end\n",
    "ols(beta::AbstractVector) = ols(y, X, beta)\n",
    "\n",
    "# simulate data\n",
    "n = 100\n",
    "p = 50\n",
    "X = randn(n, p)\n",
    "y = randn(n)\n",
    "beta = randn(p)\n",
    "ols(y, X, beta)\n",
    "\n",
    "# autodiff grad\n",
    "grad1 = zeros(length(beta))\n",
    "Enzyme.gradient!(Reverse, grad1, ols, beta) # method 1\n",
    "grad2 = Enzyme.gradient(Reverse, ols, beta) # method 2\n",
    "grad3 = zeros(length(beta))\n",
    "Enzyme.autodiff(Reverse, ols, Active, Duplicated(beta, grad3)) # method 3\n",
    "\n",
    "# analytical grad\n",
    "true_grad = -X' * (y - X*beta)\n",
    "\n",
    "# compare answers\n",
    "[true_grad grad1 grad2 grad3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zygote.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50×2 Matrix{Float64}:\n",
       "  -30.7309    -30.7309\n",
       "   75.0246     75.0246\n",
       "   -9.56967    -9.56967\n",
       "  -60.3384    -60.3384\n",
       "   86.1821     86.1821\n",
       "  245.025     245.025\n",
       "   51.3395     51.3395\n",
       "   39.1938     39.1938\n",
       "   45.1931     45.1931\n",
       "  -25.5218    -25.5218\n",
       "  106.324     106.324\n",
       "  -13.0246    -13.0246\n",
       "   18.577      18.577\n",
       "    ⋮        \n",
       "   -4.90943    -4.90943\n",
       " -158.693    -158.693\n",
       "   13.4801     13.4801\n",
       "  -47.8658    -47.8658\n",
       "   60.1435     60.1435\n",
       "   93.3104     93.3104\n",
       "   -3.67877    -3.67877\n",
       "   44.3463     44.3463\n",
       "   38.8036     38.8036\n",
       "   82.8235     82.8235\n",
       "  155.893     155.893\n",
       " -187.871    -187.871"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# objective = 0.5 || y - X*beta ||^2\n",
    "function ols(y, X, beta)\n",
    "    storage = X * beta\n",
    "    obj = zero(eltype(beta))\n",
    "    for i in eachindex(y)\n",
    "        obj += abs2(y[i] - storage[i])\n",
    "    end\n",
    "    return 0.5obj\n",
    "end\n",
    "ols(beta::AbstractVector) = ols(y, X, beta)\n",
    "\n",
    "# simulate data\n",
    "n = 100\n",
    "p = 50\n",
    "X = randn(n, p)\n",
    "y = randn(n)\n",
    "beta = randn(p)\n",
    "storage1 = zeros(n)\n",
    "storage2 = zeros(n)\n",
    "ols(y, X, beta)\n",
    "\n",
    "# autodiff grad\n",
    "grad_storage = Zygote.gradient(ols, beta)\n",
    "\n",
    "# analytical grad\n",
    "true_grad = -X' * (y - X*beta)\n",
    "\n",
    "# compare answers\n",
    "[true_grad grad_storage[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "ForwardDiff.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50×2 Matrix{Float64}:\n",
       "  101.766     101.766\n",
       " -142.45     -142.45\n",
       "  183.354     183.354\n",
       "  -48.4099    -48.4099\n",
       "   21.6648     21.6648\n",
       "  -33.7665    -33.7665\n",
       "  -38.6346    -38.6346\n",
       "  -50.3303    -50.3303\n",
       "  -49.5342    -49.5342\n",
       "  -37.1839    -37.1839\n",
       "   42.0213     42.0213\n",
       " -161.4      -161.4\n",
       "  119.435     119.435\n",
       "    ⋮        \n",
       "  -89.8549    -89.8549\n",
       " -171.656    -171.656\n",
       "  124.696     124.696\n",
       "   48.1196     48.1196\n",
       "  -32.7268    -32.7268\n",
       "    9.2581      9.2581\n",
       "   39.0069     39.0069\n",
       "  -83.9941    -83.9941\n",
       "  -17.3246    -17.3246\n",
       "  274.159     274.159\n",
       "    4.91454     4.91454\n",
       " -106.634    -106.634"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using ForwardDiff\n",
    "\n",
    "function A_mul_b!(c::AbstractVector{T}, A::AbstractMatrix, b::AbstractVector) where T\n",
    "    n, p = size(A)\n",
    "    fill!(c, zero(T))\n",
    "    for j in 1:p, i in 1:n\n",
    "        c[i] += A[i, j] * b[j]\n",
    "    end\n",
    "    return c\n",
    "end\n",
    "\n",
    "function ols(y, X, beta, storage=zeros(eltype(beta), size(X, 1)))\n",
    "    A_mul_b!(storage, X, beta)\n",
    "    storage .= y .- storage\n",
    "    return 0.5 * sum(abs2, storage)\n",
    "end\n",
    "ols(beta::AbstractVector) = ols(y, X, beta)\n",
    "\n",
    "# simulate data\n",
    "n = 100\n",
    "p = 50\n",
    "X = randn(n, p)\n",
    "y = randn(n)\n",
    "beta = randn(p)\n",
    "storage = zeros(n)\n",
    "ols(y, X, beta, storage)\n",
    "\n",
    "grad = ForwardDiff.gradient(ols, beta)\n",
    "true_grad = -X' * (y - X*beta)\n",
    "[true_grad grad]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Does Enzyme.jl/Zygote.jl work with `struct`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.153032 seconds (251.62 k allocations: 12.037 MiB, 99.30% compilation time: 100% of which was recompilation)\n",
      "  0.367664 seconds (676.90 k allocations: 1.521 GiB, 21.31% gc time, 32.68% compilation time: 100% of which was recompilation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50×3 Matrix{Float64}:\n",
       "  10958.1     10958.1     10958.1\n",
       "   6872.77     6872.77     6872.77\n",
       "   4268.43     4268.43     4268.43\n",
       "  -6559.18    -6559.18    -6559.18\n",
       "     -1.629      -1.629      -1.629\n",
       "   1296.32     1296.32     1296.32\n",
       "   9705.7      9705.7      9705.7\n",
       "  -9632.29    -9632.29    -9632.29\n",
       " -20403.3    -20403.3    -20403.3\n",
       "  -7022.28    -7022.28    -7022.28\n",
       "   4736.58     4736.58     4736.58\n",
       "   5876.46     5876.46     5876.46\n",
       " -20949.6    -20949.6    -20949.6\n",
       "      ⋮                  \n",
       " -18599.9    -18599.9    -18599.9\n",
       "  -7730.13    -7730.13    -7730.13\n",
       "  -9266.25    -9266.25    -9266.25\n",
       "    713.507     713.507     713.507\n",
       "  -4060.83    -4060.83    -4060.83\n",
       "  11029.0     11029.0     11029.0\n",
       "  -8578.22    -8578.22    -8578.22\n",
       "  23480.5     23480.5     23480.5\n",
       "  16420.2     16420.2     16420.2\n",
       "  -9767.68    -9767.68    -9767.68\n",
       "  -3973.54    -3973.54    -3973.54\n",
       "   1664.5      1664.5      1664.5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Enzyme\n",
    "using Zygote\n",
    "using LinearAlgebra\n",
    "\n",
    "struct MyData\n",
    "    X::Matrix{Float64}\n",
    "    y::Vector{Float64}\n",
    "    storage::Vector{Float64}\n",
    "end\n",
    "\n",
    "# objective = 0.5 || y - X*beta ||^2\n",
    "function ols(data::MyData, beta)\n",
    "    storage = data.X * beta # works\n",
    "#     mul!(data.storage, data.X, beta)\n",
    "    obj = zero(eltype(data.X))\n",
    "    for i in eachindex(data.y)\n",
    "        obj += abs2(data.y[i] - storage[i])\n",
    "    end\n",
    "    return 0.5obj\n",
    "end\n",
    "ols(beta::AbstractVector) = ols(data, beta)\n",
    "\n",
    "# simulate data\n",
    "n = 10000\n",
    "p = 50\n",
    "X = randn(n, p)\n",
    "y = randn(n)\n",
    "beta = randn(p)\n",
    "storage = zeros(n)\n",
    "data = MyData(X, y, storage)\n",
    "ols(data, beta)\n",
    "\n",
    "# autodiff grad\n",
    "grad = zeros(length(beta))\n",
    "@time Enzyme.autodiff(Reverse, ols, Active, Duplicated(beta, grad))\n",
    "\n",
    "# zygote grad\n",
    "@time grad2 = Zygote.gradient(ols, beta)[1]\n",
    "\n",
    "# analytical grad\n",
    "true_grad = -X' * (y - X*beta)\n",
    "\n",
    "# compare answers\n",
    "[true_grad grad grad2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.9.1",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
