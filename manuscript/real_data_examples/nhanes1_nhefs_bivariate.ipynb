{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NHANES I (NHEFS): Bivariate Counts Real Data Example:\n",
    "\n",
    "In this notebook I use the [National Health and Nutrition Examination Survey Data I (NHANES 1) Epidemiologic Follow-up Study (NHEFS)](https://wwwn.cdc.gov/nchs/nhanes/nhefs/).\n",
    "\n",
    "The data can be found in the [R package: causaldata](https://cran.r-project.org/web/packages/causaldata/causaldata.pdf), we will use the `RCall` package to access it and transform it from wide to long format for analysis.\n",
    "\n",
    "We will compare the estimates, loglikelihoods and run times of the random intercept regression model with Poisson, negative Binomial and Bernoulli base distribution using QuasiCopula.jl vs. MixedModels.jl.\n",
    "\n",
    "Regression Model:\n",
    "    - GROUPING: We will cluster by ID variable (seqn)\n",
    "    - COVARIATES: Average price of tobacco in the state of residence (price)\n",
    "    \n",
    "    - OUTCOMES: Each outcome vector is a bivariate vector of the following:\n",
    "    (1) NUMBER OF CIGARETTES SMOKED PER DAY IN 1971\n",
    "    (2) NUMBER OF CIGARETTES SMOKED PER DAY IN 1982\n",
    "    \n",
    "### Table of Contents:\n",
    "* [Read in the dataset](#Read-in-the-dataset)\n",
    "* [Check overdispersion](#Check-overdispersion-using-empirical-mean-and-variance)\n",
    "\n",
    "\n",
    "\n",
    "* [Example 1: Poisson Base Distribution](#Example-1:-Poisson-Base-Distribution)\n",
    "* [Example 2: Negative Binomial Base Distribution](#Example-2:-NB-Base-Distribution)\n",
    "* [Example 3: Bernoulli Base Distribution](#Example-3:-Bernoulli-Base-Distribution)\n",
    "\n",
    "\n",
    "\n",
    "* [Comparisons](#Comparisons)\n",
    "\n",
    "For the Bernoulli base distribution in Example 3, we transform each outcome = 1 if the number of of cigarettes smoked per day > mean(number of cigarettes smoked per day).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.6.2\n",
      "Commit 1b93d53fc4 (2021-07-14 15:36 UTC)\n",
      "Platform Info:\n",
      "  OS: macOS (x86_64-apple-darwin18.7.0)\n",
      "  CPU: Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-11.0.1 (ORCJIT, skylake)\n",
      "Environment:\n",
      "  JULIA_NUM_THREADS = 8\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using QuasiCopula, LinearAlgebra, DataFrames, GLM\n",
    "using RCall, MixedModels, ProgressMeter\n",
    "ProgressMeter.ijulia_behavior(:clear);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLAS.set_num_threads(1)\n",
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the dataset\n",
    "\n",
    "The data can be found in the [R package: causaldata](https://cran.r-project.org/web/packages/causaldata/causaldata.pdf), we will use the `RCall` package to access it and transform it from wide to long format for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>3,074 rows × 5 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>seqn</th><th>time</th><th>smoke</th><th>price</th><th>id</th></tr><tr><th></th><th title=\"String\">String</th><th title=\"Int64\">Int64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Int64\">Int64</th></tr></thead><tbody><tr><th>1</th><td>233.0</td><td>1</td><td>30.0</td><td>2.18359</td><td>1</td></tr><tr><th>2</th><td>233.0</td><td>2</td><td>20.0</td><td>1.73999</td><td>1</td></tr><tr><th>3</th><td>235.0</td><td>1</td><td>20.0</td><td>2.34668</td><td>2</td></tr><tr><th>4</th><td>235.0</td><td>2</td><td>10.0</td><td>1.79736</td><td>2</td></tr><tr><th>5</th><td>244.0</td><td>1</td><td>20.0</td><td>1.56958</td><td>3</td></tr><tr><th>6</th><td>244.0</td><td>2</td><td>6.0</td><td>1.51343</td><td>3</td></tr><tr><th>7</th><td>245.0</td><td>1</td><td>3.0</td><td>1.50659</td><td>4</td></tr><tr><th>8</th><td>245.0</td><td>2</td><td>7.0</td><td>1.4519</td><td>4</td></tr><tr><th>9</th><td>252.0</td><td>1</td><td>20.0</td><td>2.34668</td><td>5</td></tr><tr><th>10</th><td>252.0</td><td>2</td><td>20.0</td><td>1.79736</td><td>5</td></tr><tr><th>11</th><td>257.0</td><td>1</td><td>10.0</td><td>2.20996</td><td>6</td></tr><tr><th>12</th><td>257.0</td><td>2</td><td>20.0</td><td>2.02588</td><td>6</td></tr><tr><th>13</th><td>419.0</td><td>1</td><td>25.0</td><td>2.34668</td><td>9</td></tr><tr><th>14</th><td>419.0</td><td>2</td><td>15.0</td><td>1.79736</td><td>9</td></tr><tr><th>15</th><td>420.0</td><td>1</td><td>20.0</td><td>2.34668</td><td>10</td></tr><tr><th>16</th><td>420.0</td><td>2</td><td>0.0</td><td>1.79736</td><td>10</td></tr><tr><th>17</th><td>428.0</td><td>1</td><td>30.0</td><td>2.34668</td><td>11</td></tr><tr><th>18</th><td>428.0</td><td>2</td><td>0.0</td><td>1.79736</td><td>11</td></tr><tr><th>19</th><td>431.0</td><td>1</td><td>40.0</td><td>2.34668</td><td>12</td></tr><tr><th>20</th><td>431.0</td><td>2</td><td>30.0</td><td>1.79736</td><td>12</td></tr><tr><th>21</th><td>443.0</td><td>1</td><td>10.0</td><td>2.34668</td><td>14</td></tr><tr><th>22</th><td>443.0</td><td>2</td><td>10.0</td><td>1.79736</td><td>14</td></tr><tr><th>23</th><td>455.0</td><td>1</td><td>10.0</td><td>2.34668</td><td>16</td></tr><tr><th>24</th><td>455.0</td><td>2</td><td>10.0</td><td>1.79736</td><td>16</td></tr><tr><th>25</th><td>457.0</td><td>1</td><td>20.0</td><td>2.31494</td><td>17</td></tr><tr><th>26</th><td>457.0</td><td>2</td><td>20.0</td><td>1.80396</td><td>17</td></tr><tr><th>27</th><td>596.0</td><td>1</td><td>2.0</td><td>2.2417</td><td>18</td></tr><tr><th>28</th><td>596.0</td><td>2</td><td>0.0</td><td>1.82812</td><td>18</td></tr><tr><th>29</th><td>603.0</td><td>1</td><td>20.0</td><td>2.2417</td><td>19</td></tr><tr><th>30</th><td>603.0</td><td>2</td><td>20.0</td><td>1.82812</td><td>19</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& seqn & time & smoke & price & id\\\\\n",
       "\t\\hline\n",
       "\t& String & Int64 & Float64 & Float64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 233.0 & 1 & 30.0 & 2.18359 & 1 \\\\\n",
       "\t2 & 233.0 & 2 & 20.0 & 1.73999 & 1 \\\\\n",
       "\t3 & 235.0 & 1 & 20.0 & 2.34668 & 2 \\\\\n",
       "\t4 & 235.0 & 2 & 10.0 & 1.79736 & 2 \\\\\n",
       "\t5 & 244.0 & 1 & 20.0 & 1.56958 & 3 \\\\\n",
       "\t6 & 244.0 & 2 & 6.0 & 1.51343 & 3 \\\\\n",
       "\t7 & 245.0 & 1 & 3.0 & 1.50659 & 4 \\\\\n",
       "\t8 & 245.0 & 2 & 7.0 & 1.4519 & 4 \\\\\n",
       "\t9 & 252.0 & 1 & 20.0 & 2.34668 & 5 \\\\\n",
       "\t10 & 252.0 & 2 & 20.0 & 1.79736 & 5 \\\\\n",
       "\t11 & 257.0 & 1 & 10.0 & 2.20996 & 6 \\\\\n",
       "\t12 & 257.0 & 2 & 20.0 & 2.02588 & 6 \\\\\n",
       "\t13 & 419.0 & 1 & 25.0 & 2.34668 & 9 \\\\\n",
       "\t14 & 419.0 & 2 & 15.0 & 1.79736 & 9 \\\\\n",
       "\t15 & 420.0 & 1 & 20.0 & 2.34668 & 10 \\\\\n",
       "\t16 & 420.0 & 2 & 0.0 & 1.79736 & 10 \\\\\n",
       "\t17 & 428.0 & 1 & 30.0 & 2.34668 & 11 \\\\\n",
       "\t18 & 428.0 & 2 & 0.0 & 1.79736 & 11 \\\\\n",
       "\t19 & 431.0 & 1 & 40.0 & 2.34668 & 12 \\\\\n",
       "\t20 & 431.0 & 2 & 30.0 & 1.79736 & 12 \\\\\n",
       "\t21 & 443.0 & 1 & 10.0 & 2.34668 & 14 \\\\\n",
       "\t22 & 443.0 & 2 & 10.0 & 1.79736 & 14 \\\\\n",
       "\t23 & 455.0 & 1 & 10.0 & 2.34668 & 16 \\\\\n",
       "\t24 & 455.0 & 2 & 10.0 & 1.79736 & 16 \\\\\n",
       "\t25 & 457.0 & 1 & 20.0 & 2.31494 & 17 \\\\\n",
       "\t26 & 457.0 & 2 & 20.0 & 1.80396 & 17 \\\\\n",
       "\t27 & 596.0 & 1 & 2.0 & 2.2417 & 18 \\\\\n",
       "\t28 & 596.0 & 2 & 0.0 & 1.82812 & 18 \\\\\n",
       "\t29 & 603.0 & 1 & 20.0 & 2.2417 & 19 \\\\\n",
       "\t30 & 603.0 & 2 & 20.0 & 1.82812 & 19 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m3074×5 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m seqn    \u001b[0m\u001b[1m time  \u001b[0m\u001b[1m smoke   \u001b[0m\u001b[1m price   \u001b[0m\u001b[1m id    \u001b[0m\n",
       "\u001b[1m      \u001b[0m│\u001b[90m String  \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Int64 \u001b[0m\n",
       "──────┼─────────────────────────────────────────\n",
       "    1 │ 233.0        1     30.0  2.18359      1\n",
       "    2 │ 233.0        2     20.0  1.73999      1\n",
       "    3 │ 235.0        1     20.0  2.34668      2\n",
       "    4 │ 235.0        2     10.0  1.79736      2\n",
       "    5 │ 244.0        1     20.0  1.56958      3\n",
       "    6 │ 244.0        2      6.0  1.51343      3\n",
       "    7 │ 245.0        1      3.0  1.50659      4\n",
       "    8 │ 245.0        2      7.0  1.4519       4\n",
       "    9 │ 252.0        1     20.0  2.34668      5\n",
       "   10 │ 252.0        2     20.0  1.79736      5\n",
       "   11 │ 257.0        1     10.0  2.20996      6\n",
       "  ⋮   │    ⋮       ⋮       ⋮        ⋮       ⋮\n",
       " 3065 │ 25014.0      1     40.0  2.16797   1625\n",
       " 3066 │ 25014.0      2     40.0  1.94019   1625\n",
       " 3067 │ 25016.0      1     20.0  2.16797   1626\n",
       " 3068 │ 25016.0      2     20.0  1.94019   1626\n",
       " 3069 │ 25024.0      1     40.0  1.80078   1627\n",
       " 3070 │ 25024.0      2     80.0  1.64771   1627\n",
       " 3071 │ 25032.0      1     15.0  2.16797   1628\n",
       " 3072 │ 25032.0      2     20.0  1.94019   1628\n",
       " 3073 │ 25061.0      1     30.0  2.16797   1629\n",
       " 3074 │ 25061.0      2      0.0  1.94019   1629\n",
       "\u001b[36m                               3053 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R\"\"\"\n",
    "    # load NHEFS data\n",
    "    suppressWarnings(library(causaldata, warn.conflicts=FALSE))\n",
    "    data(nhefs, package = \"causaldata\")\n",
    "    \n",
    "    # keep both count outcomes from 1971 and 1982\n",
    "    nhefs$smokeintensity71 = nhefs$smokeintensity\n",
    "    nhefs$smokeintensity82 = nhefs$smokeintensity + nhefs$smkintensity82_71\n",
    "    \n",
    "    # transform data from wide format to long format\n",
    "    suppressWarnings(library(dplyr, warn.conflicts=FALSE))\n",
    "    nhefs = nhefs %>% select(seqn, smokeintensity71, smokeintensity82, price71, price82)\n",
    "    nhefs = as.data.frame(nhefs)\n",
    "    nhefs_long = reshape(nhefs, direction=\"long\",\n",
    "    varying=list(c(\"smokeintensity71\",\"smokeintensity82\"), c(\"price71\",\"price82\")), \n",
    "    v.names=c(\"smoke\",\"price\"))\n",
    "    df = nhefs_long[order(nhefs_long$seqn),]\n",
    "    df = df[complete.cases(df),]\n",
    "\"\"\"\n",
    "@rget df\n",
    "df[!, :seqn] .= string.(df[!, :seqn])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check overdispersion using empirical mean and variance\n",
    "\n",
    "If the count outcome is overdispersed, then using the Poisson Base distribution with the quasi copula model may be a case of model misspecification. The quasi copula model will inflate the variance component to account for the additional overdispersion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empirical_mean = 18.277813923227065\n",
      "empirical_variance = 178.364056918179\n",
      "empirical_overdispersion = 9.75850053334429\n"
     ]
    }
   ],
   "source": [
    "empirical_mean = mean(df[!, :smoke])\n",
    "empirical_variance = var(df[!, :smoke])\n",
    "\n",
    "empirical_overdispersion = empirical_variance / empirical_mean\n",
    "\n",
    "@show empirical_mean\n",
    "@show empirical_variance\n",
    "@show empirical_overdispersion;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is overdispersion in the data, therefore using the negative binomial base may be more appropriate for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Poisson Base Distribution\n",
    "### Form the random intercept model at fit using QuasiCopula.jl with Poisson Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quasi-Copula Variance Component Model\n",
       "  * base distribution: Poisson\n",
       "  * link function: LogLink\n",
       "  * number of clusters: 1537\n",
       "  * cluster size min, max: 2, 2\n",
       "  * number of variance components: 1\n",
       "  * number of fixed effects: 2\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = :smoke\n",
    "grouping = :seqn\n",
    "covariates = [:price]\n",
    "\n",
    "d = Poisson()\n",
    "link = LogLink()\n",
    "QC_Poisson_model = VC_model(df, y, grouping, covariates, d, link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing β using Newton's Algorithm under Independence Assumption\n",
      "gcm.β = [2.1159279480362807, 0.39787703892248655]\n",
      "initializing variance components using MM-Algorithm\n",
      "gcm.θ = [5.569804005046703]\n",
      "Total number of variables............................:        3\n",
      "                     variables with only lower bounds:        1\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        0\n",
      "Total number of inequality constraints...............:        0\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "\n",
      "Number of Iterations....: 18\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:   7.4667262223557827e+02    2.1175610374308759e+04\n",
      "Dual infeasibility......:   8.9619784478786685e-07    2.5416140640999178e-05\n",
      "Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Complementarity.........:   9.9999999999973418e-12    2.8359966260584467e-10\n",
      "Overall NLP error.......:   8.9619784478786685e-07    2.5416140640999178e-05\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 35\n",
      "Number of objective gradient evaluations             = 19\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 0\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 0\n",
      "Number of Lagrangian Hessian evaluations             = 0\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      0.073\n",
      "Total CPU secs in NLP function evaluations           =      0.086\n",
      "\n",
      "EXIT: Optimal Solution Found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.096910441"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QC_Poisson_fittime = @elapsed QuasiCopula.fit!(QC_Poisson_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without any penalty on the variance component, we see a very large value here. This may indicate there is some overdispersion in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the ridge penalty on the variance component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QC_Poisson_fittime = 0.096910441\n",
      "QC_Poisson_model.β = [2.0118278238060636, 0.43249136776609054]\n",
      "QC_Poisson_model.θ = [7.11929400615054]\n"
     ]
    }
   ],
   "source": [
    "@show QC_Poisson_fittime\n",
    "@show QC_Poisson_model.β\n",
    "@show QC_Poisson_model.θ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-21175.61037430876"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QC_Poisson_logl = logl(QC_Poisson_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit using MixedModels.jl\n",
    "\n",
    "Now we fit the same model using MixedModels.jl with 25 Gaussian quadrature points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mMinimizing 76 \t Time: 0:00:00 ( 3.53 ms/it)\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLMM_Poisson_fittime = 0.27081742\n",
      "GLMM_Poisson_β = [1.5148402125927902, 0.5984329913583817]\n",
      "GLMM_Poisson_θ = 0.4823489292459855\n"
     ]
    }
   ],
   "source": [
    "glmm_formula = @formula(smoke ~ 1 + price + (1|seqn));\n",
    "mdl = GeneralizedLinearMixedModel(glmm_formula, df, d, link)\n",
    "GLMM_Poisson_fittime = @elapsed MixedModels.fit!(mdl; nAGQ = 25);\n",
    "GLMM_Poisson_β = mdl.beta\n",
    "GLMM_Poisson_θ = mdl.σs[1][1]^2\n",
    "@show GLMM_Poisson_fittime\n",
    "@show GLMM_Poisson_β\n",
    "@show GLMM_Poisson_θ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-15535.512192772478"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GLMM_Poisson_logl = loglikelihood(mdl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some differences in the estimates using the Poisson base, and our loglikelihood is lower than that of mixed models. We note that because the data is overdispersed, using the Poisson base may be a misspecified model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: NB Base Distribution\n",
    "### Form the random intercept model at fit using QuasiCopula.jl with NB Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quasi-Copula Variance Component Model\n",
       "  * base distribution: NegativeBinomial\n",
       "  * link function: LogLink\n",
       "  * number of clusters: 1537\n",
       "  * cluster size min, max: 2, 2\n",
       "  * number of variance components: 1\n",
       "  * number of fixed effects: 2\n"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = :smoke\n",
    "grouping = :seqn\n",
    "covariates = [:price]\n",
    "\n",
    "d = NegativeBinomial()\n",
    "link = LogLink()\n",
    "QC_NB_model = VC_model(df, y, grouping, covariates, d, link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing β using GLM.jl\n",
      "gcm.β = [2.1063055490508487, 0.4027219419973325]\n",
      "initializing variance components using MM-Algorithm\n",
      "gcm.θ = [2.152252921565018e-6]\n",
      "initializing r using Newton update\n",
      "Converging when tol ≤ 1.0e-6 (max block iter = 10)\n",
      "Block iter 1 r = 1.11, logl = -12067.22, tol = 12067.219350099704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.126614904"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QC_NB_fittime = @elapsed QuasiCopula.fit!(QC_NB_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QC_NB_fittime = 0.126614904\n",
      "QC_NB_model.β = [2.1063339299583452, 0.40270765918773577]\n",
      "QC_NB_model.θ = [0.0]\n",
      "QC_NB_model.r = [1.1138519954190327]\n"
     ]
    }
   ],
   "source": [
    "@show QC_NB_fittime\n",
    "@show QC_NB_model.β\n",
    "@show QC_NB_model.θ\n",
    "@show QC_NB_model.r;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-12067.219352849264"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QC_NB_logl = logl(QC_NB_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit using MixedModels.jl\n",
    "\n",
    "Now we fit the same model using MixedModels.jl with 25 Gaussian quadrature points. \n",
    "\n",
    "These models both estimate the variance component to be 0, and have the same estimates for beta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mMinimizing 82 \t Time: 0:00:00 ( 4.05 ms/it)\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLMM_NB_fittime = 0.334116097\n",
      "GLMM_NB_β = [2.106309390981023, 0.4027195260064574]\n",
      "GLMM_NB_θ = 0.0\n",
      "GLMM_NB_r = 1.3827736598127374\n"
     ]
    }
   ],
   "source": [
    "glmm_formula = @formula(smoke ~ 1 + price + (1|seqn));\n",
    "mdl = GeneralizedLinearMixedModel(glmm_formula, df, d, link)\n",
    "GLMM_NB_fittime = @elapsed MixedModels.fit!(mdl; nAGQ = 25);\n",
    "GLMM_NB_β = mdl.beta\n",
    "GLMM_NB_θ = mdl.σs[1][1]^2\n",
    "GLMM_NB_r = inv(mdl.σ)\n",
    "@show GLMM_NB_fittime\n",
    "@show GLMM_NB_β\n",
    "@show GLMM_NB_θ\n",
    "@show GLMM_NB_r;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-12073.979452378717"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GLMM_NB_logl = loglikelihood(mdl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are not much differences in the estimates using the Negative Binomial base, and our loglikelihood is higher than that of mixed models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Bernoulli Base Distribution\n",
    "\n",
    "Lets turn the outcome into a Bernoulli indicator = 1 if the number of cigarettes smoked per day is greater than the sample mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.277813923227065"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample mean number of the number of cigarettes smoked per day in 1971 and 1982\n",
    "mean_count = mean(df[!, :smoke])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>3,074 rows × 6 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>seqn</th><th>time</th><th>smoke</th><th>price</th><th>id</th><th>binary_outcome</th></tr><tr><th></th><th title=\"String\">String</th><th title=\"Int64\">Int64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Int64\">Int64</th><th title=\"Bool\">Bool</th></tr></thead><tbody><tr><th>1</th><td>233.0</td><td>1</td><td>30.0</td><td>2.18359</td><td>1</td><td>1</td></tr><tr><th>2</th><td>233.0</td><td>2</td><td>20.0</td><td>1.73999</td><td>1</td><td>1</td></tr><tr><th>3</th><td>235.0</td><td>1</td><td>20.0</td><td>2.34668</td><td>2</td><td>1</td></tr><tr><th>4</th><td>235.0</td><td>2</td><td>10.0</td><td>1.79736</td><td>2</td><td>0</td></tr><tr><th>5</th><td>244.0</td><td>1</td><td>20.0</td><td>1.56958</td><td>3</td><td>1</td></tr><tr><th>6</th><td>244.0</td><td>2</td><td>6.0</td><td>1.51343</td><td>3</td><td>0</td></tr><tr><th>7</th><td>245.0</td><td>1</td><td>3.0</td><td>1.50659</td><td>4</td><td>0</td></tr><tr><th>8</th><td>245.0</td><td>2</td><td>7.0</td><td>1.4519</td><td>4</td><td>0</td></tr><tr><th>9</th><td>252.0</td><td>1</td><td>20.0</td><td>2.34668</td><td>5</td><td>1</td></tr><tr><th>10</th><td>252.0</td><td>2</td><td>20.0</td><td>1.79736</td><td>5</td><td>1</td></tr><tr><th>11</th><td>257.0</td><td>1</td><td>10.0</td><td>2.20996</td><td>6</td><td>0</td></tr><tr><th>12</th><td>257.0</td><td>2</td><td>20.0</td><td>2.02588</td><td>6</td><td>1</td></tr><tr><th>13</th><td>419.0</td><td>1</td><td>25.0</td><td>2.34668</td><td>9</td><td>1</td></tr><tr><th>14</th><td>419.0</td><td>2</td><td>15.0</td><td>1.79736</td><td>9</td><td>0</td></tr><tr><th>15</th><td>420.0</td><td>1</td><td>20.0</td><td>2.34668</td><td>10</td><td>1</td></tr><tr><th>16</th><td>420.0</td><td>2</td><td>0.0</td><td>1.79736</td><td>10</td><td>0</td></tr><tr><th>17</th><td>428.0</td><td>1</td><td>30.0</td><td>2.34668</td><td>11</td><td>1</td></tr><tr><th>18</th><td>428.0</td><td>2</td><td>0.0</td><td>1.79736</td><td>11</td><td>0</td></tr><tr><th>19</th><td>431.0</td><td>1</td><td>40.0</td><td>2.34668</td><td>12</td><td>1</td></tr><tr><th>20</th><td>431.0</td><td>2</td><td>30.0</td><td>1.79736</td><td>12</td><td>1</td></tr><tr><th>21</th><td>443.0</td><td>1</td><td>10.0</td><td>2.34668</td><td>14</td><td>0</td></tr><tr><th>22</th><td>443.0</td><td>2</td><td>10.0</td><td>1.79736</td><td>14</td><td>0</td></tr><tr><th>23</th><td>455.0</td><td>1</td><td>10.0</td><td>2.34668</td><td>16</td><td>0</td></tr><tr><th>24</th><td>455.0</td><td>2</td><td>10.0</td><td>1.79736</td><td>16</td><td>0</td></tr><tr><th>25</th><td>457.0</td><td>1</td><td>20.0</td><td>2.31494</td><td>17</td><td>1</td></tr><tr><th>26</th><td>457.0</td><td>2</td><td>20.0</td><td>1.80396</td><td>17</td><td>1</td></tr><tr><th>27</th><td>596.0</td><td>1</td><td>2.0</td><td>2.2417</td><td>18</td><td>0</td></tr><tr><th>28</th><td>596.0</td><td>2</td><td>0.0</td><td>1.82812</td><td>18</td><td>0</td></tr><tr><th>29</th><td>603.0</td><td>1</td><td>20.0</td><td>2.2417</td><td>19</td><td>1</td></tr><tr><th>30</th><td>603.0</td><td>2</td><td>20.0</td><td>1.82812</td><td>19</td><td>1</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& seqn & time & smoke & price & id & binary\\_outcome\\\\\n",
       "\t\\hline\n",
       "\t& String & Int64 & Float64 & Float64 & Int64 & Bool\\\\\n",
       "\t\\hline\n",
       "\t1 & 233.0 & 1 & 30.0 & 2.18359 & 1 & 1 \\\\\n",
       "\t2 & 233.0 & 2 & 20.0 & 1.73999 & 1 & 1 \\\\\n",
       "\t3 & 235.0 & 1 & 20.0 & 2.34668 & 2 & 1 \\\\\n",
       "\t4 & 235.0 & 2 & 10.0 & 1.79736 & 2 & 0 \\\\\n",
       "\t5 & 244.0 & 1 & 20.0 & 1.56958 & 3 & 1 \\\\\n",
       "\t6 & 244.0 & 2 & 6.0 & 1.51343 & 3 & 0 \\\\\n",
       "\t7 & 245.0 & 1 & 3.0 & 1.50659 & 4 & 0 \\\\\n",
       "\t8 & 245.0 & 2 & 7.0 & 1.4519 & 4 & 0 \\\\\n",
       "\t9 & 252.0 & 1 & 20.0 & 2.34668 & 5 & 1 \\\\\n",
       "\t10 & 252.0 & 2 & 20.0 & 1.79736 & 5 & 1 \\\\\n",
       "\t11 & 257.0 & 1 & 10.0 & 2.20996 & 6 & 0 \\\\\n",
       "\t12 & 257.0 & 2 & 20.0 & 2.02588 & 6 & 1 \\\\\n",
       "\t13 & 419.0 & 1 & 25.0 & 2.34668 & 9 & 1 \\\\\n",
       "\t14 & 419.0 & 2 & 15.0 & 1.79736 & 9 & 0 \\\\\n",
       "\t15 & 420.0 & 1 & 20.0 & 2.34668 & 10 & 1 \\\\\n",
       "\t16 & 420.0 & 2 & 0.0 & 1.79736 & 10 & 0 \\\\\n",
       "\t17 & 428.0 & 1 & 30.0 & 2.34668 & 11 & 1 \\\\\n",
       "\t18 & 428.0 & 2 & 0.0 & 1.79736 & 11 & 0 \\\\\n",
       "\t19 & 431.0 & 1 & 40.0 & 2.34668 & 12 & 1 \\\\\n",
       "\t20 & 431.0 & 2 & 30.0 & 1.79736 & 12 & 1 \\\\\n",
       "\t21 & 443.0 & 1 & 10.0 & 2.34668 & 14 & 0 \\\\\n",
       "\t22 & 443.0 & 2 & 10.0 & 1.79736 & 14 & 0 \\\\\n",
       "\t23 & 455.0 & 1 & 10.0 & 2.34668 & 16 & 0 \\\\\n",
       "\t24 & 455.0 & 2 & 10.0 & 1.79736 & 16 & 0 \\\\\n",
       "\t25 & 457.0 & 1 & 20.0 & 2.31494 & 17 & 1 \\\\\n",
       "\t26 & 457.0 & 2 & 20.0 & 1.80396 & 17 & 1 \\\\\n",
       "\t27 & 596.0 & 1 & 2.0 & 2.2417 & 18 & 0 \\\\\n",
       "\t28 & 596.0 & 2 & 0.0 & 1.82812 & 18 & 0 \\\\\n",
       "\t29 & 603.0 & 1 & 20.0 & 2.2417 & 19 & 1 \\\\\n",
       "\t30 & 603.0 & 2 & 20.0 & 1.82812 & 19 & 1 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m3074×6 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m seqn    \u001b[0m\u001b[1m time  \u001b[0m\u001b[1m smoke   \u001b[0m\u001b[1m price   \u001b[0m\u001b[1m id    \u001b[0m\u001b[1m binary_outcome \u001b[0m\n",
       "\u001b[1m      \u001b[0m│\u001b[90m String  \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Bool           \u001b[0m\n",
       "──────┼─────────────────────────────────────────────────────────\n",
       "    1 │ 233.0        1     30.0  2.18359      1            true\n",
       "    2 │ 233.0        2     20.0  1.73999      1            true\n",
       "    3 │ 235.0        1     20.0  2.34668      2            true\n",
       "    4 │ 235.0        2     10.0  1.79736      2           false\n",
       "    5 │ 244.0        1     20.0  1.56958      3            true\n",
       "    6 │ 244.0        2      6.0  1.51343      3           false\n",
       "    7 │ 245.0        1      3.0  1.50659      4           false\n",
       "    8 │ 245.0        2      7.0  1.4519       4           false\n",
       "    9 │ 252.0        1     20.0  2.34668      5            true\n",
       "   10 │ 252.0        2     20.0  1.79736      5            true\n",
       "   11 │ 257.0        1     10.0  2.20996      6           false\n",
       "  ⋮   │    ⋮       ⋮       ⋮        ⋮       ⋮          ⋮\n",
       " 3065 │ 25014.0      1     40.0  2.16797   1625            true\n",
       " 3066 │ 25014.0      2     40.0  1.94019   1625            true\n",
       " 3067 │ 25016.0      1     20.0  2.16797   1626            true\n",
       " 3068 │ 25016.0      2     20.0  1.94019   1626            true\n",
       " 3069 │ 25024.0      1     40.0  1.80078   1627            true\n",
       " 3070 │ 25024.0      2     80.0  1.64771   1627            true\n",
       " 3071 │ 25032.0      1     15.0  2.16797   1628           false\n",
       " 3072 │ 25032.0      2     20.0  1.94019   1628            true\n",
       " 3073 │ 25061.0      1     30.0  2.16797   1629            true\n",
       " 3074 │ 25061.0      2      0.0  1.94019   1629           false\n",
       "\u001b[36m                                               3053 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make \"count\" variable binary in new variable \"binary_outcome\"\n",
    "df[!, :binary_outcome] = df[!, :smoke] .> mean_count\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Form the random intercept model at fit using QuasiCopula.jl with Bernoulli Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quasi-Copula Variance Component Model\n",
       "  * base distribution: Bernoulli\n",
       "  * link function: LogitLink\n",
       "  * number of clusters: 1537\n",
       "  * cluster size min, max: 2, 2\n",
       "  * number of variance components: 1\n",
       "  * number of fixed effects: 2\n"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = :binary_outcome\n",
    "grouping = :seqn\n",
    "covariates = [:price]\n",
    "\n",
    "d = Bernoulli()\n",
    "link = LogitLink()\n",
    "QC_Bernoulli_model = VC_model(df, y, grouping, covariates, d, link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing β using Newton's Algorithm under Independence Assumption\n",
      "gcm.β = [-1.6639349088875555, 0.9824969792078235]\n",
      "initializing variance components using MM-Algorithm\n",
      "gcm.θ = [0.5385024551594434]\n",
      "Total number of variables............................:        3\n",
      "                     variables with only lower bounds:        1\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        0\n",
      "Total number of inequality constraints...............:        0\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "\n",
      "Number of Iterations....: 15\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:   1.9730262442597357e+03    1.9730262442597357e+03\n",
      "Dual infeasibility......:   1.9131907169622764e-09    1.9131907169622764e-09\n",
      "Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Complementarity.........:   9.9999999999999994e-12    9.9999999999999994e-12\n",
      "Overall NLP error.......:   1.9131907169622764e-09    1.9131907169622764e-09\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 26\n",
      "Number of objective gradient evaluations             = 16\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 0\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 0\n",
      "Number of Lagrangian Hessian evaluations             = 0\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      0.053\n",
      "Total CPU secs in NLP function evaluations           =      0.066\n",
      "\n",
      "EXIT: Optimal Solution Found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06998636"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QC_Bernoulli_fittime = @elapsed QuasiCopula.fit!(QC_Bernoulli_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QC_Bernoulli_fittime = 0.06998636\n",
      "QC_Bernoulli_model.β = [-3.8426699785621885, 2.1755990137575356]\n",
      "QC_Bernoulli_model.θ = [0.6692358062462648]\n"
     ]
    }
   ],
   "source": [
    "@show QC_Bernoulli_fittime\n",
    "@show QC_Bernoulli_model.β\n",
    "@show QC_Bernoulli_model.θ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1973.0262442597357"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QC_Bernoulli_logl =  logl(QC_Bernoulli_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit using MixedModels.jl\n",
    "\n",
    "Now we fit the same model using MixedModels.jl with 25 Gaussian quadrature points. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32mMinimizing 78 \t Time: 0:00:00 ( 3.58 ms/it)\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLMM_Bernoulli_fittime = 0.281189228\n",
      "GLMM_Bernoulli_β = [-3.349071450784314, 1.923119293142038]\n",
      "GLMM_Bernoulli_θ = 3.780959140641813\n"
     ]
    }
   ],
   "source": [
    "glmm_formula = @formula(binary_outcome ~ 1 + price + (1|seqn));\n",
    "mdl = GeneralizedLinearMixedModel(glmm_formula, df, d, link)\n",
    "GLMM_Bernoulli_fittime = @elapsed MixedModels.fit!(mdl; nAGQ = 25);\n",
    "GLMM_Bernoulli_β = mdl.beta\n",
    "GLMM_Bernoulli_θ = mdl.σs[1][1]^2\n",
    "@show GLMM_Bernoulli_fittime\n",
    "@show GLMM_Bernoulli_β\n",
    "@show GLMM_Bernoulli_θ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2018.049580583702"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GLMM_Bernoulli_logl = loglikelihood(mdl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some differences in these estimates for the Bernoulli base, and our loglikelihood is higher than that of mixed models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparisons\n",
    "\n",
    "Here we will just summarize the comparisons between the three models. \n",
    "\n",
    "### Poisson Base Distribution\n",
    "\n",
    "    - Using the Poisson Base distribution to analyze the data is a case of model misspecification because the count data is overdispersed.\n",
    "    - When using the Poisson base, our model tries to account for it by inflating the variance component. \n",
    "    - The loglikelihood of GLMM is higher than that of QuasiCopula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QC_Poisson_model.β = [2.0118278238060636, 0.43249136776609054]\n",
      "QC_Poisson_model.θ = [7.11929400615054]\n"
     ]
    }
   ],
   "source": [
    "# QC estimates\n",
    "@show QC_Poisson_model.β\n",
    "@show QC_Poisson_model.θ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLMM_Poisson_β = [1.5148402125927902, 0.5984329913583817]\n",
      "GLMM_Poisson_θ = 0.4823489292459855\n"
     ]
    }
   ],
   "source": [
    "# GLMM estimates\n",
    "@show GLMM_Poisson_β\n",
    "@show GLMM_Poisson_θ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QC_Poisson_logl = -21175.61037430876\n",
      "GLMM_Poisson_logl = -15535.512192772478\n"
     ]
    }
   ],
   "source": [
    "# Loglikelihoods\n",
    "@show QC_Poisson_logl\n",
    "@show GLMM_Poisson_logl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QC_Poisson_fittime = 0.096910441\n",
      "GLMM_Poisson_fittime = 0.27081742\n"
     ]
    }
   ],
   "source": [
    "# fittimes\n",
    "@show QC_Poisson_fittime\n",
    "@show GLMM_Poisson_fittime;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Binomial Base Distribution\n",
    "\n",
    "    - Using the Negative Binomial base distribution to analyze the data is more appropriate than using the Poisson base distribution since it is inherently overdispersed by definition.\n",
    "    - Both the QC and GLMM models estimate about the same betas. \n",
    "    - Both the QC and GLMM models estimate the variance component to 0. This indicates that there is no additional overdispersion than already accounted for by the negative binomial base distribution. \n",
    "    - The loglikelihood of GLMM is lower than that of QuasiCopula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QC_NB_model.β = [2.1063339299583452, 0.40270765918773577]\n",
      "QC_NB_model.θ = [0.0]\n",
      "QC_NB_model.r = [1.1138519954190327]\n"
     ]
    }
   ],
   "source": [
    "# QC estimates\n",
    "@show QC_NB_model.β\n",
    "@show QC_NB_model.θ\n",
    "@show QC_NB_model.r;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLMM_NB_β = [2.106309390981023, 0.4027195260064574]\n",
      "GLMM_NB_θ = 0.0\n",
      "GLMM_NB_r = 1.3827736598127374\n"
     ]
    }
   ],
   "source": [
    "# GLMM estimates\n",
    "@show GLMM_NB_β\n",
    "@show GLMM_NB_θ\n",
    "@show GLMM_NB_r;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QC_NB_logl = -12067.219352849264\n",
      "GLMM_NB_logl = -12073.979452378717\n"
     ]
    }
   ],
   "source": [
    "# Loglikelihoods\n",
    "@show QC_NB_logl\n",
    "@show GLMM_NB_logl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QC_NB_fittime = 0.126614904\n",
      "GLMM_NB_fittime = 0.334116097\n"
     ]
    }
   ],
   "source": [
    "# fittimes\n",
    "@show QC_NB_fittime\n",
    "@show GLMM_NB_fittime;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Base Distribution\n",
    "\n",
    "    - Using the Bernoulli base distribution to analyze the data shows comparable estimates between QC and GLMM.\n",
    "    - The loglikelihood of GLMM is lower than that of QuasiCopula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QC_Bernoulli_model.β = [-3.8426699785621885, 2.1755990137575356]\n",
      "QC_Bernoulli_model.θ = [0.6692358062462648]\n"
     ]
    }
   ],
   "source": [
    "# QC estimates\n",
    "@show QC_Bernoulli_model.β\n",
    "@show QC_Bernoulli_model.θ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLMM_Bernoulli_β = [-3.349071450784314, 1.923119293142038]\n",
      "GLMM_Bernoulli_θ = 3.780959140641813\n"
     ]
    }
   ],
   "source": [
    "# GLMM estimates\n",
    "@show GLMM_Bernoulli_β\n",
    "@show GLMM_Bernoulli_θ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QC_Bernoulli_logl = -1973.0262442597357\n",
      "GLMM_Bernoulli_logl = -2018.049580583702\n"
     ]
    }
   ],
   "source": [
    "# Loglikelihoods\n",
    "@show QC_Bernoulli_logl\n",
    "@show GLMM_Bernoulli_logl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QC_Bernoulli_fittime = 0.06998636\n",
      "GLMM_Bernoulli_fittime = 0.281189228\n"
     ]
    }
   ],
   "source": [
    "# fittimes\n",
    "@show QC_Bernoulli_fittime\n",
    "@show GLMM_Bernoulli_fittime;"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
